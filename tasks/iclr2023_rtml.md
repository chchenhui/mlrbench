## Trustworthy and Reliable Large-Scale Machine Learning Models

In recent years, the landscape of AI has been significantly altered by the advances in large-scale pre-trained models. Scaling up the models with more data and parameters has significantly improved performance and achieved great success in a variety of applications, from natural language understanding to multi-modal representation learning. However, when applying large-scale AI models to real-world applications, there have been concerns about their potential security, privacy, fairness, robustness, and ethics issues. In the wrong hands, machine learning could be used to negatively impact mission-critical domains, including healthcare, education, and law, resulting in economic and environmental consequences as well as legal and ethical concerns. For example, existing studies have shown that large-scale pre-trained language models contain toxicity in open-ended generation and have the risk of amplifying bias against marginalized groups, such as BIPOC and LGBTQ+. Moreover, large-scale models can unintentionally leak sensitive personal information during the pre-training stage. Last but not least, machine learning models are often viewed as "blackboxes" and may produce unpredictable, inaccurate, and unexplainable results, especially under domain shifts or maliciously tailored attacks.

To address these negative societal impacts in large-scale models, researchers have investigated different approaches and principles to ensure robust and trustworthy large-scale AI systems. This workshop is the first attempt to bridge the gap between security, privacy, fairness, ethics, and large-scale AI models and aims to discuss the principles and experiences of developing robust and trustworthy large-scale AI systems. The workshop also focuses on how future researchers and practitioners should prepare themselves to reduce the risks of unintended behaviors of large ML models.

## Topics

We invite submissions on any aspect of trustworthy and reliable ML, especially for large-scale models. Topics include but are not limited to:

- Novel methods for building more trustworthy large-scale machine learning models that prevent or alleviate negative societal impacts of existing ML methods
- New applications and settings where the robustness and trustworthiness of machine learning play an important role and how well existing techniques work under these settings
- Machine learning models with verifiable guarantees (such as robustness, fairness, and privacy guarantees) to build trustworthiness
- Privacy-preserving machine learning approaches for large-scale machine learning models
- Theoretical understanding of trustworthy machine learning
- Explainable and interpretable methods for large-scale AI
- Pre-training techniques to build more robust and trustworthy large-scale machine learning models
- Efficient fine-tuning methods to alleviate the trustworthiness gap for large-scale pre-trained models
- Machine unlearning to mitigate the privacy, toxicity, and bias issues within large-scale AI models
- Robust decision-making under uncertainty
- Futuristic concerns about trustworthy machine learning for foundation models
- Game-theoretic analysis for socially responsible machine learning systems
- Case studies and field research of the societal impacts of applying machine learning in mission-critical and human-centric tasks