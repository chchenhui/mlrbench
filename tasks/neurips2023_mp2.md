# Overview
The central theme of the workshop will be the application of moral philosophy and moral psychology theories to AI practices. Our invited speakers are some of the leaders in the emerging efforts to draw on theories in philosophy or psychology to develop ethical AI systems. Their talks will demonstrate cutting-edge efforts to do this cross-disciplinary work, while also highlighting their own shortcomings (and those of the field more broadly). Each talk will receive a 5-minute commentary from a junior scholar in a field that is different from that of the speaker. We hope these talks and commentaries will inspire conversations among the rest of the attendees.

# Topics
Ideal submissions will show how a theory from moral philosophy or moral psychology can be applied in the development or analysis of ethical AI systems. For example:
- How can moral philosophers and psychologists best contribute to ethically-informed AI?
- What can theories of developmental moral psychology teach us about making AI?
- How do theories of moral philosophy shed light on modern AI practices?
- How can AI tools advance the fields of moral philosophy and psychology themselves?
- How can findings from moral psychology inform the trustworthiness, transparency or interpretability of AI decision-makers?
- What human values are already embedded in current AI systems?
- Are the values embedded in the current-day AI systems consistent with those in society at large?
- What pluralistic values are missing from current-day AI?
- Methodologically, what is the best way to teach an AI system human values? What are competitors to RLHF, reinforcement learning from human feedback?
- Concerning AI alignment, to which values are we to align? Is the current practice of AI alignment amplifying monolithic voices? How can we incorporate diverse voices, views and values into AI systems?

