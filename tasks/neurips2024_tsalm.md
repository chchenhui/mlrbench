## Workshop on Time Series in the Age of Large Models
Foundation models have revolutionized the approach to building machine learning models in areas like natural language processing, where models are pretrained on large amounts of diverse data and then adapted for downstreams tasks, often in a zero-shot fashion. This approach has begun to gain traction in the time series community. Recent works have developed and open-sourced foundation models for time series tasks, particularly forecasting. Additionally, some studies have shown positive results by either leveraging pretrained models from other modalities, such as text, for time series tasks or enhancing time series analysis through exogenous information from other modalities. These advancements have opened new research directions and challenges related to the development, analysis, evaluation, and real-world applications of large models for time series tasks. This workshop aims to provide a forum for researchers and practitioners to understand the progress made and push the frontier of time series research in the era of large models.


## Scope and Topics
We invite submissions related to the theme of time series in the age of large models. Key topics include, but are not limited to:

- **Building Time Series Foundation Models:** The heterogeneity of time series data and tasks presents unique challenges in developing time series foundation models. We welcome contributions exploring various design choices and improving our understanding of how these models scale with the amount and diversity of data.
- **Analysis of Pretrained Time Series Models:** Pretrained time series models are often criticized for their black-box nature, especially compared to interpretable statistical models. We encourage submissions that analyze pretrained time series models to enhance our understanding of their learning processes.
- **Critiques on Time Series Foundation Models:** Contributions highlighting the limitations and failure modes of time series foundation models through theoretical analysis or systematic empirical evaluations are welcome.
- **Faster and Better Inference Schemes for Autoregressive Time Series Models:** Single-step autoregressive time series foundation models are generally slower than multi-step models, such as those based on patching. We invite submissions comparing these techniques and developing methods to improve the inference speed and quality of autoregressive time series models.
- **Leveraging Pretrained Models of Other Modalities for Time Series:** Recent studies show promise in adapting pretrained LLMs to specialized time series tasks. We seek to understand how design choices in leveraging these models—such as prompting techniques, adaptation methods, and fine-tuning—impact performance. We also seek to identify scenarios where these methods excel compared to training time series foundation models from scratch, in terms of model capabilities, accuracy, and training and inference times.
- **Multimodal Time Series Models:** Most time series models handle only numerical data, often providing a partial picture of the system of interest. In real-world settings, multiple modalities are available, and incorporating exogenous information, such as text, can enhance performance. We invite submissions exploring time series models that integrate information from other modalities.
- **Large-Scale Time Series Datasets and Benchmarks:** The quality and quantity of publicly available time series data lag behind other modalities, such as text and vision. We welcome contributions of large-scale time series data (both general and domain-specific) and benchmarks comparing various time series foundation models. We also invite methods for better synthetic time series generation and augmentation to address data challenges.
- **Time Series Evaluation:** We seek contributions on the analysis, comparison, and development of metrics for time series tasks, including metrics for probabilistic forecasting, multivariate forecasting, and use-case motivated metrics.
- **Real-World Applications of Large Time Series Models:** We invite contributions showcasing the potential of large time series models in real-world domains, such as energy, healthcare, retail, human mobility, and finance.
