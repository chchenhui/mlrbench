# Causal Representation Learning Workshop

## About the workshop
Current machine learning systems have rapidly increased in performance by leveraging ever-larger models and datasets. Despite astonishing abilities and impressive demos, these models fundamentally only learn from statistical correlations and struggle at tasks such as domain generalisation, adversarial examples, or planning, which require higher-order cognition. This sole reliance on capturing correlations sits at the core of current debates about making AI systems ``truly’’ understand. One promising and so far underexplored approach for obtaining visual systems that can go beyond correlations is integrating ideas from causality into representation learning.

Causal inference aims to reason about the effect of interventions or external manipulations on a system, as well as about hypothetical counterfactual scenarios. Similar to classic approaches to AI, it typically assumes that the causal variables of interest are given from the outset. However, real-world data often comprises high-dimensional, low-level observations (e.g., RGB pixels in a video) and is thus usually not structured into such meaningful causal units.

To this end, the emerging field of causal representation learning (CRL) combines the strengths of ML and causality. In CRL we aim at learning low-dimensional, high-level causal variables along with their causal relations directly from raw, unstructured data, leading to representations that support notions such as causal factors, intervention, reasoning, and planning. In this sense, CRL aligns with the general goal of modern ML to learn meaningful representations of data that are more robust, explainable, and performant, and in our workshop we want to catalyze research in this direction.

This workshop brings together researchers from the emerging CRL community, as well as from the more classical causality and representation learning communities, who are interested in learning causal, robust, interpretable and transferrable representations. Our goal is to foster discussion and cross-fertilization between causality, representation learning and other fields, as well as to engage the community in identifying application domains for this emerging new field.

## Topics
We welcome submissions related to any aspects of CRL, including but not limited to:

- Causal representation learning, including self-supervised, multi-modal or multi-environment CRL, either in time series or in an atemporal setting, observational or interventional
- Causality-inspired representation learning, including learning representations that are only approximately causal, but still useful in terms of generalization or transfer learning
- Abstractions of causal models or in general multi-level causal systems
- Connecting CRL with system identification, learning differential equations from data or sequences of images, or in general connections to dynamical systems
- Theoretical works on identifiability in representation learning broadly
- Real-world applications of CRL, e.g. in biology, healthcare, (medical) imaging or robotics; including new benchmarks or datasets, or addressing the gap from theory to practice

