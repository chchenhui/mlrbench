# Representational Alignment

Both natural and artificial intelligences form representations of the world that they use to reason, make decisions, and communicate. Despite extensive research across machine learning, neuroscience, and cognitive science, it remains unclear what the most appropriate ways are to compare and align the representations of intelligent systems (Sucholutsky et al., 2023). In the second edition of the Workshop on Representational Alignment (Re-Align), we bring together researchers from diverse fields who study representational alignment to make concrete progress on this set of open interdisciplinary problems. We invite researchers across the machine learning, neuroscience, and cognitive science communities to participate in the workshop, and to contribute to the workshop in two ways:

First, in the form of contributed papers that address questions of representational alignment that stem from the following central theme: When and why do intelligence systems learn aligned representations, and how can scientists and engineers intervene on this alignment? Other questions topical for this yearâ€™s workshop include:

- To what extent does representational alignment indicate shared computational strategies among biological and artificial systems?
- How have current alignment metrics advanced our understanding of computation, and what measurement approaches should we explore next?
- How can we develop more robust and generalizable measures of alignment that work across different domains and types of representations?
- How can we systematically increase (or decrease) representational alignment among biological and artificial systems?
W- hat are the implications (positive and negative) of increasing or decreasing representational alignment between systems, on behavioral alignment, value alignment, and beyond?

Second, by participating in our workshop hackathon. Since the first iteration of Re-Align workshop, there have been numerous debates around the metrics that we use to measure representational similarity, which is often taken as a measure of representational alignment (e.g., Cloos et al., 2024; Khosla et al., 2024; Lampinen et al., 2024; Schaeffer et al., 2024). As of now, there is little consensus on which metric best achieves the goal of identifying similarity between systems. The hackathon component of the workshop will be helpful in articulating the consequences of these methodologies by facilitating a common language among researchers, and as a result increase the reproducibility of research in this subdomain.
