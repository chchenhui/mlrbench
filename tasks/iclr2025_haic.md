HAIC 2025, the First Workshop on Human-AI Coevolution, focuses on the emerging field of Human-AI Coevolution (HAIC) to understand the feedback loops that emerge through continuous human-AI coadaptation.

This workshop focuses on new approaches beyond AI performance benchmarks, exploring multiple levels of analysis spanning single human-AI agent collaboration behavior to long term multiple human-AI interaction with impact across social institutions such as healthcare and criminal justice.


## Subject Areas

We invite contributions that address various aspects of human-AI coevolution (HAIC) from diverse disciplines. Submissions should align with the overarching goal of the workshop, which is to explore the intricate interaction between humans and AI systems over extended periods. 

We welcome submissions of either (i) work that provides innovative insights, case studies, empirical analyses, and theoretical contributions addressing HAIC, (ii) position papers that make relevant arguments about HAIC, or (ii) expressions of interest in which prospective attendees describe their general background and interests in HAIC.

In particular, we are interested in work that delve into the following subject areas:

1. Human-AI Interaction and Alignment

- Evolution of human expectations and trust in AI systems

- Design principles for aligning AI systems with human values

- Ethical and societal implications of HAIC

- Effects of HAIC on human autonomy and social norms

2. Algorithmic Adaptation and Robustness

- Enhancements to Reinforcement Learning from Human Feedback (RLHF)

- Technical frameworks for improving AI adaptability to human preferences

- Strategies for reducing bias and promoting fairness in AI decision-making

- Techniques for ensuring AI robustness across diverse contexts

3. Long-Term Societal Impact and Safety

- Implications of HAIC on governance, policy, and public decision-making processes

- Integration of AI alignment principles into socio-technological systems

- Reimagining AI safety in light of dynamic human-AI interactions

- Evaluating the impact of existing AI systems on future developments

4. Bidirectional Learning Beyond Performance Metrics

- Exploration of how prolonged human-AI interactions shape cognition and decision-making

- Revising evaluation metrics to assess AI systems through the lens of HAIC

- Investigating the interplay between human behavior and AI agency

5. Shaping Collective Behavior and Learning

- Examining AI's influence on group decision-making and consensus-building

- Addressing the role of AI in collaborative environments such as education and policy-making

- Understanding implicit biases formed through AI-mediated interactions

6. Dynamic Feedback Loops in Socially Impactful Domains

- Real-time feedback mechanisms in critical contexts (e.g., healthcare, education, criminal justice)

- Addressing unique demands of domain-specific AI-human interactions

- The role of AI in shaping outcomes in high-stakes environments

7. Socio-Technological Bias, Norms, and Ethics

- Critical analysis of how AI systems perpetuate or mitigate societal biases

- Examining ethical implications of AI feedback loops in decision-making

- Exploring the reshaping of social norms through AI interactions

- Addressing complexities of bias in the context of HAIC

We welcome submissions that provide innovative insights, case studies, empirical analyses, and theoretical contributions addressing these subjects. We welcome submissions of either (i) work that provides innovative insights, case studies, empirical analyses, and theoretical contributions addressing HAIC, (ii) position papers that make relevant arguments about HAIC, or (ii) expressions of interest in which prospective attendees describe their general background and interests in HAIC. Our aim is to facilitate interdisciplinary dialogue, foster collaboration, and advance the understanding of HAIC as a vital research area.
