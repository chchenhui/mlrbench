# AI for Science: Scaling in AI for Scientific Discovery

## About

Dramatic developments in AI have led to its increasing adoption in science as a means to model complex phenomena, generate hypotheses, design experiments, collect and interpret large datasets, and gain new insights that might not have been possible using traditional scientific methods alone. The main goal of this series of workshop is to discover synergy across a variety of scientific fields, encourage interdisciplinary discussions, and enhance the flow of knowledge between AI and various scientific communities. Throughout history, bridging seemly different fields has brought overarching benefits, with notable examples: entropy in thermodynamics and information theory, neuroscience and AI, and algorithms inspired by discoveries in science (e.g. genetic algorithm, simulated annealing and diffusion-based generative models). In the current era, successes of AI methods in different fields of science have alluded to the general effectiveness of common themes: large simulated datasets, enforcing problem symmetries, and foundation model architectures. Our mission is to bring more scientists to attend ICML to share different perspectives on the use of AI, and to illuminate exciting research directions for AI researchers. 

## Interested Areas

We welcome submissions from all AI for Science areas, but we concentrate some of our talks and panels on scaling in AI for Science.

- How scaling can help AI for Science?

- How scaling can be done in AI for Science?

- How scaling change the Pareto frontier of methodology, interpretability and discovery?

- What is the limitation of scaling and what is the cure for it?
