## Data-centric Machine Learning Research

Large-scale foundation models are revolutionizing machine learning, particularly in vision and language domains. While model architecture received significant attention in the past, recent focus has shifted towards the importance of data quality, size, and diversity, and provenance.

This workshop aims to highlight cutting-edge advancements in data-centric approaches for large-scale foundation models in new domains, in addition to language and vision, and engage the vibrant interdisciplinary community of researchers, practitioners, and engineers who tackle practical data challenges related to foundation models. By featuring innovative research and facilitating collaboration, it aims to bridge the gap between dataset-centric methodologies and the development of robust, versatile foundation models that are able to work in and across a variety of domains in service of humanity.

## Topics

Topics will include, but are not limited to
- Data sources for large-scale datasets
- Construction of datasets from large quantities of unlabeled/uncurated data
- Model-assisted dataset construction
- Quality signals for large-scale datasets
- Datasets for evaluation
- Datasets for specific applications
- Impact of dataset drifts in large-scale models
- Ethical considerations for and governance of large-scale datasets
- Data curation and HCI
- Submissions to benchmarks such as DataPerf, DynaBench, and DataComp