# Workshop on Representational Alignment

## About

Both natural and artificial intelligences form representations of the world that they use to reason, make decisions, and communicate. Despite extensive research across machine learning, neuroscience, and cognitive science, it remains unclear what the most appropriate ways are to compare and align the representations of intelligent systems (Sucholutsky et al., 2023).

## Questions

In the second edition of the Workshop on Representational Alignment (Re-Align), we bring together researchers from diverse fields who study representational alignment to make concrete progress on this set of open interdisciplinary problems. 
We invite researchers across the machine learning, neuroscience, and cognitive science communities to participate in the workshop, and to contribute papers that address questions of representational alignment that stem from the following central theme: When and why do intelligence systems learn aligned representations, and how can scientists and engineers intervene on this alignment? Other questions topical for this yearâ€™s workshop include:

- To what extent does representational alignment indicate shared computational strategies among biological and artificial systems?

- How have current alignment metrics advanced our understanding of computation, and what measurement approaches should we explore next?

- How can we develop more robust and generalizable measures of alignment that work across different domains and types of representations?

- How can we systematically increase (or decrease) representational alignment among biological and artificial systems?

- What are the implications (positive and negative) of increasing or decreasing representational alignment between systems, on behavioral alignment, value alignment, and beyond?
