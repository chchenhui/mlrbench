## Workshop on Socially Responsible Language Modelling Research

The Socially Responsible Language Modelling Research (SoLaR) workshop at NeurIPS 2024 is an interdisciplinary gathering that aims to foster responsible and ethical research in the field of language modeling. Recognizing the significant risks and harms associated with the development, deployment, and use of language models, the workshop emphasizes the need for researchers to focus on addressing these risks starting from the early stages of development. The workshop brings together experts and practitioners from various domains and academic fields with a shared commitment to promoting fairness, equity, accountability, transparency, and safety in language modeling research.

## Topics
Given the wide-ranging impacts of LMs, our workshop will welcome a broad array of submissions. We briefly detail some specific topic areas and an illustrative selection of pertinent works:

- Security and privacy concerns of LMs [13, 30, 25, 49, 55].
- Bias and exclusion in LMs [12, 2, 26, 53, 44].
- Analysis of the development and deployment of LMs, including crowdwork [42, 50], deploy- ment protocols [52, 47], and societal impacts from deployment [10, 21].
- Safety, robustness, and alignment of LMs [51, 8, 35, 32, 7].
- Auditing, red-teaming, and evaluations of LMs [41, 40, 29, 15, 11].
- Examination of risks and harms from any novel input and/or output modalities that are introduced in LMs [14, 28, 54].
- Transparency, explainability, interpretability of LMs [39, 17, 3, 46, 22, 38].
- Applications of LMs for social good, including sector-specific applications [9, 31, 16] and LMs for low-resource languages [4, 5, 36].
- Perspectives from other domains that can inform socially responsible LM development and deployment [48, 1].
