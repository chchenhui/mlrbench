## About

In-context learning (ICL) is an emerging capability of large-scale models, including large language models (LLMs) like GPT-3, to acquire new capabilities directly from the context of an input example without separate training or fine-tuning, enabling these models to adapt rapidly to new tasks, datasets, and domains. This workshop brings together diverse perspectives on this new paradigm to assess progress, synthesize best practices, and chart open problems. Core topics will include architectural and other inductive biases enabling in-context skill acquisition, and reliable evaluation of ICL in application domains including reinforcement learning, representation learning, and safe and reliable machine learning.

We invite submissions to the ICL 2024 workshop, focusing on the development of new architectures, algorithms, theoretical analysis, empirical studies, and applications of In-Context Learning (ICL). Submissions must present original research that has not been previously published.

## Topics

Specific topics of interest include, but are not limited to:

- architectures, training paradigms, and inductive biases that enable or improve ICL;
- theoretical analyses and guarantees for ICL methods;
- empirical evaluation of the performance of ICL on interpretability, controllability, and safety considerations for ICL systems;
- similarities and differences between ICL in large-scale language modeling systems and learned algorithms in other domains;
- the relationship between ICL and few-shot learning, meta-learning and automated machine learning (AutoML).
