# SSCSteer: Syntactic and Semantic Conformance Steering for LLM Code Generation

This repository contains the implementation of the SSCSteer (Syntactic and Semantic Conformance Steering) framework for enhancing the correctness of code generated by Large Language Models (LLMs).

## Overview

Large Language Models (LLMs) have shown impressive capabilities in code generation, but they often produce code with syntactic errors or semantic flaws, especially for complex tasks or low-resource languages. SSCSteer addresses this challenge by integrating lightweight formal methods into the LLM's decoding process.

SSCSteer consists of two main components:

1. **Syntactic Steering Module (SSM)**: Uses context-free grammars to constrain token selection to syntactically valid choices.
2. **Semantic Steering Module (SeSM)**: Employs static analysis and SMT solving to identify and penalize semantically problematic code paths.

By guiding the generation process, SSCSteer aims to produce code that is correct-by-construction, reducing the need for post-hoc validation and debugging.

## Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager

### Setup

1. Clone this repository and navigate to the directory:

```bash
git clone <repository-url>
cd claude_code
```

2. Create a virtual environment (optional but recommended):

```bash
python -m venv venv
source venv/bin/activate  # On Windows, use: venv\Scripts\activate
```

3. Install the required dependencies:

```bash
pip install -r requirements.txt
```

4. Set up API keys for LLM access:

```bash
export OPENAI_API_KEY=your_openai_api_key
export ANTHROPIC_API_KEY=your_anthropic_api_key
export HUGGINGFACE_API_KEY=your_huggingface_api_key
```

## Running the Experiments

The main experiment can be run using the `run_experiments.py` script:

```bash
python run_experiments.py --llm openai --model gpt-4o-mini --num_problems 10
```

### Command-line Arguments

- `--llm`: LLM provider to use (`openai`, `claude`, `codellama`, `qwen`)
- `--model`: Specific model to use
- `--num_problems`: Number of problems to evaluate per dataset
- `--save_dir`: Directory to save results (default: `results`)
- `--run_baselines`: Run baseline methods for comparison
- `--run_ablation`: Run ablation study
- `--seed`: Random seed for reproducibility (default: 42)

### Examples

1. Run the full experiment with all baselines and ablation studies:

```bash
python run_experiments.py --llm openai --model gpt-4o-mini --num_problems 10 --run_baselines --run_ablation
```

2. Run a lightweight experiment with just SSCSteer (no baselines or ablation):

```bash
python run_experiments.py --llm openai --model gpt-4o-mini --num_problems 5
```

3. Use Anthropic's Claude model:

```bash
python run_experiments.py --llm claude --model claude-3-sonnet-20240229 --num_problems 10 --run_baselines
```

4. Use Hugging Face's CodeLlama model:

```bash
python run_experiments.py --llm codellama --model CodeLlama-7b-Instruct-hf --num_problems 10
```

## Code Structure

- `src/ssm.py`: Implementation of the Syntactic Steering Module
- `src/sesm.py`: Implementation of the Semantic Steering Module
- `src/sscsteer.py`: Integration of SSM and SeSM into the SSCSteer framework
- `src/baselines.py`: Baseline methods for comparison
- `src/datasets.py`: Dataset creation and loading utilities
- `src/evaluation.py`: Evaluation metrics and testing framework
- `src/visualization.py`: Result visualization utilities
- `src/llm_interface.py`: Interface to different LLM providers
- `run_experiments.py`: Main experiment runner

## Results

After running the experiments, results are saved in the specified directory (default: `results/`). The results include:

- **experiment_results.json**: Raw data from the experiment
- **results.md**: Summarized results with tables and analysis
- **performance_comparison.png**: Chart comparing the performance of different approaches
- **bug_patterns.png**: Distribution of bug patterns across approaches
- **dataset_comparison.png**: Performance comparison across datasets
- **ablation_study.png**: Results of the ablation study
- **beam_evolution.png**: Evolution of beam search during generation

## Customization

### Adding New Datasets

To add a new dataset, modify the `datasets.py` file:

1. Create a function that generates the dataset
2. Update the `save_datasets` and `load_datasets` functions

### Supporting New Languages

To add support for a new programming language:

1. Create a new language analyzer class in `ssm.py`
2. Implement the required methods for syntactic analysis
3. Update the `SyntacticSteeringModule` class to use the new analyzer

### Using Different LLMs

To use a different LLM provider:

1. Implement a new generator class in `llm_interface.py`
2. Update the `get_llm_generator` function to return the new generator

## Limitations

- The current implementation focuses primarily on Python, with limited support for other languages.
- The semantic steering module handles only a subset of semantic properties.
- The integration with SMT solvers is simplified and doesn't handle complex logical constraints.
- The computational overhead of steering may be prohibitive for some applications.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Citation

If you use this code in your research, please cite:

```
@misc{sscsteer2024,
  author = {SSCSteer Authors},
  title = {SSCSteer: Syntactic and Semantic Conformance Steering for LLM Code Generation},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/yourusername/sscsteer}
}
```