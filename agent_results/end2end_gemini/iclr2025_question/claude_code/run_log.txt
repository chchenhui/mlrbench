2025-05-11 06:39:15,893 - __main__ - INFO - Starting all experiments at 2025-05-11 06:39:15
2025-05-11 06:39:15,894 - __main__ - INFO - Running baseline experiment
2025-05-11 06:39:15,894 - __main__ - INFO - Running command: python run_experiments.py --output-dir ./results --dataset truthfulqa --max-samples 20 --use-api --api-model gpt-4o-mini --run-baseline
2025-05-11 06:39:37,127 - __main__ - ERROR - 2025-05-11 06:39:20.566644: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-11 06:39:20.582147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1746916760.599937  560009 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1746916760.605259  560009 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1746916760.619293  560009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916760.619308  560009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916760.619310  560009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916760.619312  560009 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-05-11 06:39:20.623460: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-11 06:39:23,126 - __main__ - INFO - Starting experiment with settings: Namespace(model='gpt2', use_api=True, api_model='gpt-4o-mini', dataset='truthfulqa', split='validation', max_samples=20, embedding_model='sentence-transformers/all-MiniLM-L6-v2', use_sparse_retriever=False, num_documents=3, uncertainty='entropy', mc_samples=5, spuq_perturbations=3, threshold=0.5, threshold_type='fixed', window_size=5, chunk_size=10, segment_mode=False, temperature=0.7, max_tokens=100, batch_size=5, output_dir='./results', no_gpu=False, run_all=False, run_baseline=True, run_standard_rag=False, run_aug_rag=False, run_ablation=None, ablation_samples=20)
2025-05-11 06:39:23,126 - __main__ - INFO - Creating knowledge base for truthfulqa
2025-05-11 06:39:30,165 - data.data_utils - INFO - Loaded TruthfulQA dataset (validation split) with 817 samples
2025-05-11 06:39:30,233 - data.data_utils - INFO - Created knowledge base with 1634 items at /home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/data/truthfulqa_kb.json
2025-05-11 06:39:30,333 - __main__ - INFO - Using device: cuda
2025-05-11 06:39:30,333 - __main__ - INFO - Using API-based model: gpt-4o-mini
2025-05-11 06:39:30,333 - __main__ - INFO - Starting baseline experiment
2025-05-11 06:39:34,881 - data.data_utils - INFO - Loaded TruthfulQA dataset (validation split) with 817 samples
2025-05-11 06:39:34,881 - __main__ - INFO - Loaded truthfulqa dataset with 817 examples
2025-05-11 06:39:35,280 - models.base_model - INFO - Initialized APIBasedModel with gpt-4o-mini
2025-05-11 06:39:35,281 - __main__ - INFO - Created baseline model: gpt-4o-mini

Generating:   0%|          | 0/4 [00:00<?, ?it/s]
Generating:   0%|          | 0/4 [00:00<?, ?it/s]
2025-05-11 06:39:35,282 - __main__ - ERROR - Error running experiments: string indices must be integers, not 'str'
Traceback (most recent call last):
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 1285, in main
    baseline_results = run_baseline_experiment(env, args)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 254, in run_baseline_experiment
    questions = [item["question"] for item in batch]
                 ~~~~^^^^^^^^^^^^
TypeError: string indices must be integers, not 'str'
Traceback (most recent call last):
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 1345, in <module>
    main()
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 1285, in main
    baseline_results = run_baseline_experiment(env, args)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 254, in run_baseline_experiment
    questions = [item["question"] for item in batch]
                 ~~~~^^^^^^^^^^^^
TypeError: string indices must be integers, not 'str'

2025-05-11 06:39:37,127 - __main__ - ERROR - Baseline experiment failed
2025-05-11 06:41:35,870 - __main__ - INFO - Starting all experiments at 2025-05-11 06:41:35
2025-05-11 06:41:35,870 - __main__ - INFO - Running baseline experiment
2025-05-11 06:41:35,870 - __main__ - INFO - Running command: python run_experiments.py --output-dir ./results --dataset truthfulqa --max-samples 10 --use-api --api-model gpt-4o-mini --run-baseline
2025-05-11 06:42:00,051 - __main__ - ERROR - 2025-05-11 06:41:40.528304: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-11 06:41:40.543757: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1746916900.561607  560955 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1746916900.566929  560955 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1746916900.580956  560955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916900.580971  560955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916900.580973  560955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916900.580975  560955 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-05-11 06:41:40.585152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-11 06:41:43,085 - __main__ - INFO - Starting experiment with settings: Namespace(model='gpt2', use_api=True, api_model='gpt-4o-mini', dataset='truthfulqa', split='validation', max_samples=10, embedding_model='sentence-transformers/all-MiniLM-L6-v2', use_sparse_retriever=False, num_documents=3, uncertainty='entropy', mc_samples=5, spuq_perturbations=3, threshold=0.5, threshold_type='fixed', window_size=5, chunk_size=10, segment_mode=False, temperature=0.7, max_tokens=100, batch_size=5, output_dir='./results', no_gpu=False, run_all=False, run_baseline=True, run_standard_rag=False, run_aug_rag=False, run_ablation=None, ablation_samples=20)
2025-05-11 06:41:43,175 - __main__ - INFO - Using device: cuda
2025-05-11 06:41:43,175 - __main__ - INFO - Using API-based model: gpt-4o-mini
2025-05-11 06:41:43,175 - __main__ - INFO - Starting baseline experiment
2025-05-11 06:41:49,956 - data.data_utils - INFO - Loaded TruthfulQA dataset (validation split) with 817 samples
2025-05-11 06:41:49,956 - __main__ - INFO - Loaded truthfulqa dataset with 817 examples
2025-05-11 06:41:50,359 - models.base_model - INFO - Initialized APIBasedModel with gpt-4o-mini
2025-05-11 06:41:50,359 - __main__ - INFO - Created baseline model: gpt-4o-mini

Generating:   0%|          | 0/2 [00:00<?, ?it/s]2025-05-11 06:41:51,079 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:41:52,527 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:41:54,135 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"

Generating:  50%|█████     | 1/2 [00:03<00:03,  3.78s/it]2025-05-11 06:41:54,821 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:41:56,633 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:41:58,423 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"

Generating: 100%|██████████| 2/2 [00:08<00:00,  4.08s/it]
Generating: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]
2025-05-11 06:41:58,427 - __main__ - INFO - Baseline metrics: {'num_samples': 6, 'truthful_percent': 0.0, 'informative_percent': 1.0, 'self_contradiction_rate': 0.0, 'unique_1grams': 0.5040983606555312, 'unique_2grams': 0.8067226890752913, 'mean_length': 40.666666666666664}
2025-05-11 06:41:58,428 - __main__ - INFO - Saved baseline results to ./results/experiment_20250511_064143/results/baseline_results.json
2025-05-11 06:41:58,428 - __main__ - INFO - Creating visualizations from results
2025-05-11 06:41:58,428 - __main__ - INFO - Completed visualizations
2025-05-11 06:41:58,428 - __main__ - INFO - Generating markdown report
2025-05-11 06:41:58,429 - __main__ - INFO - Generated markdown report at ./results/experiment_20250511_064143/results.md
2025-05-11 06:41:58,429 - __main__ - INFO - Copied results to /home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/results
2025-05-11 06:41:58,429 - __main__ - INFO - Experiment completed successfully

2025-05-11 06:42:00,051 - __main__ - INFO - Running standard RAG experiment
2025-05-11 06:42:00,051 - __main__ - INFO - Running command: python run_experiments.py --output-dir ./results --dataset truthfulqa --max-samples 10 --use-api --api-model gpt-4o-mini --run-standard-rag
2025-05-11 06:42:28,115 - __main__ - ERROR - 2025-05-11 06:42:04.719311: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-11 06:42:04.734884: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1746916924.752825  561193 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1746916924.758203  561193 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1746916924.772267  561193 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916924.772283  561193 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916924.772285  561193 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916924.772286  561193 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-05-11 06:42:04.776494: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-11 06:42:07,275 - __main__ - INFO - Starting experiment with settings: Namespace(model='gpt2', use_api=True, api_model='gpt-4o-mini', dataset='truthfulqa', split='validation', max_samples=10, embedding_model='sentence-transformers/all-MiniLM-L6-v2', use_sparse_retriever=False, num_documents=3, uncertainty='entropy', mc_samples=5, spuq_perturbations=3, threshold=0.5, threshold_type='fixed', window_size=5, chunk_size=10, segment_mode=False, temperature=0.7, max_tokens=100, batch_size=5, output_dir='./results', no_gpu=False, run_all=False, run_baseline=False, run_standard_rag=True, run_aug_rag=False, run_ablation=None, ablation_samples=20)
2025-05-11 06:42:07,361 - __main__ - INFO - Using device: cuda
2025-05-11 06:42:07,361 - __main__ - INFO - Using API-based model: gpt-4o-mini
2025-05-11 06:42:07,361 - __main__ - INFO - Starting standard RAG experiment
2025-05-11 06:42:14,829 - data.data_utils - INFO - Loaded TruthfulQA dataset (validation split) with 817 samples
2025-05-11 06:42:14,830 - __main__ - INFO - Loaded truthfulqa dataset with 817 examples
2025-05-11 06:42:15,233 - models.base_model - INFO - Initialized APIBasedModel with gpt-4o-mini
2025-05-11 06:42:15,234 - models.rag_model - INFO - Loaded knowledge base with 1634 documents
2025-05-11 06:42:15,236 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2

Batches:   0%|          | 0/52 [00:00<?, ?it/s]
Batches:   2%|▏         | 1/52 [00:00<00:34,  1.47it/s]
Batches:  19%|█▉        | 10/52 [00:00<00:02, 16.53it/s]
Batches:  42%|████▏     | 22/52 [00:00<00:00, 36.06it/s]
Batches:  62%|██████▏   | 32/52 [00:01<00:00, 49.56it/s]
Batches:  83%|████████▎ | 43/52 [00:01<00:00, 63.09it/s]
Batches: 100%|██████████| 52/52 [00:01<00:00, 43.88it/s]
2025-05-11 06:42:20,161 - models.rag_model - INFO - Initialized dense retriever with sentence-transformers/all-MiniLM-L6-v2
2025-05-11 06:42:20,162 - models.rag_model - INFO - Initialized RetrieverModule with dense retrieval
2025-05-11 06:42:20,162 - models.rag_model - INFO - Initialized StandardRAGModel with 3 documents per query
2025-05-11 06:42:20,162 - __main__ - INFO - Created standard RAG model with 3 documents per query

Generating:   0%|          | 0/2 [00:00<?, ?it/s]

Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 141.49it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 295.69it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 303.08it/s]
2025-05-11 06:42:21,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:42:22,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:42:23,239 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 109.11it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 158.22it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 213.78it/s]

Generating:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]

Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 141.97it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 258.40it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 264.06it/s]
2025-05-11 06:42:24,317 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:42:25,246 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:42:26,372 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 114.13it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 171.88it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 251.77it/s]

Generating: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]
Generating: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]
2025-05-11 06:42:26,401 - __main__ - INFO - Standard RAG metrics: {'num_samples': 6, 'truthful_percent': 0.0, 'informative_percent': 1.0, 'self_contradiction_rate': 0.0, 'unique_1grams': 0.39285714285694245, 'unique_2grams': 0.6789473684206954, 'mean_length': 32.666666666666664, 'knowledge_f1': 0.0625}
2025-05-11 06:42:26,402 - __main__ - INFO - Saved standard RAG results to ./results/experiment_20250511_064207/results/standard_rag_results.json
2025-05-11 06:42:26,402 - __main__ - INFO - Creating visualizations from results
2025-05-11 06:42:26,402 - __main__ - INFO - Completed visualizations
2025-05-11 06:42:26,402 - __main__ - INFO - Generating markdown report
2025-05-11 06:42:26,402 - __main__ - INFO - Generated markdown report at ./results/experiment_20250511_064207/results.md
2025-05-11 06:42:26,403 - __main__ - INFO - Copied results to /home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/results
2025-05-11 06:42:26,403 - __main__ - INFO - Experiment completed successfully

2025-05-11 06:42:28,115 - __main__ - INFO - Running AUG-RAG experiment with entropy uncertainty and fixed threshold
2025-05-11 06:42:28,115 - __main__ - INFO - Running command: python run_experiments.py --output-dir ./results --dataset truthfulqa --max-samples 10 --use-api --api-model gpt-4o-mini --run-aug-rag --uncertainty entropy --threshold-type fixed
2025-05-11 06:42:48,803 - __main__ - ERROR - 2025-05-11 06:42:32.783330: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-11 06:42:32.798813: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1746916952.816555  561547 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1746916952.821872  561547 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1746916952.835906  561547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916952.835921  561547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916952.835923  561547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746916952.835924  561547 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-05-11 06:42:32.840101: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-11 06:42:35,335 - __main__ - INFO - Starting experiment with settings: Namespace(model='gpt2', use_api=True, api_model='gpt-4o-mini', dataset='truthfulqa', split='validation', max_samples=10, embedding_model='sentence-transformers/all-MiniLM-L6-v2', use_sparse_retriever=False, num_documents=3, uncertainty='entropy', mc_samples=5, spuq_perturbations=3, threshold=0.5, threshold_type='fixed', window_size=5, chunk_size=10, segment_mode=False, temperature=0.7, max_tokens=100, batch_size=5, output_dir='./results', no_gpu=False, run_all=False, run_baseline=False, run_standard_rag=False, run_aug_rag=True, run_ablation=None, ablation_samples=20)
2025-05-11 06:42:35,421 - __main__ - INFO - Using device: cuda
2025-05-11 06:42:35,421 - __main__ - INFO - Using API-based model: gpt-4o-mini
2025-05-11 06:42:35,421 - __main__ - INFO - Starting AUG-RAG experiment
2025-05-11 06:42:42,349 - data.data_utils - INFO - Loaded TruthfulQA dataset (validation split) with 817 samples
2025-05-11 06:42:42,349 - __main__ - INFO - Loaded truthfulqa dataset with 817 examples
2025-05-11 06:42:42,749 - models.base_model - INFO - Initialized APIBasedModel with gpt-4o-mini
2025-05-11 06:42:42,750 - models.rag_model - INFO - Loaded knowledge base with 1634 documents
2025-05-11 06:42:42,752 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2

Batches:   0%|          | 0/52 [00:00<?, ?it/s]
Batches:   2%|▏         | 1/52 [00:00<00:29,  1.71it/s]
Batches:  21%|██        | 11/52 [00:00<00:01, 20.73it/s]
Batches:  48%|████▊     | 25/52 [00:00<00:00, 45.98it/s]
Batches:  71%|███████   | 37/52 [00:00<00:00, 63.30it/s]
Batches: 100%|██████████| 52/52 [00:00<00:00, 52.77it/s]
2025-05-11 06:42:47,112 - models.rag_model - INFO - Initialized dense retriever with sentence-transformers/all-MiniLM-L6-v2
2025-05-11 06:42:47,113 - models.rag_model - INFO - Initialized RetrieverModule with dense retrieval
2025-05-11 06:42:47,113 - models.uncertainty - INFO - Initialized EntropyBasedUncertainty
2025-05-11 06:42:47,113 - models.aug_rag_model - INFO - Initialized AdaptiveRetrievalTrigger with fixed threshold
2025-05-11 06:42:47,113 - models.aug_rag_model - INFO - Initialized AdaptiveRAGModel with 3 documents per retrieval
2025-05-11 06:42:47,113 - __main__ - INFO - Created AUG-RAG model with entropy uncertainty and fixed threshold

Generating:   0%|          | 0/2 [00:00<?, ?it/s]
Generating:   0%|          | 0/2 [00:00<?, ?it/s]
2025-05-11 06:42:47,114 - __main__ - ERROR - Error running experiments: 'APIBasedModel' object has no attribute 'tokenizer'
Traceback (most recent call last):
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 1303, in main
    aug_rag_results = run_aug_rag_experiment(env, args)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 464, in run_aug_rag_experiment
    batch_predictions = model.generate(
                        ^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/aug_rag_model.py", line 316, in generate
    output = self.generate_with_adaptive_retrieval(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/aug_rag_model.py", line 242, in generate_with_adaptive_retrieval
    uncertainty = self.uncertainty_estimator.estimate_uncertainty(current_context, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/uncertainty.py", line 67, in estimate_uncertainty
    logits = self.model.get_logits(input_text)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/base_model.py", line 126, in get_logits
    input_encodings = self.tokenizer(
                      ^^^^^^^^^^^^^^
AttributeError: 'APIBasedModel' object has no attribute 'tokenizer'
Traceback (most recent call last):
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 1353, in <module>
    main()
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 1303, in main
    aug_rag_results = run_aug_rag_experiment(env, args)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/run_experiments.py", line 464, in run_aug_rag_experiment
    batch_predictions = model.generate(
                        ^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/aug_rag_model.py", line 316, in generate
    output = self.generate_with_adaptive_retrieval(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/aug_rag_model.py", line 242, in generate_with_adaptive_retrieval
    uncertainty = self.uncertainty_estimator.estimate_uncertainty(current_context, **kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/uncertainty.py", line 67, in estimate_uncertainty
    logits = self.model.get_logits(input_text)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/claude_code/models/base_model.py", line 126, in get_logits
    input_encodings = self.tokenizer(
                      ^^^^^^^^^^^^^^
AttributeError: 'APIBasedModel' object has no attribute 'tokenizer'

2025-05-11 06:42:48,803 - __main__ - ERROR - AUG-RAG experiment with entropy and fixed failed
2025-05-11 06:45:13,157 - __main__ - INFO - Starting all experiments at 2025-05-11 06:45:13
2025-05-11 06:45:13,158 - __main__ - INFO - Running baseline experiment
2025-05-11 06:45:13,158 - __main__ - INFO - Running command: python run_experiments.py --output-dir ./results --dataset truthfulqa --max-samples 8 --use-api --api-model gpt-4o-mini --run-baseline
2025-05-11 06:45:38,501 - __main__ - ERROR - 2025-05-11 06:45:17.842394: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-11 06:45:17.858105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1746917117.876392  562764 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1746917117.881892  562764 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1746917117.896074  562764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746917117.896091  562764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746917117.896093  562764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746917117.896094  562764 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-05-11 06:45:17.900275: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-11 06:45:20,405 - __main__ - INFO - Starting experiment with settings: Namespace(model='gpt2', use_api=True, api_model='gpt-4o-mini', dataset='truthfulqa', split='validation', max_samples=8, embedding_model='sentence-transformers/all-MiniLM-L6-v2', use_sparse_retriever=False, num_documents=3, uncertainty='entropy', mc_samples=5, spuq_perturbations=3, threshold=0.5, threshold_type='fixed', window_size=5, chunk_size=10, segment_mode=False, temperature=0.7, max_tokens=100, batch_size=5, output_dir='./results', no_gpu=False, run_all=False, run_baseline=True, run_standard_rag=False, run_aug_rag=False, run_ablation=None, ablation_samples=20)
2025-05-11 06:45:20,492 - __main__ - INFO - Using device: cuda
2025-05-11 06:45:20,492 - __main__ - INFO - Using API-based model: gpt-4o-mini
2025-05-11 06:45:20,492 - __main__ - INFO - Starting baseline experiment
2025-05-11 06:45:27,581 - data.data_utils - INFO - Loaded TruthfulQA dataset (validation split) with 817 samples
2025-05-11 06:45:27,581 - __main__ - INFO - Loaded truthfulqa dataset with 817 examples
2025-05-11 06:45:27,984 - models.base_model - INFO - Initialized APIBasedModel with gpt-4o-mini
2025-05-11 06:45:27,984 - __main__ - INFO - Created baseline model: gpt-4o-mini

Generating:   0%|          | 0/2 [00:00<?, ?it/s]2025-05-11 06:45:28,812 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:45:31,111 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:45:32,801 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"

Generating:  50%|█████     | 1/2 [00:04<00:04,  4.82s/it]2025-05-11 06:45:33,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:45:34,929 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:45:36,871 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"

Generating: 100%|██████████| 2/2 [00:08<00:00,  4.38s/it]
Generating: 100%|██████████| 2/2 [00:08<00:00,  4.44s/it]
2025-05-11 06:45:36,876 - __main__ - INFO - Baseline metrics: {'num_samples': 6, 'truthful_percent': 0.0, 'informative_percent': 1.0, 'self_contradiction_rate': 0.16666666666666666, 'unique_1grams': 0.5311203319499871, 'unique_2grams': 0.7957446808507253, 'mean_length': 40.166666666666664}
2025-05-11 06:45:36,876 - __main__ - INFO - Saved baseline results to ./results/experiment_20250511_064520/results/baseline_results.json
2025-05-11 06:45:36,876 - __main__ - INFO - Creating visualizations from results
2025-05-11 06:45:36,877 - __main__ - INFO - Completed visualizations
2025-05-11 06:45:36,877 - __main__ - INFO - Generating markdown report
2025-05-11 06:45:36,877 - __main__ - INFO - Generated markdown report at ./results/experiment_20250511_064520/results.md
2025-05-11 06:45:36,878 - __main__ - INFO - Copied results to /home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/results
2025-05-11 06:45:36,878 - __main__ - INFO - Experiment completed successfully

2025-05-11 06:45:38,502 - __main__ - INFO - Running standard RAG experiment
2025-05-11 06:45:38,502 - __main__ - INFO - Running command: python run_experiments.py --output-dir ./results --dataset truthfulqa --max-samples 8 --use-api --api-model gpt-4o-mini --run-standard-rag
2025-05-11 06:46:08,023 - __main__ - ERROR - 2025-05-11 06:45:43.159174: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-11 06:45:43.174628: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1746917143.192438  563008 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1746917143.197794  563008 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1746917143.211800  563008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746917143.211815  563008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746917143.211817  563008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1746917143.211818  563008 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-05-11 06:45:43.215987: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-05-11 06:45:45,717 - __main__ - INFO - Starting experiment with settings: Namespace(model='gpt2', use_api=True, api_model='gpt-4o-mini', dataset='truthfulqa', split='validation', max_samples=8, embedding_model='sentence-transformers/all-MiniLM-L6-v2', use_sparse_retriever=False, num_documents=3, uncertainty='entropy', mc_samples=5, spuq_perturbations=3, threshold=0.5, threshold_type='fixed', window_size=5, chunk_size=10, segment_mode=False, temperature=0.7, max_tokens=100, batch_size=5, output_dir='./results', no_gpu=False, run_all=False, run_baseline=False, run_standard_rag=True, run_aug_rag=False, run_ablation=None, ablation_samples=20)
2025-05-11 06:45:45,806 - __main__ - INFO - Using device: cuda
2025-05-11 06:45:45,806 - __main__ - INFO - Using API-based model: gpt-4o-mini
2025-05-11 06:45:45,806 - __main__ - INFO - Starting standard RAG experiment
2025-05-11 06:45:53,029 - data.data_utils - INFO - Loaded TruthfulQA dataset (validation split) with 817 samples
2025-05-11 06:45:53,029 - __main__ - INFO - Loaded truthfulqa dataset with 817 examples
2025-05-11 06:45:53,429 - models.base_model - INFO - Initialized APIBasedModel with gpt-4o-mini
2025-05-11 06:45:53,430 - models.rag_model - INFO - Loaded knowledge base with 1634 documents
2025-05-11 06:45:53,432 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2

Batches:   0%|          | 0/52 [00:00<?, ?it/s]
Batches:   2%|▏         | 1/52 [00:00<00:26,  1.93it/s]
Batches:  21%|██        | 11/52 [00:00<00:01, 22.76it/s]
Batches:  44%|████▍     | 23/52 [00:00<00:00, 45.21it/s]
Batches:  71%|███████   | 37/52 [00:00<00:00, 68.71it/s]
Batches:  94%|█████████▍| 49/52 [00:00<00:00, 81.21it/s]
Batches: 100%|██████████| 52/52 [00:00<00:00, 54.01it/s]
2025-05-11 06:45:57,731 - models.rag_model - INFO - Initialized dense retriever with sentence-transformers/all-MiniLM-L6-v2
2025-05-11 06:45:57,731 - models.rag_model - INFO - Initialized RetrieverModule with dense retrieval
2025-05-11 06:45:57,731 - models.rag_model - INFO - Initialized StandardRAGModel with 3 documents per query
2025-05-11 06:45:57,731 - __main__ - INFO - Created standard RAG model with 3 documents per query

Generating:   0%|          | 0/2 [00:00<?, ?it/s]

Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 135.71it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 284.21it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 290.40it/s]
2025-05-11 06:45:59,054 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:46:00,430 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:46:01,496 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 113.07it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 104.97it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 212.26it/s]

Generating:  50%|█████     | 1/2 [00:03<00:03,  3.80s/it]

Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 262.19it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 259.13it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 261.90it/s]
2025-05-11 06:46:03,081 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:46:05,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2025-05-11 06:46:06,284 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 119.44it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 163.39it/s]


Batches:   0%|          | 0/1 [00:00<?, ?it/s][A
Batches: 100%|██████████| 1/1 [00:00<00:00, 196.56it/s]

Generating: 100%|██████████| 2/2 [00:08<00:00,  4.38s/it]
Generating: 100%|██████████| 2/2 [00:08<00:00,  4.29s/it]
2025-05-11 06:46:06,316 - __main__ - INFO - Standard RAG metrics: {'num_samples': 6, 'truthful_percent': 0.0, 'informative_percent': 1.0, 'self_contradiction_rate': 0.16666666666666666, 'unique_1grams': 0.39662447257367234, 'unique_2grams': 0.7359307359304174, 'mean_length': 39.5, 'knowledge_f1': 0.05550980185126527}
2025-05-11 06:46:06,316 - __main__ - INFO - Saved standard RAG results to ./results/experiment_20250511_064545/results/standard_rag_results.json
2025-05-11 06:46:06,316 - __main__ - INFO - Creating visualizations from results
2025-05-11 06:46:06,316 - __main__ - INFO - Completed visualizations
2025-05-11 06:46:06,316 - __main__ - INFO - Generating markdown report
2025-05-11 06:46:06,317 - __main__ - INFO - Generated markdown report at ./results/experiment_20250511_064545/results.md
2025-05-11 06:46:06,317 - __main__ - INFO - Copied results to /home/chenhui/mlr-bench/pipeline_gemini/iclr2025_question/results
2025-05-11 06:46:06,317 - __main__ - INFO - Experiment completed successfully

2025-05-11 06:46:08,023 - __main__ - INFO - Running AUG-RAG experiment with entropy uncertainty and fixed threshold
2025-05-11 06:46:08,023 - __main__ - INFO - Running command: python run_experiments.py --output-dir ./results --dataset truthfulqa --max-samples 8 --use-api --api-model gpt-4o-mini --run-aug-rag --uncertainty entropy --threshold-type fixed
