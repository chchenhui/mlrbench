2025-05-11 05:18:25,791 [INFO] Environment setup complete
2025-05-11 05:18:25,791 [INFO] ================================================================================
2025-05-11 05:18:25,791 [INFO] Starting Concept-Graph experiment pipeline
2025-05-11 05:18:25,791 [INFO] Model: meta-llama/Llama-3.1-8B-Instruct
2025-05-11 05:18:25,791 [INFO] Dataset: gsm8k
2025-05-11 05:18:25,791 [INFO] Samples: 3
2025-05-11 05:18:25,791 [INFO] Small experiment: True
2025-05-11 05:18:25,791 [INFO] Force CPU: True
2025-05-11 05:18:25,791 [INFO] Skip OpenAI: False
2025-05-11 05:18:25,791 [INFO] ================================================================================
2025-05-11 05:18:25,791 [INFO] Starting experiment
2025-05-11 05:18:25,791 [INFO] Running command: python run_experiments.py --model_name meta-llama/Llama-3.1-8B-Instruct --device cpu --datasets gsm8k --num_samples 3 --output_dir experiment_results --use_openai True
Traceback (most recent call last):
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_buildingtrust/claude_code/run_experiments.py", line 19, in <module>
    from experiments.experiment_runner import ExperimentRunner
  File "/home/chenhui/mlr-bench/pipeline_gemini/iclr2025_buildingtrust/claude_code/experiments/experiment_runner.py", line 18, in <module>
    from ..models.llm_state_extractor import LLMStateExtractor
ImportError: attempted relative import beyond top-level package
2025-05-11 05:18:28,170 [ERROR] Experiment failed with return code 1
2025-05-11 05:18:28,170 [ERROR] Experiment failed, aborting pipeline
