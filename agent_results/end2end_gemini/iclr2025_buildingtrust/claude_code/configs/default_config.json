{
  "models_config": {
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",
    "device": "cuda",
    "layers_to_extract": null,
    "cache_dir": "cache"
  },
  "dataset_config": {
    "datasets": ["gsm8k"],
    "max_samples": 100,
    "train_ratio": 0.7,
    "val_ratio": 0.15,
    "test_ratio": 0.15,
    "cache_dir": "cache/datasets",
    "test_splits": ["test"]
  },
  "experiment_config": {
    "num_samples_per_dataset": 10,
    "use_openai": true,
    "openai_model": "gpt-4o-mini",
    "seed": 42,
    "generation": {
      "max_new_tokens": 200,
      "temperature": 0.7,
      "do_sample": true,
      "top_p": 0.9
    },
    "concept_mapping": {
      "num_concepts": 10,
      "pca_components": 50,
      "umap_components": 2,
      "clustering_method": "kmeans",
      "min_edge_weight": 0.1,
      "graph_layout": "temporal"
    }
  }
}