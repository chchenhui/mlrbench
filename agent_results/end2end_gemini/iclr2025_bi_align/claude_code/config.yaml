# Configuration file for the AI Cognitive Tutor experiment

# Experiment settings
experiment:
  name: ai_cognitive_tutor_experiment
  random_seed: 42
  num_trials: 50  # Number of diagnostic trials per participant
  num_simulated_participants: 60  # 30 per group (control and treatment)
  save_path: "./experiment_results"
  log_file: "./experiment_results/experiment.log"

# AI Diagnostic System settings
ai_diagnostic:
  model_type: "medical_diagnosis"
  accuracy: 0.85  # Base accuracy of the AI diagnostic system
  uncertainty_levels: 3  # Number of uncertainty levels (low, medium, high)
  explanation_types:
    - "feature_importance"  # LIME/SHAP style explanations
    - "confidence_score"    # Confidence score for the diagnosis
    - "uncertainty_estimate"  # Uncertainty estimate

# Participant settings
participants:
  expertise_levels:
    - "novice"
    - "intermediate"
    - "expert"
  expertise_distribution: [0.3, 0.4, 0.3]  # 30% novice, 40% intermediate, 30% expert

# Misunderstanding triggers
triggers:
  repeated_queries: True        # User repeatedly queries the same information
  inconsistent_actions: True    # User actions inconsistent with AI recommendation
  ignoring_uncertainty: True    # User ignores high uncertainty warnings
  confusion_signals: True       # User explicitly expresses confusion
  prolonged_hesitation: True    # User hesitates for an extended period

# AI Cognitive Tutor settings
tutor:
  enabled: True                  # Whether the tutor is enabled (for treatment group)
  activation_threshold: 0.7      # Threshold for activating the tutor
  strategies:
    simplified_explanation: True  # Simplified explanation of AI reasoning
    analogies: True               # Analogies to familiar concepts
    interactive_qa: True          # Interactive Q&A
    visualizations: True          # Visualizations of data and reasoning
    micro_learning: True          # Micro-learning snippets
    contrastive_explanation: True # Contrastive explanations

# Baseline methods for comparison
baselines:
  standard_explanation: True     # Standard AI explanation without tutor
  no_explanation: True           # No explanation (just diagnosis)
  static_tutorial: True          # Static tutorial about AI before interaction

# Evaluation metrics
evaluation:
  mental_model_accuracy: True     # Accuracy of user's mental model
  diagnostic_performance: True    # Performance on diagnostic tasks
  appropriate_reliance: True      # Appropriate reliance on AI
  user_ai_misalignment: True      # Frequency of misalignment incidents
  cognitive_load: True            # Cognitive load during tasks
  trust_calibration: True         # Correlation between trust and AI reliability
  tutor_effectiveness: True       # Effectiveness of the tutor interventions