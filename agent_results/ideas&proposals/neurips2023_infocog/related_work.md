**Related Papers:**

1. **Title**: Policy Learning with a Language Bottleneck (arXiv:2405.04118)
   - **Authors**: Megha Srivastava, Cedric Colas, Dorsa Sadigh, Jacob Andreas
   - **Summary**: This paper introduces the Policy Learning with a Language Bottleneck (PLLB) framework, enabling AI agents to generate linguistic rules that capture the strategies underlying their most rewarding behaviors. By alternating between rule generation guided by language models and policy updates informed by these rules, PLLB agents learn interpretable and generalizable behaviors, enhancing human-AI coordination.
   - **Year**: 2024

2. **Title**: Bridging the Sim-to-Real Gap from the Information Bottleneck Perspective (arXiv:2305.18464)
   - **Authors**: Haoran He, Peilin Wu, Chenjia Bai, Hang Lai, Lingxiao Wang, Ling Pan, Xiaolin Hu, Weinan Zhang
   - **Summary**: This study formulates the sim-to-real gap as an information bottleneck problem and proposes the Historical Information Bottleneck (HIB) method. HIB learns privileged knowledge representations from historical trajectories, capturing dynamic information to reduce value discrepancies between oracle and learned policies, thereby improving generalizability in real-world tasks.
   - **Year**: 2023

3. **Title**: Justices for Information Bottleneck Theory (arXiv:2305.11387)
   - **Authors**: Faxian Cao, Yongqiang Cheng, Adil Mehmood Khan, Zhijing Yang
   - **Summary**: This paper addresses criticisms of the information bottleneck (IB) theory by introducing an auxiliary function that reinterprets the maximal coding rate reduction method as a special case of IB theory. It clarifies misconceptions about mutual information in deep learning networks and demonstrates IB theory's applicability in explaining the absence of a compression phase with linear activation functions.
   - **Year**: 2023

4. **Title**: Multimodal Information Bottleneck for Deep Reinforcement Learning with Multiple Sensors (arXiv:2410.17551)
   - **Authors**: Bang You, Huaping Liu
   - **Summary**: The authors propose a multimodal information bottleneck model to learn task-relevant joint representations from egocentric images and proprioception. By compressing and retaining predictive information, the model fuses complementary sensory inputs while filtering out irrelevant data, leading to improved sample efficiency and robustness in locomotion tasks.
   - **Year**: 2024

5. **Title**: Learning to Influence Human Behavior with Offline Reinforcement Learning (arXiv:2303.02265)
   - **Authors**: Joey Hong, Sergey Levine, Anca Dragan
   - **Summary**: This research explores how offline reinforcement learning can be utilized to influence suboptimal human behavior. By learning from datasets of human-human interactions, the agent develops strategies to steer humans toward better performance, even on new tasks, without assuming near-optimal human behavior.
   - **Year**: 2023

6. **Title**: Overconfident and Unconfident AI Hinder Human-AI Collaboration (arXiv:2402.07632)
   - **Authors**: Jingshu Li, Yitian Yang, Renwen Zhang, Yi-chieh Lee
   - **Summary**: The study examines the effects of uncalibrated AI confidence on human-AI collaboration. It finds that both overconfident and underconfident AI can lead to misuse or disuse, respectively, hindering collaboration outcomes. The paper emphasizes the importance of AI confidence calibration to enhance collaboration.
   - **Year**: 2024

7. **Title**: Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge (arXiv:2411.01796)
   - **Authors**: Weihua Du, Qiushi Lyu, Jiaming Shan, Zhenting Qi, Hongxin Zhang, Sunli Chen, Andi Peng, Tianmin Shu, Kwonjoon Lee, Behzad Dariush, Chuang Gan
   - **Summary**: This paper introduces the Constrained Human-AI Cooperation (CHAIC) challenge, designed to test social perception and cooperation in embodied agents. The challenge involves assisting humans with physical constraints in performing tasks efficiently, requiring agents to infer human intents and constraints and to plan cooperatively.
   - **Year**: 2024

8. **Title**: Representation Learning in Deep RL via Discrete Information Bottleneck
   - **Authors**: Riashat Islam, Hongyu Zang, Manan Tomar, Aniket Didolkar, Md Mofijul Islam, Samin Yeasar Arnob, Tariq Iqbal, Xin Li, Anirudh Goyal, Nicolas Heess, Alex Lamb
   - **Summary**: The authors propose architectures utilizing variational and discrete information bottleneck methods to learn structured, factorized representations in reinforcement learning. By integrating these bottlenecks with self-supervised objectives, the approach improves performance by predicting relevant states while ignoring irrelevant information.
   - **Year**: 2023

9. **Title**: Learning Efficient Multi-agent Communication: An Information Bottleneck Approach
   - **Authors**: Rundong Wang, Xu He, Runsheng Yu, Wei Qiu, Bo An, Zinovi Rabinovich
   - **Summary**: This paper develops the Informative Multi-Agent Communication (IMAC) method, which learns efficient communication protocols and scheduling under limited bandwidth constraints. By applying the information bottleneck principle, IMAC generates low-entropy, informative messages, leading to faster convergence and efficient communication among agents.
   - **Year**: 2020

10. **Title**: Towards Human-Agent Communication via the Information Bottleneck Principle (arXiv:2207.00088)
    - **Authors**: Mycal Tucker, Julie Shah, Roger Levy, Noga Zaslavsky
    - **Summary**: This work studies emergent communication by optimizing the trade-off between utility, informativeness, and complexity, inspired by the Information Bottleneck principle. The proposed Vector-Quantized Variational Information Bottleneck (VQ-VIB) method trains neural agents to compress inputs into discrete signals, leading to human-like lexicon sizes and improved communication convergence rates.
    - **Year**: 2022

**Key Challenges:**

1. **Balancing Informativeness and Complexity**: Achieving an optimal trade-off between providing sufficient information for task performance and minimizing communication complexity remains a significant challenge.

2. **Human Cognitive Limitations**: Designing AI communication strategies that align with human cognitive capacities to prevent information overload or misunderstandings is complex.

3. **Generalization Across Tasks**: Developing communication policies that generalize effectively across diverse cooperative tasks and environments is difficult.

4. **Real-Time Adaptation**: Ensuring that AI agents can adapt their communication strategies in real-time to dynamic human behaviors and changing task requirements poses a challenge.

5. **Evaluation Metrics**: Establishing standardized metrics to evaluate the efficiency and effectiveness of human-AI communication strategies is essential yet challenging. 