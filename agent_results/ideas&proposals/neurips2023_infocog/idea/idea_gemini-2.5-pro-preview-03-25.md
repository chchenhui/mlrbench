**Title:** Information Bottleneck for Efficient Human-AI Communication in Cooperative Tasks

**Motivation:** Effective human-AI collaboration hinges on efficient communication. Agents often overwhelm humans with excessive or irrelevant information, while overly compressing information can lead to critical misunderstandings. Information theory, specifically the Information Bottleneck (IB) principle, offers a framework to optimize the trade-off between communicative expressiveness and complexity.

**Main Idea:** We propose applying the IB principle to train AI agents for cooperative tasks involving communication with humans. The agent's internal state (representing its understanding of the task and environment) acts as the source variable. The communication signal sent to the human is the compressed representation. The objective is to learn a communication policy (a stochastic mapping from state to signal) that maximizes mutual information between the signal and the task-relevant aspects of the agent's state (e.g., goal, plan, perceived obstacles), while minimizing the mutual information between the signal and the full internal state (constraining communication cost/complexity). This will be implemented using deep variational IB methods within a reinforcement learning loop, aiming for agents that learn concise yet informative communication strategies tailored to human cognitive limits, improving joint task performance and user experience.