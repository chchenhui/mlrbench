Title: Hierarchical Information Bottleneck for Human-Aligned Agents

Motivation:  
As AI systems increasingly collaborate with humans, their internal representations often encode task-irrelevant details that hinder interpretability, alignment, and trust. A principled, information-theoretic compression can distill only the human-relevant features, streamlining communication and improving cooperative performance.

Main Idea:  
We introduce a Hierarchical Variational Information Bottleneck (HVIB) that compresses an agent’s raw inputs X into a stack of latent codes z₁,…,zₙ, each optimized to preserve only the information most predictive of human feedback Y_h. At layer i we minimize  
 Lᵢ = βᵢ I(zᵢ;X) − I(zᵢ;Y_h∣z_{<i})  
using neural mutual-information estimators (e.g., MINE or variational bounds). Early layers capture coarse, high-level cues; deeper layers refine nuances critical to human collaborators. By pruning redundant or private features, HVIB yields intermediate representations that are both compact and interpretable. We will validate this framework on cooperative navigation and language‐grounded dialogue tasks, measuring alignment accuracy, task success, and human judgments of transparency. This approach offers a systematic, information-theoretic recipe for building AI agents that communicate and cooperate more effectively with people.