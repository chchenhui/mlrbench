**Title:** Cross-Domain Failure Taxonomy for Real-World Deep Learning Deployments  

**Motivation:** Deep learning (DL) failures in real-world applications often stem from recurring, domain-agnostic issues (e.g., distribution shifts, ethical misalignment), but these remain siloed within specific fields. A unified understanding of cross-cutting failure modes is critical to generalize solutions, yet no systematic framework exists to categorize and compare failures across domains.  

**Main Idea:** Develop a hierarchical, cross-domain taxonomy of DL deployment failures by analyzing case studies from the ICBINB workshop submissions. Using qualitative coding and clustering, failures will be categorized by *root cause* (data, model, deployment), *manifestation* (e.g., safety violations, performance drops), and *domain-specific context*. For example, label noise in medical imaging and sensor drift in autonomous vehicles both map to "data distribution shifts" but require distinct mitigation strategies. The taxonomy will be validated via iterative feedback from domain experts and tested by annotating historical failure cases from published literature. Expected outcomes include: (1) a publicly accessible failure database with tags from the taxonomy, (2) guidelines for translating mitigation strategies across domains (e.g., adapting robotics robustness checks for healthcare models), and (3) identification of understudied failure modes (e.g., human-AI interaction bottlenecks). This work will enable practitioners to anticipate risks and prioritize research on universal DL weaknesses.