**Title:** TrustGuard EHR: Adversarial Benchmarking of GenAI Reliability for Clinical Note Synthesis

**Motivation:** Generative AI promises to alleviate clinician burnout by automating clinical note generation. However, subtle inaccuracies or hallucinations introduced by GenAI could lead to misdiagnosis or treatment errors. Standard benchmarks often fail to capture the safety-critical nuances of clinical settings. This research aims to create a robust benchmark specifically designed to test the reliability and factual consistency of GenAI-synthesized clinical notes against adversarial scenarios reflecting real-world complexities.

**Main Idea:** We propose developing "TrustGuard EHR," a benchmark comprising: 1) A curated dataset of diverse patient electronic health records (EHRs). 2) An adversarial perturbation engine that introduces clinically plausible but challenging variations (e.g., contradicting information, subtle symptom changes, rare conditions) into source EHR data. 3) A suite of automated evaluation metrics focusing on factual consistency (semantic similarity to ground truth, contradiction detection, entity extraction verification) and clinical relevance (assessment by expert clinicians). This benchmark will allow rigorous testing of different GenAI models' reliability in generating accurate clinical notes under challenging, realistic conditions, thereby guiding the development of safer GenAI for healthcare documentation.