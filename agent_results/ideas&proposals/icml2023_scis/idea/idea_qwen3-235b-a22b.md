### Title  
**Automated Discovery and Mitigation of Spurious Correlations via Causal Invariance Testing**

### Motivation  
Spurious correlations between inputs and labels degrade model fairness, robustness, and out-of-distribution (OOD) generalization. While methods exist to address these issues, they often require manual identification of spurious features or strong causal assumptions. Automated tools for <em>discovering</em> and <em>correcting</em> such correlations—especially in high-dimensional data like medical imaging or genomics—are critical for scalable, reliable deployment across domains like healthcare and NLP.

### Main Idea  
This work proposes **Causal Invariance Testing (CIT)**, a pipeline that combines probabilistic causal discovery with adversarial robustness to automatically identify and penalize spurious features. First, CIT uses score-based causal discovery to learn a causal graph from input features and predictions, flagging features with unstable causal relationships (e.g., scanner-type in radiology) across subgroups or domains. Second, it trains a model with a **causal invariance loss**, which enforces consistency in predictions when spurious feature values are perturbed synthetically (e.g., swapping ancestry markers in polygenic scores via generative models). The approach integrates domain-invariant representation learning and counterfactual data augmentation, validated on benchmarks probing OOD stability and fairness. Expected outcomes include actionable insights into spurious dependencies, domain-agnostic performance improvements (e.g., ≥15% accuracy gains on shifted radiology/X-ray datasets), and reliable generalization to underrepresented populations in genomic risk prediction. Impact spans high-stakes ML applications where spurious correlations pose ethical and practical risks.