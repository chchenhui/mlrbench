**Title:** Harnessing Structured Knowledge Graphs for Efficient Continual Learning in Foundation Models  

**Motivation:**  
Continual learning (CL) in foundation models (FMs) faces critical challenges: catastrophic forgetting, resource-intensive retraining, and poor adaptation to domain shifts. Existing methods struggle to balance plasticity and stability while scaling. Structured knowledge sources (e.g., knowledge graphs) offer external, persistent memory that could decouple knowledge acquisition from model parameters, enabling efficient updates without retraining. Integrating such structures could mitigate forgetting, contextualize new data, and reduce computational overhead, enabling FMs to evolve dynamically in real-world applications like healthcare or legal systems.  

**Main Idea:**  
We propose **Knowledge-Guided Continual Learning (KG-CL)**: augment FMs with a dynamic knowledge graph interface that stores and retrieves task-specific semantic structures. During CL, the model updates the graph via retrieval-augmented learning—new data is encoded into graph nodes/edges using lightweight adapters, while preserved knowledge remains static. Graph neural networks (GNNs) then propagate updates, aligning the FM’s representations with the evolving graph. Training alternates between: (1) freezing FM weights to update the graph via contrastive learning, and (2) finetuning shallow GNN layers for downstream tasks. This minimizes parameter updates while retaining historical knowledge.  

We expect KG-CL to outperform baselines in accuracy and efficiency on long-tail, domain-shift datasets (e.g., Wikidata, clinical records). Evaluation will focus on catastrophic forgetting metrics (e.g., backward transfer) and scalability (compute/memory cost vs. full retraining). Successful integration could enable “prompt-free” updates—new knowledge is injected via graph edits—dramatically reducing carbon footprint and costs. This work bridges structured knowledge and continual learning, offering a pathway to sustainable, real-world FMs.