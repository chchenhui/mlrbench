**Title:** Principled Design of Auxiliary Tasks via Information Disentanglement in SSL

**Motivation:** Existing self-supervised auxiliary tasks (e.g., contrastive learning, masked prediction) are largely designed heuristically, lacking a clear theoretical link to *why* they yield good representations. Understanding this link is crucial for designing better tasks, especially for complex data or specific downstream requirements like robustness or fairness.

**Main Idea:** We propose a theory-driven framework for designing auxiliary tasks based on information disentanglement. The core idea is that effective representations should separate "invariant" information shared across augmented views from "variant" information specific to each view. We will formalize this using mutual information objectives: maximizing the mutual information between representations of different views (capturing invariants) while simultaneously minimizing the mutual information between a view's representation and view-specific nuisance variables (disentangling variants). We will instantiate this principle to derive novel contrastive and non-contrastive loss functions. These theoretically grounded tasks will be evaluated against state-of-the-art heuristic tasks on benchmarks assessing transferability, robustness to perturbations, and representation quality (e.g., linear probing, downstream fine-tuning). Success would provide a principled way to design tailored auxiliary tasks.