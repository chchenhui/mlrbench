**Title:** Planning via Persuasion: Reinforcement Learning in Adversarial Language Games

**Motivation:** Large Language Models (LLMs) exhibit limitations in complex, multi-step planning and reasoning, partially attributed to their training on static datasets lacking interactive grounding. Language games provide a dynamic environment to cultivate these abilities through goal-oriented interaction, as suggested by the workshop's focus on interactive finetuning.

**Main Idea:** This research proposes training LLMs using Deep Reinforcement Learning (DRL) within an adversarial "Persuasion Game." In this setup, one LLM agent (the Planner) must formulate a multi-step plan and persuade another LLM agent (the Skeptic) of its feasibility and correctness through interactive dialogue. The Planner receives rewards based on successfully convincing the Skeptic, who is incentivized to find flaws or demand justifications. This interactive RL loop forces the Planner to develop robust planning, justification, and reasoning skills grounded in adversarial interaction, going beyond passive imitation learning. We expect this approach to significantly enhance LLMs' planning capabilities and logical coherence.