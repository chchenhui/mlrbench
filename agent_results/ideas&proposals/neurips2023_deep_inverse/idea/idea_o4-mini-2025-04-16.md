Title: Uncertainty-Aware Diffusion Inversion via Bayesian Forward Surrogates

Motivation:  
Real-world inverse problems often lack accurate or complete forward models, causing diffusion-based solvers—which assume perfect physics—to produce biased or unstable reconstructions. Integrating quantified model uncertainty into learned priors is essential for trustworthy imaging in medicine, geophysics, and beyond.

Main Idea:  
We introduce a two-stage framework. First, train a Bayesian neural surrogate pϕ(y|x) on limited calibration data to capture both mean predictions and epistemic uncertainty of the forward operator. Second, embed this surrogate into score-based diffusion sampling by replacing the fixed data-consistency term with an expected log-likelihood gradient ∇ₓE_{pϕ}[log pϕ(y|x)], approximated via Monte Carlo draws from the surrogate’s posterior. This yields reconstructions that honor measured data within the surrogate’s confidence bounds while leveraging powerful diffusion priors. We will validate on sparse-view CT and multi-coil MRI with unknown geometry, expecting enhanced robustness to model mismatch and quantified error guarantees. This approach generalizes to any inverse problem with partial forward knowledge, enabling reliable, uncertainty-aware deep reconstruction.