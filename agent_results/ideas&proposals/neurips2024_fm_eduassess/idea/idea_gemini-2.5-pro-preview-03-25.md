**Title:** CHAIN-OF-RUBRIC: Enhancing LFM Explainability for Automated Scoring via Rubric Grounding

**Motivation:** Large Foundation Models (LFMs) show promise for automated scoring, but their black-box nature hinders adoption in education due to lack of explainability and trust. Stakeholders (educators, students, policymakers) need transparent justifications for assigned scores, aligned with established assessment rubrics.

**Main Idea:** We propose CHAIN-OF-RUBRIC, a fine-tuning and prompting strategy to make LFM-based scoring explainable. Instead of just outputting a score, the LFM will be trained to generate a step-by-step reasoning process explicitly grounded in the specific criteria of the provided scoring rubric. Given a student response and a rubric, the model will output: 1) the final score, and 2) a textual explanation highlighting which specific rubric criteria were met/unmet, citing evidence from the student's response. This involves fine-tuning LFMs on datasets pairing responses with expert scores and rubric-based feedback chains. Expected outcomes are significantly improved score transparency and actionable, diagnostic feedback for learners, increasing stakeholder trust in AI-driven assessment.