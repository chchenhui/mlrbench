**Title:** Hybrid Authenticity Verification for Student Assignments via Multimodal Generative AI Analysis  

**Motivation:** The rise of generative AI in education has intensified concerns about academic integrity, as current detection tools often yield unreliable results, leading to unfair accusations or undetected cheating. A robust solution is needed to validate assignment authenticity while respecting student privacy and fostering trust.  

**Main Idea:** This research proposes a hybrid framework combining text-based AI detection with behavioral process analysis. The methodology integrates two streams: (1) *Content analysis* using fine-tuned LLMs to detect stylistic inconsistencies and AI-generated text patterns, and (2) *Behavioral metadata analysis* leveraging keystroke dynamics, edit histories, and time-spent data captured during assignment creation. A multimodal model processes these inputs, correlating writing process patterns (e.g., revision frequency, pause intervals) with final text features. Datasets of student-written and AI-generated assignments, paired with behavioral logs, will train the model to distinguish authentic work. The system would integrate with learning platforms via APIs, providing educators with interpretable "authenticity likelihood" scores and flagged anomalies. Expected outcomes include reduced false positives compared to text-only detectors and actionable insights for educators. If successful, this approach could restore confidence in assessments while guiding ethical AI use in education.