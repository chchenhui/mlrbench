Title: SE(3)-Equivariant Variational World Models for Sample-Efficient Robotic Control

Motivation:  
Robotic manipulation in unstructured environments demands models that generalize across object positions and orientations. Embedding the underlying SE(3) symmetry into world models can dramatically improve sample efficiency, robustness to novel poses, and consistency under spatial transformations.

Main Idea:  
We propose a variational world model whose encoder, transition, and decoder are all SE(3)-equivariant. The encoder processes multi-view RGB-D observations through tensor-field network layers to extract symmetry-preserving latent features. The latent dynamics are modeled with an equivariant graph neural network that propagates interactions under rigid-body group actions. A corresponding equivariant decoder reconstructs future observations and predicts task-relevant metrics (e.g., object grasp success). Training uses a combination of ELBO, contrastive future prediction, and symmetry-consistency losses. We will evaluate on manipulation benchmarks (block stacking, peg insertion) with randomized object poses. We expect faster convergence, reliable zero-shot generalization to unseen orientations, and insights into how group-structured latent spaces mirror neural coding in motor circuits.