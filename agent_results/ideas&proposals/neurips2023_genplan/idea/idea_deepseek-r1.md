**Title:** Neuro-Symbolic Hierarchical Planning with Meta-Learned Sub-Policies for Cross-Domain Generalization  

**Motivation:** Current AI systems struggle with long-horizon, cross-domain sequential decision-making due to the separation between data-driven RL (sample-inefficient but adaptive) and symbolic planning (generalizable but rigid). Bridging this gap is critical for real-world applications like robotics, where agents must adapt learned skills to unseen tasks with minimal data.  

**Main Idea:** This work proposes a hybrid neuro-symbolic framework where a symbolic planner generates abstract task hierarchies using meta-learned neural sub-policies. The symbolic layer defines reusable high-level action schemas (e.g., "navigate," "manipulate") grounded in PDDL, enabling cross-domain transfer. Neural sub-policies, trained via meta-reinforcement learning on diverse environments, embed adaptability into low-level execution. During deployment, the symbolic planner composes these sub-policies into task-specific plans, while a formal verification module ensures constraint satisfaction. Key innovations include: (1) bi-level optimization for aligning symbolic abstractions with sub-policy capabilities, (2) contrastive meta-learning to disentangle task-invariant and task-specific policy components, and (3) neuro-symbolic plan repair using LLM-guided refinement. Expected outcomes include improved zero-shot generalization in ProcTHOR-like environments and sample-efficient policy adaptation, validated through cross-domain robotics benchmarks. Impact: Unifies planning and RL communities, advancing deployable AI systems that generalize across tasks with minimal retraining.