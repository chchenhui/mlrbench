# Self-Supervised Contrastive Learning for Missing Value Imputation in ICU Time Series

## Motivation
Intensive Care Units (ICU) generate vast amounts of multivariate time series data critical for patient monitoring and clinical decision-making. However, these datasets frequently contain missing values due to irregular sampling, sensor failures, or patient-specific care protocols. Current imputation methods often fail to capture the complex temporal dependencies and clinical contexts unique to critical care settings. This research addresses the challenge of handling missing values in high-dimensional ICU time series data while preserving the clinical validity of the imputed values for downstream tasks like mortality prediction or intervention timing.

## Main Idea
We propose a self-supervised contrastive learning framework that learns robust representations of ICU time series while simultaneously addressing missing value imputation. Our approach combines a transformer-based architecture with a novel contrastive learning objective that leverages the inherent temporal structure of ICU data. By masking random segments of multivariate time series and training the model to distinguish between true and synthetically generated continuations, the framework learns clinically valid temporal patterns without requiring complete data. The method incorporates clinical domain constraints as regularization terms, ensuring physiologically plausible imputations. We evaluate on MIMIC-IV and eICU databases, focusing on how representation quality impacts downstream clinical tasks. The framework explicitly addresses the unique challenges of pediatric ICU data, where reference ranges and physiological dynamics differ significantly from adult populations.