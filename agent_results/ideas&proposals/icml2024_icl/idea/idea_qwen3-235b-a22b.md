**Title**: Bridging In-Context Learning and Automated Machine Learning via Dynamic Prompt Adaptation  

**Motivation**: While in-context learning (ICL) enables rapid task adaptation without parameter updates, it lacks long-term generalization. Conversely, AutoML automates model design for sustained performance but requires costly retraining. Bridging these paradigms could create systems that adapt instantly *and* refine strategies over time, addressing inefficiencies in dynamic environments where rapid responses and evolving accuracy are critical (e.g., real-time robotics or healthcare diagnostics).  

**Main Idea**: Propose a hybrid framework, *MetaPrompter*, that integrates ICL with AutoML. The system alternates between: (1) ICL-based inference, where few-shot prompts guide a frozen LLM; and (2) a meta-controller trained via reinforcement learning (RL) to optimize prompt templates and task representations using feedback from ICL performance. During deployment, the meta-controller dynamically updates prompts in batches, refining ICLâ€™s context to reduce errors over time. Methodologically, we analyze how task metadata (e.g., input complexity) influences the optimal balance between ICL and meta-learning. Evaluation will compare dynamic vs. static prompt adaptation on diverse tasks (e.g., mathematical reasoning, sequential decision-making). Expected outcomes include improved robustness to distribution shifts and reduced manual engineering. Impact-wise, this work advances "continual in-context learning" by merging the agility of ICL with the longevity of AutoML, enabling deployable models for volatile domains.