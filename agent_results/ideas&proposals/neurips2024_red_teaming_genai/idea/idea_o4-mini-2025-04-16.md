Title: Adaptive Adversarial Prompt Curriculum for Continual Red Teaming  

Motivation: Static red-teaming benchmarks quickly become outdated as generative models evolve and adversaries discover new exploits. A dynamic, self-updating framework is needed to continuously surface emerging vulnerabilities, reduce manual curation, and prevent overfitting to known test sets.  

Main Idea: We propose a closed-loop “prompt curriculum” that iteratively generates, evaluates, and refines adversarial attacks against a target GenAI model.  
1. Adversary Generator: A small transformer is meta-fine-tuned on past successful jailbreak or misuse prompts.  
2. Evaluation & Filtering: Candidate prompts are executed on the target model; those that induce safety, privacy, or truthfulness failures are retained.  
3. Diversity Clustering: Retained prompts are clustered by semantic and failure-mode similarity to maximize coverage of distinct risks.  
4. Curriculum Update: Clusters feed back to retrain the generator, biasing it toward underexplored attack classes.  

Expected Outcomes: A continuously growing, high-coverage adversarial benchmark that adapts to model updates without manual intervention.  
Potential Impact: Scalable red teaming that anticipates new classes of harmful behavior, enabling proactive hardening and more trustworthy generative AI systems.