Title: Compositional Continual Learning with Modular Prototype Replay

Motivation:  
Continual learning of compositional skills faces two intertwined challenges: catastrophic forgetting of learned primitives and poor generalization to novel compositions. Addressing these is critical for deploying agents in dynamic environments where they must reuse and recombine past knowledge without retraining from scratch.

Main Idea:  
We propose a modular continual learning framework that (1) represents each learned primitive as a lightweight adapter module, (2) maintains a prototype memory bank of activation patterns for each module, and (3) employs a gating network to dynamically select and assemble adapters for incoming tasks. When a new task arrives, relevant modules are retrieved and composed; simultaneously, prototype replay—sampling stored activations—reinforces old primitives and their interactions. A consolidation loss aligns updated adapter weights with their prototypes to reduce drift. We will evaluate on sequential compositional benchmarks (e.g., SCAN, CLEVR variations) measuring both backward retention and forward composition accuracy. Expected outcomes include robust retention of primitive skills, enhanced zero- and few-shot generalization to unseen compositions, and minimal parameter growth. This method paves the way for adaptive agents that continuously build complex capabilities from reusable building blocks.