1. **Title**: InvisMark: Invisible and Robust Watermarking for AI-generated Image Provenance (arXiv:2411.07795)
   - **Authors**: Rui Xu, Mengya Hu, Deren Lei, Yaxi Li, David Lowe, Alex Gorevski, Mingyu Wang, Emily Ching, Alex Deng
   - **Summary**: InvisMark introduces a watermarking technique for high-resolution AI-generated images, embedding imperceptible yet robust watermarks. It achieves high imperceptibility (PSNR ~51, SSIM ~0.998) and maintains over 97% bit accuracy across various image manipulations, including encoding 256-bit watermarks for enhanced payload capacity.
   - **Year**: 2024

2. **Title**: Provable Robust Watermarking for AI-Generated Text (arXiv:2306.17439)
   - **Authors**: Xuandong Zhao, Prabhanjan Ananth, Lei Li, Yu-Xiang Wang
   - **Summary**: This paper presents Unigram-Watermark, a method for embedding watermarks into text generated by large language models. It ensures generation quality, correct watermark detection, and robustness against text editing and paraphrasing, verified through experiments on multiple LLMs and datasets.
   - **Year**: 2023

3. **Title**: Spread them Apart: Towards Robust Watermarking of Generated Content (arXiv:2502.07845)
   - **Authors**: Mikhail Pautov, Danil Ivanov, Andrey V. Galichin, Oleg Rogov, Ivan Oseledets
   - **Summary**: The authors propose a method to embed watermarks into generated content during inference, eliminating the need for model retraining. The approach guarantees robustness against additive perturbations and matches state-of-the-art schemes in resisting various synthetic watermark removal attacks.
   - **Year**: 2025

4. **Title**: REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models (arXiv:2310.12362)
   - **Authors**: Ruisi Zhang, Shehzeen Samarah Hussain, Paarth Neekhara, Farinaz Koushanfar
   - **Summary**: REMARK-LLM introduces a watermarking framework for texts generated by large language models, featuring a learning-based message encoding module, a reparameterization module, and a decoding module. It effectively embeds binary signatures while preserving semantic integrity and demonstrates resilience against various watermark detection and removal attacks.
   - **Year**: 2023

5. **Title**: Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge (arXiv:2503.04036)
   - **Authors**: Xinyue Cui, Johnny Tian-Zheng Wei, Swabha Swayamdipta, Robin Jia
   - **Summary**: This work proposes a data watermarking approach that injects coherent yet fictitious knowledge into training data, creating watermarks that are memorized by language models. These watermarks are robust throughout the model development pipeline and can be evaluated even under API-only access via question answering.
   - **Year**: 2025

6. **Title**: Certifiably Robust Image Watermark (arXiv:2407.04086)
   - **Authors**: Zhengyuan Jiang, Moyang Guo, Yuepeng Hu, Jinyuan Jia, Neil Zhenqiang Gong
   - **Summary**: The authors propose the first image watermarks with certified robustness guarantees against removal and forgery attacks, leveraging randomized smoothing techniques. The method is extensively evaluated for both certified and empirical robustness.
   - **Year**: 2024

7. **Title**: Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances (arXiv:2410.18775)
   - **Authors**: Shilin Lu, Zihan Zhou, Jiayou Lu, Yuanzhi Zhu, Adams Wai-Kin Kong
   - **Summary**: This paper introduces W-Bench, a benchmark to evaluate watermarking methods against image editing techniques. The authors propose VINE, a watermarking method that enhances robustness against various image editing techniques while maintaining high image quality, leveraging frequency characteristics analysis and a pretrained diffusion model.
   - **Year**: 2024

8. **Title**: Elevating Defenses: Bridging Adversarial Training and Watermarking for Model Resilience (arXiv:2312.14260)
   - **Authors**: Janvi Thakkar, Giulio Zizzo, Sergio Maffeis
   - **Summary**: The authors introduce a framework integrating adversarial training with watermarking techniques to enhance model resilience against evasion attacks and ensure confident model verification. The approach uses adversarial training with adversarial watermarks, evaluated on MNIST and Fashion-MNIST datasets.
   - **Year**: 2023

9. **Title**: Provably Robust Multi-bit Watermarking for AI-generated Text (arXiv:2401.16820)
   - **Authors**: Wenjie Qu, Wengrui Zheng, Tianyang Tao, Dong Yin, Yanze Jiang, Zhihua Tian, Wei Zou, Jinyuan Jia, Jiaheng Zhang
   - **Summary**: This work introduces a watermarking method for AI-generated text based on pseudo-random segment assignment, embedding multi-bit messages. The method demonstrates substantial improvements over existing baselines in accuracy and robustness, tolerating edits within an average edit distance of 17 per paragraph.
   - **Year**: 2024

10. **Title**: Robust Distortion-free Watermarks for Language Models (arXiv:2307.15593)
    - **Authors**: Rohith Kuditipudi, John Thickstun, Tatsunori Hashimoto, Percy Liang
    - **Summary**: The authors propose a methodology for embedding watermarks in text generated by autoregressive language models that are robust to perturbations without altering the distribution over text. The approach is validated on multiple language models, demonstrating reliable detection even after significant token corruption.
    - **Year**: 2023

**Key Challenges:**

1. **Adversarial Robustness**: Ensuring that watermarks remain detectable under various adversarial attacks, such as noise addition, cropping, or inpainting, is a significant challenge.

2. **Imperceptibility vs. Robustness Trade-off**: Balancing the imperceptibility of watermarks with their robustness against attacks often involves trade-offs that are difficult to optimize.

3. **Scalability**: Developing watermarking methods that can efficiently handle large-scale AI-generated content without compromising performance is essential.

4. **Generalization to Unseen Attacks**: Creating watermarks that can withstand novel and unforeseen attack strategies remains a complex task.

5. **Evaluation Metrics**: Establishing standardized benchmarks and metrics to assess the effectiveness and robustness of watermarking techniques is crucial for consistent evaluation. 