**Title:** Fairness-Aware Active Learning under Data Scarcity

**Motivation:** Acquiring high-quality labeled data is expensive, leading to limited datasets, especially for underrepresented subgroups. Standard models trained on such data often exhibit biases, violating fairness principles. This research aims to develop techniques that mitigate fairness issues proactively during data acquisition when labeled data is scarce.

**Main Idea:** We propose a novel active learning framework that explicitly incorporates fairness metrics into the data point selection strategy. Instead of solely prioritizing points that maximize overall model accuracy or reduce uncertainty, our method will select points that yield the largest improvement in fairness metrics (e.g., demographic parity, equalized odds) across sensitive groups, while still maintaining competitive model performance. This involves developing new acquisition functions that balance uncertainty, representativeness, and fairness criteria. We will evaluate this approach on benchmark datasets known for fairness challenges (e.g., COMPAS, Adult), demonstrating improved fairness outcomes compared to standard active learning under identical labeling budgets. The impact lies in enabling the development of fairer ML systems even with severely limited labeled data.