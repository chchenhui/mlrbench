Title: Policy2Constraint – A DSL-Based Compiler for Regulatory ML Compliance

Motivation:  
Translating verbose legal texts into precise, enforceable constraints is a major bottleneck in deploying ML systems that meet regulatory requirements (e.g., GDPR, EU AI Act). Manual interpretation is error-prone, inconsistent, and slows development. Policy2Constraint aims to automate this translation step, reducing risk and accelerating compliant model development.

Main Idea:  
Policy2Constraint uses a two‐stage pipeline. First, an NLP module ingests regulatory documents, segments clauses (rights, obligations, prohibitions) via dependency parsing and modal verb detection, and maps them to a predefined ontology of ML desiderata (fairness, privacy, explainability). Second, a domain-specific language (DSL) compiler converts these ontology mappings into executable code modules: (a) constraint-aware loss functions (e.g., demographic parity, ε-differential privacy), (b) run-time auditors for “right to be forgotten,” and (c) automated tests for explainability (e.g., counterfactual coverage). The DSL outputs native PyTorch/TensorFlow hooks and audit scripts. We will evaluate on case studies—credit scoring under GDPR Articles 13–15 and hiring models under the EU AI Act—measuring translation accuracy, developer effort reduction, and compliance coverage. By standardizing policy-to-code, Policy2Constraint bridges the gap between legal texts and ML practice, enabling faster, safer, and more transparent deployments.