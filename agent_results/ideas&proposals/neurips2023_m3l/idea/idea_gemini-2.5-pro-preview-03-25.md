**Title:** Mechanistic Understanding of In-Context Learning via Implicit Optimization Simulation

**Motivation:** Large language models exhibit In-Context Learning (ICL), learning tasks from prompted examples without gradient updates. The underlying mechanism remains elusive, hindering theoretical progress and principled model improvement. Understanding how transformers perform ICL is crucial for explaining emergent abilities and potentially designing more efficient learners.

**Main Idea:** This research investigates the hypothesis that ICL arises from transformers implicitly simulating a simple optimization algorithm (e.g., ridge regression or one gradient descent step) within their forward pass, using the provided context examples as training data. We propose to: 1) Analyze the attention patterns and intermediate activations of pretrained transformers during ICL tasks to identify computational motifs corresponding to steps of known learning algorithms. 2) Develop minimal theoretical models (e.g., attention-only networks) demonstrating how sequences of attention and MLP operations can perform such implicit optimization. 3) Empirically validate predictions from the theory by intervening on model activations during ICL. The outcome would be a mechanistic theory linking transformer architecture and pretraining to the emergence of ICL, providing insights into scaling laws and emergent computation.