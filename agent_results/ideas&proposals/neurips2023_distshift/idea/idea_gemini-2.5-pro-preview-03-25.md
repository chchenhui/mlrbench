**Title:** Robust Domain Adaptation via Parameter-Efficient Tuning of Foundation Models

**Motivation:** While foundation models exhibit promising performance under distribution shifts, standard fine-tuning often diminishes this robustness when adapting to specialized downstream tasks. Parameter-Efficient Fine-Tuning (PEFT) methods modify only a small subset of parameters, offering a potential avenue to adapt foundation models effectively while preserving the robust representations learned during pretraining. This research aims to understand and enhance the robustness benefits of PEFT under distribution shifts.

**Main Idea:** This research proposes a systematic investigation into the robustness properties of various PEFT methods (e.g., LoRA, Adapters, Prompt Tuning) compared to full fine-tuning on established distribution shift benchmarks (like WILDS). We will analyze how different PEFT strategies affect model representations and performance on both in-distribution and out-of-distribution data. Furthermore, we will develop novel PEFT variants specifically designed for robustness, potentially by incorporating regularization techniques targeting out-of-distribution performance or adaptively selecting which parameters/modules to tune based on shift characteristics. The expected outcome is identifying PEFT methods that best preserve foundation model robustness and providing practical guidelines for robust adaptation.