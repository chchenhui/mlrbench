**Title:** Hybrid Neuro-Symbolic Architecture for System-2 Reasoning in Language Models  

**Motivation:** Current language models (LMs) excel at pattern recognition (System-1) but struggle with deliberate, rule-based reasoning (System-2). This gap limits their reliability in tasks requiring structured problem-solving (e.g., math, logic) and raises safety concerns due to opaque decision-making. A hybrid neuro-symbolic approach could combine neural flexibility with symbolic rigor, enabling systematic generalization while maintaining scalability.  

**Main Idea:** Propose a framework where a transformer-based LM *generates intermediate symbolic representations* (e.g., logical forms, equations) during reasoning, which are then processed by an external, modular symbolic engine (e.g., theorem prover, constraint solver). The LM is trained via reinforcement learning to produce syntactically valid symbolic outputs, guided by feedback from the external system. For example, in math problem-solving, the LM would break the task into equation steps, verified and refined by a symbolic solver. Benchmarks would focus on compositional tasks (e.g., unseen combinations of arithmetic operations) using synthetic datasets to avoid contamination. Expected outcomes include improved out-of-distribution generalization, interpretable reasoning traces, and reduced reliance on memorization. The impact lies in bridging neural and symbolic paradigms, enabling scalable yet systematic AI systems with verifiable decision-making.