Title: Geneplore-Enhanced Transformers for Human-Like Creative Generation

Motivation:  
Current generative models excel at fluent output but often lack the structured creative process humans employ. Psychological theories (e.g., the Geneplore model’s “generate” and “explore” phases) explain how people produce and refine novel ideas. Embedding these stages into AI could yield outputs that are not only coherent but also genuinely novel, surprising, and aligned with human judgments of creativity.

Main Idea:  
We propose a two‐phase transformer architecture inspired by the Geneplore framework. During the “generate” stage, a transformer module samples diverse concept sketches by perturbing learned embeddings within semantic subspaces. In the “explore” stage, a critic network—trained on human novelty and surprise ratings—scores each sketch for originality and coherence. Top candidates feed back into the next generate cycle, emulating iterative divergent/convergent thinking.  
Methodology includes:  
1. Pretraining on large corpora augmented with creativity annotations.  
2. Designing intrinsic novelty metrics using information‐theoretic surprise.  
3. Conducting human evaluations against standard creativity benchmarks.  
Expected outcomes: richer idea diversity, higher human‐rated novelty, and a reusable framework for text, image, or design generation that bridges cognitive theory and generative AI.