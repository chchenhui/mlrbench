**Title:** Multimodal Temporal Transformers for Early Detection of Neurodevelopmental Disorders  

**Motivation:** Early diagnosis of neurodevelopmental disorders like autism or ADHD is critical for effective intervention. Yet, traditional diagnostic methods often rely on sporadic clinical observations, which are subjective, time-consuming, and inaccessible in low-resource settings. A scalable, objective tool could democratize early screening and enable timely, equitable intervention globally.  

**Main Idea:** Propose a multimodal transformer-based model that analyzes longitudinal video/audio recordings of children during naturalistic interactions (e.g., play sessions or pediatric visits). The model processes temporal patterns in facial expressions, vocal intonation, motor coordination, and social engagement, integrating these cues to identify early markers of disorders. By training on diverse, curated datasets spanning cultural and socioeconomic backgrounds, the system could adapt to developmental milestones across age groups. Federated learning ensures privacy-preserving data aggregation. Expected outcomes include a diagnostic tool with >90% sensitivity for disorders like autism by 24 months of age. This could reduce diagnostic wait times, improve equitable access, and empower proactive therapies globally, particularly in underserved regions with limited pediatric specialists.