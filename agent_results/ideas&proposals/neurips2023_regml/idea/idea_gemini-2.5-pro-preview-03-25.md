**Title:** AuditGen: A Framework for Auditing Copyright Compliance in Generative Models

**Motivation:** The proliferation of large generative models raises concerns about their potential to reproduce copyrighted content from their training data, creating legal risks and violating regulations protecting creative industries. There is a pressing need for systematic methods to evaluate and mitigate these risks before model deployment.

**Main Idea:** We propose AuditGen, an automated framework to audit generative models (e.g., for images, text) for copyright compliance risks. The framework will involve: (1) Curated Input Probing: Systematically generating prompts designed to potentially trigger the recall of copyrighted material. (2) Output Similarity Analysis: Employing a multi-modal approach (e.g., perceptual hashing, embedding space similarity, subsequence matching) to compare generated outputs against a representative database of known copyrighted works. (3) Risk Quantification: Developing metrics to score the model's propensity to generate content substantially similar to copyrighted material. AuditGen aims to provide developers with practical tools and standardized reports to assess and address copyright infringement risks, fostering responsible AI development aligned with regulatory expectations.