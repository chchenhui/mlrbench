**Title**: FairSynthTab: Fairness-Aware Synthetic Tabular Data Generation Using Large Language Models  

**Motivation**: Tabular data in high-stakes domains like healthcare and finance often suffers from under-representation of marginalized groups, leading to biased ML models. Traditional generative methods prioritize fidelity over fairness, limiting their utility in building equitable systems. Addressing data scarcity for these groups while ensuring fairness remains a critical unmet challenge.  

**Main Idea**: Leverage large language models (LLMs) to generate synthetic tabular data that explicitly mitigates bias. Convert tabular records into text prompts (e.g., "Age: 30, Income: $50k, Gender: Female...") to train LLMs. During generation, condition the LLM on sensitive attributes (e.g., race, gender) and enforce fairness constraints via reinforcement learning with a reward function that penalizes distributional imbalances. For example, generate synthetic samples to match desired demographic ratios while preserving feature correlations. Evaluate using fairness metrics (e.g., demographic parity, equalized odds) and downstream classifier performance. This approach combines LLMsâ€™ pattern-learning capacity with explicit fairness guidance, enabling creation of balanced datasets that enhance model equity without compromising data utility. Expected impact: scalable, fair synthetic data for high-stakes applications.