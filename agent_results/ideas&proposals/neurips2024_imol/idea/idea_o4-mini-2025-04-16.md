Title: Dynamic Skill Tree Construction for Open-Ended Exploration

Motivation:  
Autonomous agents in open-ended environments struggle to decide which goals to pursue and in what order. Humans naturally scaffold skills—first learning simple tasks, then gradually building complexity. Enabling agents to autonomously structure their own curriculum could dramatically accelerate exploration, improve generalization, and reduce the need for hand-crafted goal spaces.

Main Idea:  
We propose an algorithm that incrementally builds a hierarchical “skill tree” of discovered behaviors. At regular intervals, the agent embeds experienced end-states into a latent space (via a variational autoencoder) and clusters them into candidate sub-goal nodes. Edges connecting nodes carry a learning-progress signal measuring performance gains when transitioning between them. A meta-controller selects sub-goals by sampling edges proportionally to their recent progress, driving exploration toward tasks that are neither too easy nor too hard. Low-level policies are trained with goal-conditioned RL and hindsight experience replay. Over time, the tree branches to reflect emerging capabilities and prunes stagnated nodes. We expect this dynamic curriculum to yield faster skill acquisition, improved coverage of complex tasks, and seamless lifelong learning without manual goal engineering.