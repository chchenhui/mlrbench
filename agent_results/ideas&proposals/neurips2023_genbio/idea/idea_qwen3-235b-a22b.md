**Title:** Efficient Tuning of Large Language Models for Scientific Hypothesis Generation in Biology  

**Motivation:**  
Despite the success of large language models (LLMs) in general domains, their application to scientific hypothesis generation in biology remains limited by domain specificity, computational costs, and the need for grounded, reproducible insights. Biology faces a growing crisis of knowledge fragmentation: experimental data and literature grow exponentially, but systematic synthesis of this information into testable hypotheses lags. Traditional methods rely on manual curation, which is time-consuming and error-prone. Enabling LLMs to efficiently bridge this gap could unlock discoveries in understudied biological systems or diseases.  

**Main Idea:**  
We propose **BioHypoGen**, a framework that adaptively fine-tunes LLMs (e.g., BioMedLM, Galactica) using parameter-efficient methods (LoRA, adapters) on multi-modal biological data, including literature, gene-expression datasets, and protein interaction networks. The model will generate hypotheses by (1) identifying knowledge gaps via contrastive learning between known mechanisms and uncharacterized data, and (2) leveraging retrieval-augmented generation to ground predictions in external databases (e.g., UniProt, STRING). To ensure biological plausibility, we introduce a dual-validation pipeline: computational evaluation via novelty metrics and experimental validation of top hypotheses in wet-lab settings. Expected outcomes include automated identification of candidate gene-disease associations, drug-target interactions, or synthetic biology pathways with a â‰¥30% higher validation rate compared to baseline models. This work addresses key challenges in the GenBio workshop by aligning generative AI capabilities with biological experiment design and closing the loop between *in silico* predictions and *in vivo* testing. Impact spans accelerated discovery in neglected diseases and improved reproducibility in hypothesis-driven research.