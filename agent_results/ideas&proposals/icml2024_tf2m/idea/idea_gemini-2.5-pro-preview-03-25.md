**Title:** Information-Theoretic Guarantees for Fairness-Preserving Distillation of Foundation Models

**Motivation:** Distilling large foundation models (FMs) into smaller, efficient versions is crucial for deployment. However, the distillation process can inadvertently amplify biases present in the teacher model or training data, compromising fairness. Current distillation methods often lack theoretical guarantees regarding fairness preservation. This research aims to develop a principled framework for distilling FMs while ensuring fairness properties are maintained or improved.

**Main Idea:** We propose an information-theoretic approach to fairness-preserving knowledge distillation. We will model the distillation process as minimizing the information loss between the teacher and student models, subject to fairness constraints defined using information-theoretic measures (e.g., mutual information between model outputs and sensitive attributes, conditional entropy). The core idea is to derive theoretical bounds on the fairness degradation during distillation based on the teacher model's fairness, the compression rate, and the chosen fairness metric. We will develop practical distillation objectives informed by these bounds and validate the approach by distilling large language models for downstream tasks, empirically demonstrating improved fairness-performance trade-offs compared to standard distillation methods.