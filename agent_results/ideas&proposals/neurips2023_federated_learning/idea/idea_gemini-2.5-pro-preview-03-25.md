**Title:** FedPrompt: Parameter-Efficient Federated Prompt Tuning of Foundation Models

**Motivation:** Fine-tuning large foundation models in Federated Learning (FL) is prohibitively expensive due to massive communication and computation costs, especially for resource-constrained clients. Prompt tuning offers a parameter-efficient alternative by only tuning small prompt vectors, but its application within FL raises unique challenges regarding aggregation and heterogeneity.

**Main Idea:** We propose FedPrompt, a framework specifically designed for federated prompt tuning. Clients download a frozen foundation model once and only collaboratively train lightweight prompt parameters using FL. During local training, each client optimizes its prompt using local private data. Only these small prompt parameters (or their updates) are communicated and aggregated by the server, drastically reducing communication overhead compared to fine-tuning larger model parts. We will investigate adaptive aggregation strategies for prompts tailored to data heterogeneity across clients and evaluate its effectiveness on various downstream tasks. Expected outcomes include a highly resource-efficient FL pipeline for adapting foundation models, enabling practical personalization on edge devices while preserving data privacy.