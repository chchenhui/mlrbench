Title: FedMetaPrompt â€“ Federated Meta-Learning of Adaptive Prompts for Foundation Models

Motivation:
Fine-tuning large foundation models in federated settings is hampered by client heterogeneity, privacy constraints, and communication overhead. Static global prompts fail to adapt across diverse local data distributions, limiting personalization and overall performance.

Main Idea:
FedMetaPrompt integrates model-agnostic meta-learning (MAML) with prompt tuning in a privacy-preserving FL pipeline. Each client starts from a shared meta-prompt and performs lightweight local prompt tuning on its private data. Clients compute meta-gradients reflecting how their tuned prompts improve task performance. The server aggregates these meta-gradients to update the global meta-prompt, rather than raw model weights. Over successive rounds, the meta-prompt converges to an initialization that clients can quickly adapt into personalized prompts with minimal local updates. Communication is limited to prompt vectors and meta-gradients (<1MB), reducing bandwidth. Expected outcomes include rapid on-device personalization, robust performance across heterogeneous tasks, and stringent data privacy. This approach democratizes access to foundation models by enabling efficient, adaptive tuning in federated environments.