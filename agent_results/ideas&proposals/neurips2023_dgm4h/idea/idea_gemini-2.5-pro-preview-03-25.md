**Title:** Federated Diffusion Models for Privacy-Preserving Synthetic Medical Image Generation

**Motivation:** Generating realistic synthetic medical images (e.g., CT, MRI) is crucial for augmenting scarce datasets, especially for rare diseases or underrepresented populations. However, centralizing sensitive patient data from multiple institutions to train generative models poses significant privacy risks and logistical challenges. Federated learning offers a privacy-preserving alternative, but applying it effectively to complex generative models like diffusion models for high-resolution medical images remains an open challenge.

**Main Idea:** We propose a federated diffusion model framework (FedDiff) specifically designed for medical image synthesis. Each participating institution trains a local diffusion model on its private data. Instead of sharing raw data or model weights directly, we explore secure aggregation techniques (e.g., secure multi-party computation, differential privacy noise addition) for model parameters or parameter updates periodically exchanged via a central server or peer-to-peer. The core idea is to enable collaborative training that leverages diverse institutional data to generate high-fidelity, diverse synthetic images reflecting the global data distribution, without compromising patient privacy. We will evaluate FedDiff by generating synthetic scans for a specific rare condition, assessing image quality (FID, IS), data utility (performance on downstream tasks like segmentation/classification), and privacy guarantees.