**Title:** Equivariant Dynamics Learning in Latent World Models

**Motivation:** World models learn environment dynamics for planning and control but often require vast amounts of data and struggle to generalize under transformations respecting physical symmetries (e.g., rotation, translation). Explicitly encoding these symmetries within the learned dynamics model is crucial for improving sample efficiency and robustness, particularly in robotics and physical interaction domains.

**Main Idea:** We propose incorporating group equivariance (e.g., SE(3) for rigid bodies) directly into the latent dynamics component of world models. Using equivariant neural networks (like E(n)-equivariant GNNs) to model the transition function `z_t+1 = f(z_t, a_t)` ensures that predictions inherently respect the specified physical symmetries. We will train this model on simulated robotic manipulation or physics interaction datasets and compare its performance (prediction accuracy, sample efficiency, generalization to novel configurations) against standard, non-equivariant world model baselines. We expect equivariant dynamics models to achieve significantly better generalization and data efficiency by leveraging built-in geometric priors.