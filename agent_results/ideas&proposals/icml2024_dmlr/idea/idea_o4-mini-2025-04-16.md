Title: MetaCurate: Model-Assisted Quality Signal Integration for Scalable Dataset Curation

Motivation:  
The explosion of raw unlabeled data for foundation models demands scalable curation pipelines. Manual curation is time-consuming and prone to bias, and current automated filters focus on simple heuristics. Integrating nuanced quality signals from pretrained models can streamline dataset assembly, enhancing robustness and representativeness across domains.

Main Idea:  
We propose MetaCurate, a data-centric pipeline that extracts multi-dimensional quality signals—semantic novelty, model-annotator agreement, bias heuristics and multimodal alignment—using ensembles of foundation models. Each candidate sample is encoded to compute metrics like uncertainty, out-of-distribution score and prosociality bias. A weighted scoring function ranks and selects high-quality instances, while an LLM-driven module suggests conceptual categories. An interactive dashboard enables users to adjust signal weights, visualize coverage and iteratively refine selections. We will validate MetaCurate on large-scale vision and text corpora, training downstream models to measure gains in performance, diversity and reduced harmful content. By automating rich quality assessments and embedding human-in-the-loop controls, MetaCurate reduces manual effort, adapts to dataset shifts and fosters the creation of robust foundation models for new domains.