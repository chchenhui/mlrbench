**Title:** Dynamically Regularized Learning with Scientific Model Priors

**Motivation:** Training complex Machine Learning (ML) models often requires large datasets. Scientific models encapsulate domain knowledge that could regularize ML models, improving data efficiency and adherence to physical laws. However, inflexibly enforcing scientific constraints can limit the ML model's ability to capture nuances beyond the idealized scientific model.

**Main Idea:** We propose a dynamic regularization framework where a scientific model acts as a "prior" during ML training. Instead of rigid constraints, the scientific model's predictions or governing equations impose a soft, adaptive penalty on the ML model's output or latent space. The strength of this regularization dynamically adjusts based on the ML model's confidence or the data's local density. In data-sparse regions or when the ML model yields low-confidence predictions, the regularization strength increases, guiding the model towards scientifically plausible behaviour. Conversely, in data-rich regions, the regularization weakens, allowing the ML model to capture complex, data-driven patterns. This approach aims to optimally leverage scientific knowledge for better generalization and physical consistency without stifling the ML model's learning capacity.