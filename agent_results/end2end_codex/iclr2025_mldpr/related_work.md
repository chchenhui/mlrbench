1. **Title**: VeML: An End-to-End Machine Learning Lifecycle for Large-scale and High-dimensional Data (arXiv:2304.13037)
   - **Authors**: Van-Duc Le, Cuong-Tien Bui, Wen-Syan Li
   - **Summary**: This paper introduces VeML, a version management system designed for end-to-end machine learning lifecycles, particularly focusing on large-scale and high-dimensional datasets. VeML addresses challenges such as the high cost of building ML lifecycles and model accuracy degradation due to differences between training and testing data. The system proposes transferring lifecycles of similar datasets to new training data and includes mechanisms to detect mismatches without labeled data from testing datasets.
   - **Year**: 2023

2. **Title**: Model Lake: A New Alternative for Machine Learning Models Management and Governance (arXiv:2503.22754)
   - **Authors**: Moncef Garouani, Franck Ravat, Nathalie Valles-Parlangeau
   - **Summary**: The authors propose the concept of a Model Lake, inspired by data lakes, as a centralized management framework for datasets, codes, and models within organizational environments. This framework aims to enhance model lifecycle management, discovery, audit, and reusability, addressing challenges in versioning, audit, and reuse of ML models.
   - **Year**: 2025

3. **Title**: Atlas: A Framework for ML Lifecycle Provenance & Transparency (arXiv:2502.19567)
   - **Authors**: Marcin Spoczynski, Marcela S. Melara, Sebastian Szyller
   - **Summary**: Atlas is introduced as a framework enabling fully attestable ML pipelines by leveraging open specifications for data and software supply chain provenance. It collects verifiable records of model artifact authenticity and end-to-end lineage metadata, enhancing metadata integrity and preserving data confidentiality throughout the ML pipeline operations.
   - **Year**: 2025

4. **Title**: Dataset Management Platform for Machine Learning (arXiv:2303.08301)
   - **Authors**: Ze Mao, Yang Xu, Erick Suarez
   - **Summary**: This paper describes a platform designed to manage and use datasets effectively, integrating dataset management and transformation mechanisms. It includes a storage engine acting as a source of truth for all data, handling versioning and access control, and a dataset transformation mechanism to generate datasets serving different purposes, thereby improving efficiency in the ML process.
   - **Year**: 2023

5. **Title**: An Empirical Study of Challenges in Machine Learning Asset Management (arXiv:2402.15990)
   - **Authors**: [Authors not specified in the provided excerpt]
   - **Summary**: This study explores the challenges in managing machine learning assets, including datasets and models. It highlights issues such as versioning, dependency management, and the need for effective lifecycle management practices to ensure reproducibility and reliability in ML workflows.
   - **Year**: 2024

6. **Title**: Flow with FlorDB: Incremental Context Maintenance for the Machine Learning Lifecycle (arXiv:2408.02498)
   - **Authors**: [Authors not specified in the provided excerpt]
   - **Summary**: The paper introduces FlorDB, a system designed for incremental context maintenance in the ML lifecycle. It addresses challenges in managing and updating ML models by providing mechanisms for efficient context tracking and version control, thereby facilitating smoother transitions and updates in ML workflows.
   - **Year**: 2024

7. **Title**: Machine Learning Data Practices through a Data Curation Lens: An Evaluation Framework (arXiv:2405.02703)
   - **Authors**: [Authors not specified in the provided excerpt]
   - **Summary**: This paper presents an evaluation framework for machine learning data practices viewed through a data curation perspective. It emphasizes the importance of proper data documentation, versioning, and maintenance to ensure data quality and reproducibility in ML research and applications.
   - **Year**: 2024

8. **Title**: How to Avoid Machine Learning Pitfalls: A Guide for Academic Researchers (arXiv:2108.02497)
   - **Authors**: [Authors not specified in the provided excerpt]
   - **Summary**: This guide addresses common pitfalls in machine learning research, including issues related to data management, model evaluation, and reproducibility. It provides recommendations for best practices to enhance the quality and reliability of ML research outcomes.
   - **Year**: 2023

9. **Title**: A Framework for Deprecating Datasets: Standardizing Documentation, Identification, and Communication (arXiv:2111.04424)
   - **Authors**: Alexandra Sasha Luccioni, Frances Corry, Hamsini Sridharan, Mike Ananny, Jason Schultz, Kate Crawford
   - **Summary**: This paper studies the practice of dataset deprecation in ML, identifying cases where datasets continued to circulate despite deprecation. It proposes a Dataset Deprecation Framework that includes considerations of risk, mitigation of impact, appeal mechanisms, timeline, post-deprecation protocols, and publication checks, aiming to standardize dataset deprecation practices.
   - **Year**: 2021

10. **Title**: An Empirical Study of Challenges in Machine Learning Asset Management (arXiv:2402.15990)
    - **Authors**: [Authors not specified in the provided excerpt]
    - **Summary**: This study explores the challenges in managing machine learning assets, including datasets and models. It highlights issues such as versioning, dependency management, and the need for effective lifecycle management practices to ensure reproducibility and reliability in ML workflows.
    - **Year**: 2024

**Key Challenges:**

1. **Lack of Standardized Deprecation Procedures**: The absence of uniform guidelines for dataset deprecation leads to continued use of outdated or flawed datasets, undermining reproducibility and ethical compliance.

2. **Data Quality and Maintenance**: Ensuring the quality and timely updating of datasets is challenging, especially for large-scale and high-dimensional data, impacting model performance and reliability.

3. **Versioning and Provenance Tracking**: Effective version control and tracking the provenance of datasets and models are essential for reproducibility but are often inadequately addressed in current practices.

4. **Ethical and Legal Considerations**: Datasets may contain biases, licensing conflicts, or privacy issues that are not always identified or addressed, leading to ethical and legal challenges.

5. **Integration of Automated Tools**: Developing and integrating automated tools for dataset evaluation, deprecation scoring, and notification systems require significant resources and coordination among stakeholders. 