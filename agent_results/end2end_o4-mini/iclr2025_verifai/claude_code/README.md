# ContractGPT: A Closed-Loop Formal Specification-Guided LLM Code Synthesis Framework

This repository contains the implementation of ContractGPT, a closed-loop framework for code synthesis guided by formal specifications.

## Overview

ContractGPT is a framework that iteratively refines code generated by Large Language Models (LLMs) to satisfy formal specifications expressed in a lightweight Domain-Specific Language (DSL). The framework follows a "spec-generate-verify-refine" cycle:

1. A user provides a specification in the ContractGPT DSL.
2. An LLM generates candidate code based on the specification.
3. A static analyzer and SMT solver verify whether the code meets the specification.
4. If verification fails, counterexamples are translated into natural language feedback.
5. The feedback is provided to the LLM to refine the implementation.
6. The cycle continues until a verified implementation is produced or a maximum number of iterations is reached.

## Project Structure

- `models/`: Core components of the ContractGPT framework
  - `dsl_parser.py`: Parser for the ContractGPT DSL
  - `llm_wrapper.py`: Wrapper for interacting with LLMs
  - `static_analyzer.py`: Static analyzer and Z3 SMT solver integration
  - `feedback_translator.py`: Counterexample to natural language feedback translator
  - `contract_gpt.py`: Main ContractGPT implementation
  - `baselines.py`: Baseline methods for comparison
- `data/`: Benchmark specifications and datasets
  - `benchmarks.py`: Functions for generating benchmarks
- `utils/`: Utility functions
  - `metrics.py`: Functions for calculating and visualizing metrics
  - `experiment.py`: Functions for running experiments
- `scripts/`: Scripts for running experiments
  - `run_experiments.py`: Script for running ContractGPT experiments
- `run_all.py`: Main script for running the entire experimental pipeline

## Installation

### Prerequisites

- Python 3.8 or later
- Z3 SMT solver

### Dependencies

Install the required Python packages:

```bash
pip install z3-solver matplotlib pandas requests numpy typing
```

### Environment Variables

Set the following environment variables for LLM API access:

- `OPENAI_API_KEY`: API key for OpenAI services
- `ANTHROPIC_API_KEY`: API key for Anthropic services

## Usage

### Running All Experiments

To run the complete experimental pipeline:

```bash
python run_all.py --model-name gpt-4o-mini --target-language python
```

This will:
1. Generate benchmark specifications
2. Run all methods (ContractGPT and baselines) on all benchmarks
3. Calculate metrics
4. Generate visualizations
5. Create a results.md file with the experiment results

### Options

- `--target-language`: Target programming language (default: python)
- `--model-name`: Name of the LLM to use (default: gpt-4o-mini)
- `--max-iterations`: Maximum number of iterations for synthesis (default: 5)
- `--temperature`: Temperature for LLM generation (default: 0.2)
- `--skip-benchmarks`: Skip benchmark generation
- `--methods`: Methods to run (default: ContractGPT LLMOnly VeCoGenLike LLM4CodeLike)

### Running Specific Experiments

To run specific experiments using the run_experiments.py script:

```bash
python scripts/run_experiments.py --generate-benchmarks --methods ContractGPT LLMOnly
```

## Benchmarks

The framework includes two types of benchmarks:

1. **Algorithmic Benchmarks**:
   - Bubble Sort
   - Binary Search
   - Quick Sort
   - Breadth-First Search
   - Dijkstra's Algorithm

2. **Systems-Level Benchmarks**:
   - File Buffer
   - Memory Pool Allocator
   - HTTP Request Parser

## Results

After running the experiments, results are saved to:

- `results/`: Contains:
  - `results.md`: Markdown file with experiment results
  - Various .png files with visualizations
  - `log.txt`: Experiment execution log

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Citation

If you use ContractGPT in your research, please cite:

```
@inproceedings{contractgpt2025,
  title={ContractGPT: A Closed-Loop Formal Specification-Guided LLM Code Synthesis Framework},
  author={ContractGPT Team},
  booktitle={Proceedings of the VerifAI: AI Verification in the Wild Workshop},
  year={2025}
}
```