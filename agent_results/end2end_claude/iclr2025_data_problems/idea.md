# Attribution-Guided Training: Improving Foundation Model Transparency and Copyright Compliance

## Motivation
As foundation models increasingly rely on vast datasets, concerns about copyright infringement and proper attribution have escalated. Current approaches for data attribution are often retroactive and inefficient, making it difficult to identify potential copyright violations during training. Additionally, models frequently generate content that closely resembles training examples without providing proper attribution or recognition to original creators. This research addresses these challenges by proposing a novel training framework that integrates attribution mechanisms directly into the training process.

## Main Idea
We propose Attribution-Guided Training (AGT), a framework that embeds attribution signals during foundation model training rather than applying them post-hoc. AGT employs a dual-objective optimization: alongside standard predictive loss, it incorporates an "attribution loss" that encourages the model to internally represent and track the provenance of information. The approach utilizes a parallel attribution network that maps model activations to potential source documents, creating an attributable embedding space. When generating content, the model can automatically cite sources based on activation patterns that closely match those from training. This attribution mechanism serves both as documentation for copyright compliance and as a regularization technique that potentially enhances model generalization by discouraging exact memorization. AGT offers practical benefits to model developers seeking to ensure compliance with copyright laws while providing transparency to users about the origins of generated content.