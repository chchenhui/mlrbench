**Title:** Meta-Learned Bayesian Inference with Language Model Priors for Scalable Decision-Making  

**Motivation:** Scaling Bayesian methods to high-dimensional data and integrating informative priors from large language models (LLMs) remains challenging, limiting their application in dynamic, data-scarce scenarios where robust uncertainty quantification and adaptive decisions are critical.  

**Main Idea:** Develop a meta-learning framework where a transformer model is trained to approximate Bayesian posterior updates efficiently. LLMs generate task-specific embeddings as structured priors, encoding domain knowledge (e.g., molecular properties for drug discovery). The transformer meta-learns on diverse tasks to generalize inference across domains, enabling fast, uncertainty-aware decisions with limited data. By combining LLM-derived priors and amortized inference via meta-learning, computational costs are reduced while maintaining calibration. The method integrates with active learning to optimize data acquisition, dynamically balancing exploration and exploitation. Expected outcomes include a scalable Bayesian decision-making framework validated in drug discovery (e.g., optimizing molecule selection) and robotics (safe exploration), bridging the gap between modern AI tools and principled uncertainty handling.