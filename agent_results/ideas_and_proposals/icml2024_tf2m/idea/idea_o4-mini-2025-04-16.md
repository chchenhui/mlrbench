Title: InfoPrune – Information-Theoretic Pruning of Foundation Models

Motivation:  
Foundation models (FMs) deliver state-of-the-art performance but incur massive energy, memory, and latency costs. Existing pruning heuristics often lack principled guarantees, risking unpredictable accuracy drops. By grounding compression in information theory, we can obtain both efficiency and performance bounds.

Main Idea:  
We propose InfoPrune, a framework that quantifies each transformer's submodule (attention head, MLP neuron) by its mutual information (MI) contribution to the model’s output distribution. Using a variational MI estimator, we score and rank modules; those with the lowest information contribution are pruned first. We derive an upper bound on the total performance degradation in terms of the sum of pruned modules’ MI, offering theoretical guarantees. Practically, InfoPrune alternates between MI estimation and structured pruning, followed by light fine-tuning to recover any residual loss. We will validate on language modeling and vision-language benchmarks, targeting 50–70% parameter reduction with ≤1% perplexity or accuracy drop. This principled approach promises transparent, predictable compression for large-scale FMs.