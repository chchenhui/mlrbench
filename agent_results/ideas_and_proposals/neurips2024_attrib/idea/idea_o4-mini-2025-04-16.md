Title: Coreset Influence Graphs for Scalable Data Attribution

Motivation:  
As models scale to billions of parameters and trillions of training examples, pinpointing which data points drive specific behaviors becomes intractable. Efficiently attributing model outputs back to influential training examples can help diagnose biases, detect contamination, and guide dataset curation.

Main Idea:  
We propose constructing a hierarchical “Coreset Influence Graph” that clusters training examples into semantically coherent groups (coresets) and uses approximate influence functions to estimate each group’s effect on a target prediction. First, we compute low‐rank Hessian inverses via randomized sketching and approximate per‐example gradients for a small validation set. Next, we aggregate gradient–Hessian interactions within each coreset to obtain cluster‐level influence scores, filtering out low‐impact clusters. Finally, we drill down on high‐impact clusters, computing fine‐grained influence scores only for their members. This two‐stage approach reduces computation by orders of magnitude compared to full influence estimation. Expected outcomes include: (1) fast detection of mislabeled or contaminated data, (2) targeted data pruning or augmentation to improve downstream performance, and (3) a practical pipeline for large‐scale dataset auditing.