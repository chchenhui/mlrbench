**Title:** Efficient Data Attribution via Meta-Learning Gradient-Based Influence Proxies  

**Motivation:** Understanding how individual training examples influence model behavior is critical for diagnosing biases, improving data quality, and curating datasets. Current influence estimation methods (e.g., influence functions) are computationally prohibitive for large models and datasets, limiting their practical utility.  

**Main Idea:** This research proposes a meta-learning framework to train a lightweight proxy model that predicts the influence of training examples without exhaustive recomputation. The proxy model ingests training example embeddings (e.g., gradients, activations, metadata) and outputs influence scores relative to specific model behaviors (e.g., predictions on a validation set). It is trained on a subset of data where influence is precomputed using traditional methods, then generalized to the full dataset. By leveraging gradient dynamics and validation performance during training, the proxy learns to approximate influence efficiently. Expected outcomes include a scalable, model-agnostic tool for attributing behavior to data subsets, enabling rapid identification of harmful or critical examples (e.g., leaked or biased data). Potential impact includes reducing dataset curation costs and mitigating unintended behaviors in LLMs.