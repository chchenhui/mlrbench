Title: Uncertainty-Guided Active Human-in-the-Loop Annotation for Trustworthy Medical Imaging Models

Motivation: Limited labeled data and poorly calibrated uncertainty estimates hinder clinical adoption of ML in healthcare. Targeted expert involvement can both improve model performance and foster clinician trust.

Main Idea: We propose a Bayesian uncertainty-driven active learning framework that identifies high-uncertainty regions in multimodal MRI/CT scans and solicits focused annotations from clinicians via an interactive interface. At each iteration, the model computes predictive entropy and mutual information to rank candidate samples; only top-uncertainty instances are presented for expert labeling. Incremental model updates refine both segmentation accuracy and confidence calibration. We will validate on brain tumor segmentation and pulmonary nodule detection benchmarks, measuring Dice score, Expected Calibration Error, and annotation time. Expected outcomes include higher diagnostic accuracy, well-aligned uncertainty estimates with clinical risk, reduced annotation burdens, and increased clinician trustâ€”advancing transparent human-AI collaboration in medical imaging.