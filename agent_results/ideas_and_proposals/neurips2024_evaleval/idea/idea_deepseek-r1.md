**Title:** Co-Designing Inclusive Evaluation Frameworks for Generative AI with Multi-Stakeholder Participation  

**Motivation:** Current evaluations of generative AI’s societal impacts focus narrowly on technical metrics and lack diverse stakeholder input, risking oversight of real-world harms. A standardized, participatory approach is critical to ensuring equitable and holistic assessments that reflect varied perspectives, from marginalized communities to policymakers.  

**Main Idea:** This research proposes a co-designed framework for evaluating generative AI’s impacts by systematically integrating stakeholders (e.g., ethicists, educators, policymakers, and affected communities) alongside technical experts. Methodologies include iterative co-design workshops and Delphi consensus-building exercises to identify priority impact domains (e.g., misinformation, labor displacement) and design mixed-method evaluation criteria (quantitative metrics, qualitative case studies). Outcomes will include a publicly adaptable toolkit with evaluation protocols, participatory guidelines, and impact severity scales. Expected impacts include mitigating evaluation biases, fostering accountability, and informing policy for responsible AI deployment. The framework will be validated through pilot evaluations of generative models in education and media, measuring coverage of ethical and social risks compared to traditional approaches.