1. **Title**: Particip-AI: A Democratic Surveying Framework for Anticipating Future AI Use Cases, Harms and Benefits (arXiv:2403.14791)
   - **Authors**: Jimin Mun, Liwei Jiang, Jenny Liang, Inyoung Cheong, Nicole DeCario, Yejin Choi, Tadayoshi Kohno, Maarten Sap
   - **Summary**: This paper introduces PARTICIP-AI, a framework designed to involve laypeople in speculating and assessing AI use cases and their impacts. Through a medium-scale study with 295 participants, the authors highlight the importance of democratic risk assessment and the inclusion of diverse perspectives in AI development. The study emphasizes applications for personal life and society, contrasting with the business-focused current AI development, and surfaces diverse envisioned harms such as distrust in AI and institutions. The findings suggest that involving the public can guide more democratic AI development and governance.
   - **Year**: 2024

2. **Title**: Evaluating the Social Impact of Generative AI Systems in Systems and Society (arXiv:2306.05949)
   - **Authors**: Irene Solaiman, Zeerak Talat, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Canyu Chen, Hal Daum√© III, Jesse Dodge, Isabella Duan, Ellie Evans, Felix Friedrich, Avijit Ghosh, Usman Gohar, Sara Hooker, Yacine Jernite, Ria Kalluri, Alberto Lusoli, Alina Leidinger, Michelle Lin, Xiuzhu Lin, Sasha Luccioni, Jennifer Mickel, Margaret Mitchell, Jessica Newman, Anaelia Ovalle, Marie-Therese Png, Shubham Singh, Andrew Strait, Lukas Struppek, Arjun Subramonian
   - **Summary**: This paper presents a guide toward standardizing the evaluation of generative AI systems' social impacts across modalities such as text, image, audio, and video. The authors define seven categories of social impact, including bias, cultural values, and environmental costs, and offer methods for evaluation applicable to various generative modalities. The framework aims to serve as a starting point for necessary investment in future evaluations and provides recommendations for mitigating harm in broader societal contexts.
   - **Year**: 2023

3. **Title**: A Shared Standard for Valid Measurement of Generative AI Systems' Capabilities, Risks, and Impacts (arXiv:2412.01934)
   - **Authors**: Alexandra Chouldechova, Chad Atalla, Solon Barocas, A. Feder Cooper, Emily Corvi, P. Alex Dow, Jean Garcia-Gathright, Nicholas Pangakis, Stefanie Reed, Emily Sheng, Dan Vann, Matthew Vogel, Hannah Washington, Hanna Wallach
   - **Summary**: This paper introduces a shared standard for valid measurement of generative AI systems' capabilities, risks, and impacts, grounded in measurement theory from the social sciences. The framework involves systematizing, operationalizing, and applying concepts, contexts, and metrics, enabling better understanding, reliability, and comparability of evaluations. The authors argue that this approach advances GenAI evaluation practices toward more formalized and theoretically grounded processes.
   - **Year**: 2024

4. **Title**: Participatory Approaches in AI Development and Governance: A Principled Approach (arXiv:2407.13100)
   - **Authors**: Ambreesh Parthasarathy, Aditya Phalnikar, Ameen Jauhar, Dhruv Somayajula, Gokul S Krishnan, Balaraman Ravindran
   - **Summary**: This paper advocates for participatory approaches in AI development and governance, emphasizing the inclusion of individuals impacted by AI systems in their design, development, and deployment. The authors describe the AI lifecycle, identify criteria for stakeholder participation, and map relevant stakeholders to different stages of the AI lifecycle. The study argues that such participatory approaches enhance fairness, empower citizens, and provide developers with valuable information to improve AI algorithms.
   - **Year**: 2024

**Key Challenges:**

1. **Lack of Standardized Evaluation Protocols**: The absence of universally accepted frameworks for assessing the societal impact of generative AI leads to inconsistent and ad hoc evaluations.

2. **Limited Stakeholder Involvement**: Current AI development processes often exclude diverse stakeholders, resulting in evaluations that may not fully capture the societal implications of AI systems.

3. **Measurement Validity and Reliability**: Ensuring that evaluation metrics accurately and consistently measure the intended concepts remains a significant challenge in assessing AI systems.

4. **Addressing Diverse Harms**: Identifying and mitigating a wide range of potential harms, including bias, privacy violations, and environmental costs, is complex and requires comprehensive evaluation frameworks.

5. **Balancing Innovation and Governance**: Developing AI systems that are both innovative and aligned with societal values necessitates frameworks that effectively balance technological advancement with ethical considerations. 