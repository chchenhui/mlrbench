Title: HyperG: A Meta-Learned Hyperparameter Generator for Agnostic RL

Motivation:
Reinforcement learning often demands costly, expert-driven hyperparameter tuning, hampering out-of-the-box deployment on novel tasks. Automating this step can democratize RL and boost reproducibility.

Main Idea:
We introduce HyperG, a lightweight neural generator gφ that maps concise environment embeddings (state/action dimensions, reward sparsity metrics, preliminary rollout statistics) to a full RL hyperparameter set. Using a meta-learning loop over a diverse task distribution, HyperG is trained via gradient-based updates: for each sampled task, gφ proposes hyperparameters, an RL agent trains for a few episodes, and task performance gradients flow back to refine gφ. At test time, HyperG predicts near-optimal hyperparameters in one shot—eliminating expensive grid or Bayesian searches. We validate on MuJoCo control and Atari suites, demonstrating comparable performance to hand-tuned baselines with zero additional tuning. HyperG paves the way toward truly hyperparameter-agnostic RL, lowering barriers for real-world applications and aligning AutoML advances with reinforcement learning.