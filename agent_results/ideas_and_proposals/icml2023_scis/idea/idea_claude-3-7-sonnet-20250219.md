# Causality-Guided Adversarial Stress Testing for Detecting Spurious Correlations

## Motivation
Machine learning models often exploit spurious correlations – relationships between features and labels that don't reflect true causal connections – leading to poor generalization in real-world settings. Current methods for detecting these shortcut correlations are either reactive or require manual inspection, while stress testing approaches often lack principled guidance to efficiently probe model vulnerabilities. There's an urgent need for systematic methods to identify spurious correlations before deployment, especially in high-stakes domains like healthcare and criminal justice.

## Main Idea
I propose a causality-guided adversarial stress testing framework that combines causal inference principles with adversarial techniques to systematically detect spurious correlations. The approach begins by constructing a causal graph of expected relationships based on domain knowledge. This graph guides the generation of targeted perturbations that should affect prediction if the model relies on spurious correlations but not if it uses causal features. The framework has three components: (1) automatic identification of potential spurious pathways in the causal graph, (2) targeted adversarial perturbations along non-causal paths, and (3) sensitivity analysis to quantify and rank discovered vulnerabilities. This approach provides interpretable results, as each detected vulnerability maps to specific causal relationships, enabling developers to prioritize fixes based on potential real-world impact rather than just performance metrics.