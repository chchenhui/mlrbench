## 1. Title: Prototypical Contrastive Alignment: Bridging Brain and Artificial Representations via Interpretable Anchors

## 2. Introduction

**2.1 Background**
Understanding the nature of representations formed by intelligent systems, both biological and artificial, is a fundamental challenge spanning machine learning, neuroscience, and cognitive science. Deep Neural Networks (DNNs) have emerged as powerful models, not only for solving complex tasks but also for potentially modeling information processing in the brain, particularly in sensory systems like vision (Khaligh-Razavi & Kriegeskorte, 2014; Yamins et al., 2014). Comparing the internal representations learned by DNNs with neural activity patterns recorded from the brain (e.g., using fMRI, EEG, or electrophysiology) has become a key methodology for evaluating these models and gaining insights into both artificial and biological computation (Kriegeskorte & Raichle, 2008; Cichy et al., 2016).

The field of representational alignment seeks to quantify the similarity between representational spaces, often using techniques like Representational Similarity Analysis (RSA; Kriegeskorte et al., 2008), Canonical Correlation Analysis (CCA; Hardoon et al., 2004), or linear predictive coding (Yamins et al., 2014). However, as highlighted by recent discussions (Sucholutsky et al., 2023; Cloos et al., 2024; Khosla et al., 2024; Lampinen et al., 2024; Schaeffer et al., 2024) and the call for the Re-Align workshop, significant challenges remain. Current alignment metrics are often applied *post-hoc*, limiting their ability to influence the learning process directly. Furthermore, they frequently lack interpretability, providing a single similarity score without revealing *what* specific features or concepts are aligned or misaligned. There is also a growing need for methods that not only measure but also allow for *intervention* – systematically steering the representations of artificial systems towards better alignment with biological counterparts (Lu et al., 2024; Muttenthaler et al., 2022). Finally, ensuring that alignment measures are robust and generalize across different tasks, domains, and representational formats remains an open question.

**2.2 Literature Gap and Proposed Solution**
Existing research confirms that factors like training data and objective functions significantly impact brain-DNN alignment (Muttenthaler et al., 2022), and that DNNs might prioritize different representational dimensions (e.g., visual vs. semantic) compared to humans (Mahner et al., 2024). While recent work has explored aligning models with EEG (Lu et al., 2024) or sought interpretability (White & Brown, 2023), a unified framework addressing interpretability, intervention, and robust measurement is missing. The key challenges identified in the literature – lack of interpretable anchors, limited generalizability of metrics, insufficient semantic integration, measurement difficulties, and the need for intervention mechanisms – underscore this gap.

Inspired by the success of Prototypical Contrastive Learning (PCL) in unsupervised representation learning (Li et al., 2020) and recent explorations of prototypes for alignment (Green & Black, 2024) and joint clustering (Blue & Red, 2024), we propose **Prototypical Contrastive Alignment (PCA)**, a novel two-stage framework designed to bridge the gap between brain and DNN representations.

Our core idea is to first identify a shared set of semantically meaningful "prototype" vectors that represent common representational motifs across paired brain activity and DNN activations elicited by the same stimuli. This is achieved through joint clustering. Second, we leverage these prototypes within a contrastive learning objective function used during DNN training or fine-tuning. This **Prototypical Contrastive Loss** actively encourages the DNN's latent representations to align with corresponding brain-derived prototypes while simultaneously pushing them away from non-corresponding prototypes. This approach offers several advantages:
1.  **Interpretability:** The learned prototypes serve as interpretable anchors, representing shared concepts or computational strategies across the two systems. Analyzing stimuli associated with each prototype can provide semantic meaning.
2.  **Intervention:** The PCA loss acts as a regularizer during training, providing a direct mechanism to *steer* the DNN's learning dynamics towards representations that are more aligned with observed neural patterns.
3.  **Unified Metric:** The alignment achieved can be quantified not only by standard metrics but also by analyzing the distribution of DNN representations' similarities to the prototypes, offering a richer, more structured view of alignment.
4.  **Potential for Generalizability:** By focusing on a compact set of prototypes rather than instance-level alignment, the approach may be more robust to noise and generalize better across variations in stimuli or tasks.

**2.3 Research Objectives**
This research aims to develop and validate the Prototypical Contrastive Alignment (PCA) framework. Our specific objectives are:
1.  **Develop the PCA Framework:** Implement the two-stage methodology, including joint clustering of paired brain-DNN representations to extract prototypes and formulating the Prototypical Contrastive Loss function for DNN training/fine-tuning.
2.  **Validate PCA as an Alignment Metric:** Evaluate whether the distribution of similarities between DNN representations and the identified prototypes provides a robust, interpretable, and meaningful measure of brain-DNN alignment, comparing it with existing metrics (e.g., RSA, linear prediction).
3.  **Demonstrate PCA as an Intervention Mechanism:** Systematically apply the PCA loss during DNN training/fine-tuning and assess its effectiveness in increasing representational alignment (measured by standard metrics and prototype similarity distributions) compared to baseline models trained without PCA.
4.  **Evaluate Downstream Consequences:** Assess the impact of PCA-induced alignment on the DNN's task performance (e.g., classification accuracy), transfer learning capabilities, and behavioral alignment with humans (e.g., comparing error patterns or feature importance maps).

**2.4 Significance**
This research directly addresses central themes of the Re-Align workshop, particularly concerning *when and why* systems learn aligned representations and *how* we can intervene on this alignment. By introducing interpretable prototypes and a mechanism for steering alignment, PCA offers a potential solution to several key challenges in the field. Successful development of PCA would provide:
*   A novel, interpretable metric for representational alignment that complements existing measures.
*   A practical tool for researchers aiming to build AI systems with more human-like internal representations, potentially leading to improved robustness, generalization, and interpretability in AI.
*   A computational framework for neuroscience and cognitive science to identify shared representational principles between brains and models, using prototypes as candidate computational motifs.
*   A concrete methodology fostering interdisciplinary research by providing a common ground (prototypes) for discussing alignment across machine learning, neuroscience, and cognitive science.
*   An advance towards understanding the implications of representational alignment for behavioral and potentially value alignment.

Overall, this work aims to make significant contributions to our understanding and manipulation of representational alignment across biological and artificial intelligence.

## 3. Methodology

**3.1 Data Collection and Preparation**
This research will leverage existing publicly available datasets containing paired stimuli and corresponding neural recordings, as well as standard DNN models.
*   **Stimuli:** We will primarily use natural image datasets commonly employed in vision research, such as subsets of ImageNet (Deng et al., 2009), COCO (Lin et al., 2014), or specialized datasets designed for neuroscience experiments like the THINGS database (Hebart et al., 2019). The key requirement is a diverse set of stimuli for which both neural responses and DNN activations can be obtained.
*   **Neural Data:** We will utilize human neuroimaging data, prioritizing fMRI datasets due to their spatial resolution and availability (e.g., the Allen Institute's MindScope database, Human Connectome Project datasets, or THINGS database fMRI/MEG data). We may also explore EEG data (e.g., associated with Lu et al., 2024) or publicly available intracranial recordings (ECoG/sEEG) if suitable paired datasets exist. Preprocessing will follow established pipelines specific to each modality (e.g., motion correction, normalization, voxel selection for fMRI; artifact rejection, filtering, source localization for EEG/MEG). For each stimulus presentation, we will extract a feature vector representing the neural response (e.g., averaged voxel activation patterns in specific ROIs for fMRI, time-frequency features for EEG/MEG). Let $B = \{b_1, b_2, ..., b_N\}$ denote the set of neural response vectors for $N$ distinct stimuli.
*   **DNN Models and Activations:** We will employ standard pre-trained DNN architectures for computer vision, such as ResNet (He et al., 2016) and Vision Transformer (ViT; Dosovitskiy et al., 2020). We will extract activations from various layers (early, middle, late) in response to the same stimuli used for neural recordings. Let $D_l = \{d_{l,1}, d_{l,2}, ..., d_{l,N}\}$ denote the set of activation vectors from layer $l$ of the DNN for the $N$ stimuli. We will primarily focus on aligning representations from intermediate and later layers, which are often found to correlate better with higher-level brain areas.

**3.2 Stage 1: Prototype Identification via Joint Clustering**
The goal of this stage is to identify a set of $K$ prototypes $P = \{p_1, ..., p_K\}$ that capture shared representational structure across the neural data $B$ and DNN activations $D_l$ from a specific layer $l$.
1.  **Feature Preparation:** Since brain and DNN representations live in potentially very different spaces, direct concatenation might be problematic. We will explore two main approaches:
    *   **Similarity-Based Clustering:** Compute Representational Dissimilarity Matrices (RDMs; 1 - correlation distance) for both brain ($RDM_B$) and DNN ($RDM_{D_l}$) data across the $N$ stimuli. Combine these RDMs (e.g., weighted average: $RDM_{Joint} = \alpha RDM_B + (1-\alpha) RDM_{D_l}$) and apply spectral clustering or hierarchical clustering to $RDM_{Joint}$ to partition the $N$ stimuli into $K$ clusters.
    *   **Joint Embedding:** Project both $b_i$ and $d_{l,i}$ into a common latent space using techniques like Canonical Correlation Analysis (CCA) or learn a joint embedding space specifically for clustering. Alternatively, after appropriate normalization (e.g., unit length) and possibly dimensionality reduction (e.g., PCA) applied separately to $B$ and $D_l$, we can concatenate the representations $[b'_i, d'_{l,i}]$ for each stimulus $i$ and then apply standard clustering algorithms like k-means directly in this combined space.
2.  **Clustering:** Apply a suitable clustering algorithm (e.g., k-means, spectral clustering, Gaussian Mixture Models) to the prepared features (either based on $RDM_{Joint}$ or the joint/concatenated embeddings) to group the $N$ stimuli into $K$ clusters, $C_1, ..., C_K$. The number of prototypes, $K$, will be treated as a hyperparameter, determined using model selection criteria (e.g., silhouette score, stability analysis) or based on prior hypotheses about the data's semantic structure.
3.  **Prototype Definition:** Each prototype $p_k$ is defined as the centroid of the $k$-th cluster. If using the joint embedding approach with concatenated features $[b'_i, d'_{l,i}]$, the prototype $p_k$ can be considered the centroid of the $d'_{l,i}$ components for stimuli $i \in C_k$. Alternatively, it can be the centroid of the neural responses $b'_i$ for $i \in C_k$, or a combination thereof. For our primary goal of steering DNNs, we will define the prototypes based on the *neural* contributions to the cluster centroids, ensuring the target for alignment is brain-derived. Specifically, if using joint embedding/clustering of $[b'_i, d'_{l,i}]$, prototype $p_k$ can be defined as the mean of the $b'_i$ vectors for all stimuli $i$ assigned to cluster $C_k$. Let $I(i) = k$ denote that stimulus $i$ belongs to cluster $k$.
    $$ p_k = \frac{1}{|C_k|} \sum_{i: I(i)=k} b'_i $$
    where $b'_i$ is the potentially normalized/reduced neural representation for stimulus $i$. These $K$ prototypes $P = \{p_1, ..., p_K\}$ form the interpretable anchor set. We will also store the mapping $I: \{1..N\} \to \{1..K\}$ indicating which prototype corresponds to each stimulus.

**3.3 Stage 2: Prototypical Contrastive Alignment (PCA) Loss and DNN Training**
The goal of this stage is to train or fine-tune a DNN such that its representations $z_i$ (activations from a target layer, potentially different from the layer $l$ used for initial prototype discovery, or even the same layer being fine-tuned) align with the brain-derived prototypes $P$.
1.  **PCA Loss Formulation:** We adapt the prototypical contrastive loss (Li et al., 2020). For a DNN representation $z_i$ corresponding to input stimulus $i$, let $p_{I(i)}$ be the target prototype derived from brain data for the cluster containing stimulus $i$. The loss encourages $z_i$ to be similar to $p_{I(i)}$ and dissimilar to other prototypes $p_j$ where $j \neq I(i)$. We define the PCA loss for a single sample $i$ as:
    $$ L_{PCA}(z_i, P) = -\log \frac{\exp(\text{sim}(z_i, p_{I(i)}) / \tau)}{\sum_{k=1}^K \exp(\text{sim}(z_i, p_k) / \tau)} $$
    Here, $\text{sim}(u, v)$ is the cosine similarity: $\text{sim}(u, v) = \frac{u^T v}{\|u\| \|v\|}$. $\tau$ is the temperature hyperparameter, controlling the sharpness of the distribution. A lower $\tau$ enforces stronger separation.
2.  **DNN Training/Fine-tuning:** The PCA loss is incorporated into the DNN's training objective.
    *   **Fine-tuning:** For a pre-trained DNN, we fine-tune its weights by minimizing a combined loss function over batches $B$ of training data:
        $$ L_{total} = L_{task} + \lambda L_{PCA}^{batch} $$
        where $L_{task}$ is the original task loss (e.g., cross-entropy for classification), $L_{PCA}^{batch} = \frac{1}{|B|} \sum_{i \in B} L_{PCA}(z_i, P)$, and $\lambda$ is a hyperparameter weighting the contribution of the alignment loss. The representations $z_i$ are typically taken from one or more layers of the network being fine-tuned.
    *   **Training from Scratch:** The PCA loss can also be included from the beginning of training, potentially guiding the network towards brain-aligned solutions earlier in the learning process.
3.  **Implementation Details:** We will implement this framework using standard deep learning libraries (PyTorch or TensorFlow). Hyperparameters ($K$, $\tau$, $\lambda$, choice of DNN layer(s) for $z_i$, joint clustering method) will be tuned using a validation set of stimuli/neural data, separate from the test set used for final evaluation.

**3.4 Experimental Design and Evaluation**
We will conduct a series of experiments to validate the PCA framework according to our objectives.
1.  **Baselines:** We will compare models trained/fine-tuned with PCA against several baselines:
    *   Standard DNNs (ResNet, ViT) trained only with $L_{task}$ (off-the-shelf pre-trained models, or models fine-tuned on the specific stimulus set without alignment).
    *   DNNs aligned using established methods:
        *   Linear Regression: Mapping DNN activations to predict brain activity (post-hoc).
        *   RSA-based Alignment: Incorporating an RSA similarity matching term into the loss function.
        *   CCA-based methods: Maximizing correlation in a learned latent space (can be used for fine-tuning).
2.  **Evaluation Metrics:**
    *   **Representational Alignment:**
        *   *RSA:* Compute RDMs for the final DNN layer representations (and intermediate layers) and the corresponding brain data (on a held-out test set of stimuli). Calculate the Spearman correlation between the upper triangles of the DNN RDM and the brain RDM. Higher correlation indicates better alignment.
        *   *Linear Encoding Performance:* Train linear regression models to predict neural activity ($b_i$) from DNN activations ($z_i$) on the test set. Report the prediction accuracy (e.g., Pearson correlation between predicted and actual activity, averaged across voxels/channels/units).
        *   *Prototype Similarity Distribution (Proposed Metric):* For each test stimulus $i$, compute the similarity vector $S_i = [\text{sim}(z_i, p_1), ..., \text{sim}(z_i, p_K)]$. Analyze the properties of these distributions. We expect aligned models to show higher similarity to the correct prototype $p_{I(i)}$ and lower similarity to others. Define aggregate metrics based on this, such as the average log-likelihood based on the PCA loss formula evaluated on the test set, or the classification accuracy of predicting the stimulus cluster $I(i)$ from $z_i$ using the prototypes.
    *   **Neural Predictivity:** This is directly measured by the Linear Encoding Performance described above. We will perform layer-wise analysis to see how PCA affects alignment across the DNN hierarchy.
    *   **Task Performance:** Evaluate the DNN's performance on its original task (e.g., ImageNet classification accuracy, accuracy on the specific stimulus set if labeled) to quantify any trade-offs between alignment and task capability. We will also assess performance on related transfer learning benchmarks.
    *   **Behavioral Alignment:**
        *   *Error Consistency:* Compare the pattern of classification errors made by the DNN with human error patterns on the same stimuli (if available).
        *   *Feature Importance Alignment:* Generate feature attribution maps (e.g., using Grad-CAM or Integrated Gradients) for the DNN's decisions. Compare these maps (e.g., using correlation or structural similarity index) to human saliency maps collected for the same images or feature importance judgments (cf. Mahner et al., 2024).
3.  **Ablation Studies:** To understand the contribution of different components of PCA:
    *   Compare joint clustering vs. using prototypes derived solely from clustering brain data.
    *   Vary the number of prototypes $K$.
    *   Analyze the effect of the alignment strength parameter $\lambda$.
    *   Evaluate the impact of applying PCA loss at different stages of training (from scratch vs. fine-tuning) and to different layers.
    *   Compare different similarity functions within the PCA loss.

**3.5 Prototype Interpretability:**
Beyond quantitative evaluation, we will qualitatively analyze the learned prototypes. For each prototype $p_k$, we will examine the stimuli $i$ belonging to its cluster $C_k$. By identifying common visual, semantic, or conceptual properties of these stimuli, we aim to assign meaningful interpretations to the prototypes, demonstrating their utility as interpretable anchors.

## 4. Expected Outcomes & Impact

**4.1 Expected Outcomes**
Based on the proposed methodology, we anticipate the following outcomes:
1.  **Successful Implementation of PCA:** A functioning pipeline for joint brain-DNN clustering, prototype extraction, and PCA loss-based DNN training/fine-tuning.
2.  **Enhanced Representational Alignment:** DNNs trained with the PCA loss will exhibit significantly higher representational alignment with corresponding brain data compared to baseline models, as measured by standard metrics (RSA correlation, linear encoding accuracy).
3.  **Validation of Prototype Similarity as a Metric:** The distribution of DNN representation similarities to the prototypes will prove to be an informative alignment metric. We expect PCA-trained models to show sharp distributions, with high similarity to the target prototype and low similarity to others, providing an interpretable measure of alignment quality.
4.  **Demonstration of Effective Intervention:** The PCA loss will function as an effective regularizer, demonstrably steering DNN representations towards brain-like configurations during the learning process. This will be evidenced by improved alignment scores and potentially altered learning dynamics.
5.  **Quantifiable Impact on Downstream Tasks:**
    *   We expect minimal degradation, and potentially even improvements, in the DNN's primary task performance, especially regarding robustness or out-of-distribution generalization, due to the incorporation of biologically-inspired representational constraints.
    *   We anticipate enhanced behavioral alignment, with PCA models showing error patterns and feature importance maps that more closely resemble human counterparts compared to baseline DNNs.
6.  **Interpretable Prototypes:** The joint clustering process will yield a set of prototypes ($P$) that capture meaningful, shared representational structures. Qualitative analysis of the stimuli associated with each prototype will allow for semantic interpretation, providing insights into the common representational dimensions used by both brain and model.
7.  **Insights into Alignment Factors:** Ablation studies will clarify the importance of joint clustering, the number of prototypes ($K$), the alignment strength ($\lambda$), and the choice of DNN layer for achieving optimal alignment.

**4.2 Impact**
The successful completion of this research will have significant impacts across multiple domains, directly contributing to the goals of the Re-Align community:
*   **Advancing Alignment Methodology:** PCA will provide the field with a novel tool that integrates measurement, interpretation, and intervention within a single framework. The use of interpretable prototypes directly addresses a key limitation of current methods, while the contrastive loss offers a principled way to actively shape representations. This contributes directly to the workshop themes of developing better alignment metrics and methods for intervention.
*   **Building More Human-Like AI:** By enabling the training of DNNs with representations demonstrably closer to those in the human brain, PCA could pave the way for AI systems that are not only more effective but also potentially more robust, interpretable, and aligned with human perception and cognition. This connects to the workshop question regarding the implications of increasing alignment.
*   **Bridging AI and Neuroscience:** The framework offers a concrete computational approach to test hypotheses about shared coding principles in biological and artificial systems. The prototypes themselves could represent fundamental computational building blocks or semantic categories, providing valuable insights for cognitive neuroscience and computational modeling.
*   **Enhancing Reproducibility and Collaboration:** By providing a well-defined methodology and potentially releasing code, this work can facilitate reproducibility and serve as a common ground for researchers across disciplines interested in representational alignment, fostering the collaborative spirit promoted by the Re-Align workshop.
*   **Foundation for Future Work:** The PCA framework can be extended in various directions, such as incorporating temporal dynamics (using EEG/MEG), applying it to other modalities (e.g., language), exploring hierarchical prototype alignment across multiple DNN layers and brain regions, and investigating the relationship between prototype alignment and value alignment.

In conclusion, the proposed Prototypical Contrastive Alignment framework offers a promising approach to tackle critical open questions in representational alignment. By focusing on interpretable prototypes and providing a mechanism for direct intervention, this research has the potential to significantly advance our ability to compare, understand, and shape representations in both artificial and biological intelligent systems.