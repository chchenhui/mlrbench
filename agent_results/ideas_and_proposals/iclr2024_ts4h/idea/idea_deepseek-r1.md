**Title:** Robust and Interpretable Foundation Models for Healthcare Time Series with Irregular Sampling  

**Motivation:** Healthcare time series data often suffer from irregular sampling, missing values, and noisy labels, limiting the applicability of existing foundation models. Clinicians require interpretable predictions to trust and act on AI insights, yet current models lack transparency and robustness to data imperfections. Addressing these gaps is critical for deploying reliable models in real-world healthcare settings.  

**Main Idea:** We propose a self-supervised foundation model for multimodal healthcare time series that inherently handles irregularity and missing data while providing interpretable outputs. The model uses a transformer architecture with *time-aware attention* that weights observations based on sampling intervals and uncertainty. A masked reconstruction objective during pre-training encourages robustness to missing values. For explainability, we integrate a feature importance module that identifies influential time points and modalities via attention gradients. The model is pre-trained on diverse datasets (EHR, wearables, ECG) and fine-tuned for tasks like sepsis prediction. Expected outcomes include state-of-the-art performance on irregularly sampled data, reduced sensitivity to missing values, and actionable explanations for clinicians. This work bridges the gap between foundation models’ scalability and healthcare’s need for reliable, interpretable tools.