Title: Physics-Integrated Deep Operator Networks for Subgrid-Scale Climate Surrogates

Motivation:  
Global climate models (GCMs) are limited by coarse grids that cannot resolve crucial subgrid processes (e.g., convection, cloud formation). Traditional parameterizations are empirical, expensive, and often poorly generalize to extreme events. A universal, efficient surrogate that respects physical laws would dramatically speed up simulations and improve fidelity.

Main Idea:  
We propose training a physics–informed Deep Operator Network (DeepONet) to learn the mapping from resolved-scale state variables (temperature, humidity, wind fields) to subgrid-scale fluxes and tendencies. Training data come from high-resolution cloud-resolving simulations. We embed conservation laws (mass, energy) and symmetries (Galilean invariance) as hard constraints or penalty terms in the loss. An active-learning loop identifies high-uncertainty regimes (e.g., deep convection) and selectively augments the dataset. Once trained, the surrogate module replaces conventional parameterizations in a GCM, achieving ~10× speed-up with <5% bias in key climate indicators. Beyond weather and climate, this framework generalizes to other multiscale PDE systems, offering a universal AI method for bridging scales in complex physical models.