**Title:** Probing Pre-training Data Influence on Emergent Abilities via Representation Perturbation

**Motivation:** Foundation models exhibit surprising emergent capabilities like complex reasoning, yet we lack understanding of how specific pre-training data contributes to these abilities. Identifying critical data subsets is key to efficient training and potentially cultivating desired skills or mitigating undesirable ones without costly full re-training.

**Main Idea:** This research proposes investigating the influence of pre-training data subsets on emergent abilities by analyzing their impact on learned representations. We hypothesize that critical data significantly shapes specific regions of the representation space crucial for emergent tasks. We will first identify pre-training data clusters (e.g., code, mathematical texts, dialogues). Then, using techniques inspired by representation engineering or causal mediation analysis, we will selectively perturb or ablate representation components strongly associated with these clusters in a pre-trained FM. By measuring the downstream impact on specific emergent abilities (e.g., performance on GSM8K, BIG-Bench reasoning tasks), we can quantify the influence of different data types, providing insights into data curation for capability development.