**Title:** Self-Supervised Temporal Contrastive Learning for Incomplete and Irregular Time Series in Minority Health Applications  

**Motivation:** Minority healthcare applications (e.g., rare diseases, pediatrics, ICU) face challenges due to sparse, incomplete, and irregularly sampled time series data with limited labels. Existing models struggle with missing values, temporal irregularities, and insufficient data, hindering robust representation learning. Addressing these issues could unlock actionable insights for underrepresented populations.  

**Main Idea:** Propose a **self-supervised framework** combining temporal contrastive learning and missing-value-aware imputation. Key innovations: 1) Augment time series with synthetic missing values/outliers and temporal irregularities during training, 2) Contrastive loss guided by temporal dynamics (e.g., future step prediction, temporal order recovery) to enforce structured representations, 3) Adversarial imputation networks embedded into the model to handle missing data during contrastive learning. The learned representations will generalize across heterogeneous datasets from rare diseases or ICU settings. Evaluate on clustering, prognosis prediction, and anomaly detection tasks using open datasets (e.g., pediatric ICU waves). This approach promises improved robustness to sparse/incomplete data while maintaining interpretability via temporal alignment, enabling reliable deployment in critical healthcare scenarios.