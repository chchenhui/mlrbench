**Title:** Federated Self-Supervised Representation Learning for Irregularly Sampled Pediatric Time Series

**Motivation:** Acquiring labeled, high-quality time series data in pediatrics is challenging due to privacy concerns, consent hurdles, and inherent data irregularity/sparsity. Centralizing data is often infeasible. Self-supervised learning (SSL) can leverage unlabeled data, while federated learning (FL) enables collaborative model training without data sharing, preserving privacy. This research aims to address data scarcity and privacy challenges in pediatric TSRL.

**Main Idea:** We propose a federated SSL framework for learning robust representations from irregularly sampled pediatric time series data distributed across multiple institutions (e.g., different hospitals). The core idea involves adapting contrastive or reconstructive SSL objectives (e.g., TS2Vec, TF-C) to handle irregular sampling and operate within an FL setting (e.g., FedAvg, FedProx). Local models learn representations from sparse, irregular data, potentially using imputation-aware encoders or time-aware attention. Only model updates or representations are aggregated centrally, preserving patient privacy. Expected outcomes include robust pediatric patient representations learned collaboratively without sharing raw data, improving performance on downstream tasks (e.g., growth anomaly detection, developmental delay prediction) compared to single-institution or centralized non-private approaches.