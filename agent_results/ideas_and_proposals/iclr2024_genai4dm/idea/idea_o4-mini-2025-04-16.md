Title: Physics-Constrained Diffusion World Models for Sample-Efficient Planning

Motivation:  
Model-based reinforcement learning on raw pixels often demands massive data to learn accurate dynamics. Diffusion models excel at capturing complex, multimodal distributions yet remain under-utilized as world models. Integrating physics priors into diffusion-based predictions can drastically reduce sample complexity, improve planning robustness, and enable effective exploration in sparse-reward tasks.

Main Idea:  
We propose a two-stage latent diffusion world model that (1) pre-trains on unlabelled video of the target domain to learn rich, multimodal dynamics priors and then (2) fine-tunes with a physics-consistency loss that enforces kinematic constraints (e.g., momentum conservation) in the latent space. At test time, the model serves as the core of a Model Predictive Control (MPC) planner: it generates diverse future rollouts via the diffusion sampler and scores them under the task reward. We further harness uncertainty in the diffusion predictions to define an intrinsic exploration bonus that guides the agent into under-modeled regions. We expect this approach to yield 5–10× improvements in sample efficiency on pixel-based control benchmarks and to demonstrate robust planning under stochastic dynamics.