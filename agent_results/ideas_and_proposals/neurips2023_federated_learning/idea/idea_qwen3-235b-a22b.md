**Title:** Efficient Prompt Tuning in Federated Learning Using Parameter-Efficient Personalization  

**Motivation:** Fine-tuning large foundation models in decentralized environments is computationally and privacy-costly. Centralized approaches require data sharing, violating regulations, while existing federated learning (FL) methods optimally update full model weights, leading to high communication overhead. Personalized prompt tuning—a parameter-efficient technique—offers a lightweight alternative, but its integration with FL remains unexplored. Addressing this gap could enable scalable, privacy-preserving adaptation of foundation models.  

**Main Idea:** Propose **FedPrompt**, a FL framework where clients train compact prompt vectors for foundation model personalization instead of updating full models. Class-level prompts are optimized using local data, while the global model remains static. The server aggregates prompts via adaptive clustering (grouping similar prompts by data heterogeneity) and updates prototypes to improve cross-client generalization. This reduces communication by orders of magnitude compared to full-model approaches. Theoretical analysis will include convergence guarantees for clustered aggregation, while experiments on healthcare and text data will measure accuracy, latency, and compression ratios against baselines like FedAvg and LoRA-based FL.  

**Outcome & Impact:** FedPrompt could democratize foundation model adaptation for resource-constrained, privacy-sensitive domains, enabling hospitals or banks to collaboratively strengthen models without exposing raw data. The design principles could inspire broader adoption of parameter-efficient FL frameworks.