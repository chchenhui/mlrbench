**Title**: Hierarchical Intrinsic Goal Generation for Lifelong Skill Composition  

**Motivation**: Current AI agents rely on fixed goal spaces or human-defined rewards, limiting their ability to autonomously acquire diverse skills in open-ended settings. Real-world deployment requires systems that self-generate meaningful, transferable goals and incrementally build skill repertoires without catastrophic forgetting.  

**Main Idea**: Propose a framework where agents hierarchically generate goals via dual intrinsic motivation signals: (1) a meta-controller that proposes high-level *exploration goals* based on *learning progress* (quantified by prediction error reduction) and (2) a lower-level policy that decomposes these into executable *exploitation goals* driven by *novelty* (e.g., state visitation density). Skills are stored in a neurosymbolic memory with dynamic modularity, enabling composition of prior skills to solve new tasks. To prevent forgetting, replay buffers are prioritized by skill diversity and utility. Evaluations in procedurally generated 3D environments (e.g., Minecraft-like worlds) would measure cross-domain generalization, goal diversity, and task-solving efficiency over long timescales. Success could enable lifelong learning robots or adaptive educational agents that self-direct skill acquisition.