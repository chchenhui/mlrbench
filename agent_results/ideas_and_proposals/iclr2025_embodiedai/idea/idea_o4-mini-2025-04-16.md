Title: GeoMemNet – Dynamic Geospatial Memory for Urban LLM Agents

Motivation:  
Large language model agents excel at text reasoning but falter in open-city navigation and spatial awareness. Without a persistent, structured memory of streets, landmarks and temporal context, they make suboptimal route choices and fail in complex outdoor tasks like search-and-rescue or last-mile delivery.

Main Idea:  
We introduce GeoMemNet, a modular geospatial memory layer that augments an LLM’s reasoning with dynamic map context. At each timestep, the agent queries a vectorized memory bank built from OpenStreetMap tiles and on-the-fly sensory inputs (e.g., street‐view images, GPS). GeoMemNet encodes local street graphs into embeddings, stores visited nodes, and retrieves relevant spatial subgraphs to inform the LLM’s next‐action prompts. Training combines imitation learning on human trajectory datasets with reinforcement learning rewards for path efficiency and goal attainment. We evaluate on a large-scale urban simulator, measuring success rate, detours avoided, and planning latency. GeoMemNet bridges the gap between symbolic city representations and LLM planning, enabling robust, scalable outdoor embodied intelligence.