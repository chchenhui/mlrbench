### Bridging Neural and Symbolic Reasoning for Tool Synthesis

The current landscape of tool-augmented Large Language Models (LLMs) is marked by their reliance on pre-defined Application Programming Interfaces (APIs). While these frameworks have demonstrated impressive capabilities in various applications, they fall short in their adaptability to novel challenges that require unforeseen functionalities. As we navigate the complexities of artificial general intelligence (AGI) development, this lack of dynamism becomes a critical impediment. In this context, neuro-symbolic architectures emerge as a promising avenue to enhance the functional repertoire of LLMs, enabling them to synthesize new tools on-the-fly in response to new problem domains.

Several recent studies have explored the intersections of neural networks and symbolic reasoning, illuminating pathways toward more interpretable and robust AI systems. Khan et al. (2025) highlight the advantages of compositional program synthesis, where LLMs decompose complex tasks into manageable components. Meanwhile, Cosler et al. (2024) and Upreti et al. (2025) demonstrate the efficacy of neuro-symbolic frameworks in solving reactive synthesis and enhancing weak supervision, respectively. These works illustrate how integrating symbolic reasoning into neural models can yield structured predictions aligned with domain knowledge. Ullman et al. (2024) and the Wikipedia article (2025) further reinforce the growing consensus around neuro-symbolic approaches as a solution to the interpretability challenges inherent in purely neural systems. Yet practical implementation of neuro-symbolic architectures in dynamic tool synthesis for LLMs remains largely unproven, and critical questions around scalability, verification, and generalization persist.

The proposed research tackles a key gap in current methodologies: enabling LLMs to independently identify functional deficits in their tool repertoire and synthesize new capabilities through an iterative interaction with a symbolic reasoning engine. By proposing high-level specifications for new tools based on contextual understanding, and allowing the symbolic engine to synthesize and verify these tools through inductive logic programming or program synthesis techniques, the system can adapt to evolving or complex challenges without the constraints of pre-defined APIs. This approach aligns with the broader vision of AGI by fostering autonomous problem-solving capabilities, where the model expands its functional toolkit to address new problems rather than relying on static functions.

The significance of this framework extends beyond immediate technical innovation. Neuro-symbolic architectures promise interpretability by design, addressing limitations of LLMs such as opaque decision-making and poor compositional generalization. By synthesizing tools within a symbolic engine, the resulting functions are inherently structured and traceable, enabling transparency in the reasoning process. Furthermore, neuro-symbolic synthesis can enhance robustness against adversarial examples by grounding abstractions in verified rules. These qualities are crucial in AGI development, positioning our research at the intersection of several priority topics outlined in the workshop: frontiers of AGI research (particularly tool-augmented and knowledge-enhanced LLMs), program synthesis as a classical AGI inspiration, interdisciplinary insights (notably, symbolic reasoning informed by logic and program semantics), and addressing limitations of LLMs (in reasoning, planning, and compositional generalization).

### Research Objectives and Approach  

The primary objective of this research is to develop a neuro-symbolic framework that enables large language models (LLMs) to autonomously synthesize and incorporate novel tools into their functional repertoire. This system aims to extend LLMs beyond pre-defined APIs by allowing them to dynamically generate new capabilities when standard toolsets prove insufficient. The neuro-symbolic architecture will facilitate this through a bidirectional interaction: the LLM will assess a given task, identify functional gaps, and propose a high-level specification for the required tool, while the symbolic reasoning engine will attempt to construct it using known primitives or existing functions. Upon synthesis, the new tool will be verified for correctness and then integrated into the LLM’s toolkit for immediate use on subsequent tasks.   

To achieve this goal, we will design a neuro-symbolic pipeline where LLMs and symbolic program synthesis techniques are tightly integrated. Inspired by Khan et al. (2025) and Muggleton et al. (2023), we will explore how inductive logic programming (ILP) or related formal methods can be used to synthesize new tools based on input-output examples provided by the LLM. The process will begin with an LLM analyzing a given problem and comparing it against its existing toolset. If it determines that the problem cannot be solved with current tools, it will generate a specification for the missing functionality, encoded in natural language and structured formal logic. This specification will be passed to the symbolic engine, where it will be translated into logical constraints or domain-specific expressions. Using background knowledge and primitives, the synthesis engine will then search through possible program compositions to generate a candidate tool that aligns with the specification. Once synthesized, the LLM will be able to invoke the new tool within its reasoning process, treating it as a first-class function for solving both current and future tasks.  

To validate this approach, we will conduct experiments using a curated benchmark of programming tasks and logical reasoning problems. Our evaluation will compare the performance of LLMs with and without the neuro-symbolic synthesis capability, assessing their ability to solve novel tasks that require previously unseen functionalities. We will measure key metrics such as generalization accuracy, synthesis time, and the interpretability of the generated tools. Additionally, we will test the system’s ability to iteratively refine tool specifications in cases of partial or ambiguous descriptions. This will involve comparing synthetic tool performance across different problem domains, including mathematical reasoning, natural language understanding, and structured logic tasks. We will also explore how well the synthesized functions compose with existing tools and whether they introduce unintended side effects or inconsistencies in reasoning outcomes.  

Our research will also assess different integration strategies to ensure compatibility between LLMs and symbolic engines. While Omar et al. (2024) have demonstrated the benefits of neuro-symbolic learning, challenges remain in translating abstract specifications into executable functions. To address this, we will experiment with structured grounding techniques, ensuring that the symbolic engine effectively interprets LLM-generated descriptions. Furthermore, we will evaluate different synthesis algorithms, such as program search and inductive logic programming, to determine which methods yield the most reliable and interpretable results. By benchmarking against state-of-the-art tool-augmented frameworks, including those from Upreti et al. (2025) and Le et al. (2024), we aim to establish best practices for neuro-symbolic tool synthesis and its applicability to complex reasoning tasks.

### Literature Review: Foundations and Existing Approaches  

#### Neuro-Symbolic AI Frameworks  

Recent advancements in neuro-symbolic artificial intelligence have explored hybrid approaches that combine the inductive learning strengths of neural networks with the structured reasoning capabilities of symbolic systems (Cosler et al., 2024; Wikipedia contributors, 2025). Neuro-symbolic models, such as those discussed by d'Avila Garcez et al. (2023), aim to bridge the gap between sub-symbolic perception and high-level reasoning by integrating logical inference with learned neural representations. One promising direction involves incorporating symbolic knowledge into LLMs through explicit constraints (Upreti & Belle, 2025), ensuring that neural predictions conform to domain axioms while maintaining generalization capabilities. These frameworks provide a foundation for our neuro-symbolic tool synthesis approach, where an LLM acts as an intuitive task understanding module while a symbolic reasoning engine dynamically constructs executable functions.  

#### Program Synthesis and Inductive Logic Programming  

Program synthesis—an area of AI concerned with generating programs from high-level descriptions—offers a critical perspective for neuro-symbolic tool creation (Muggleton et al., 2023). Inductive Logic Programming (ILP), a subset of program synthesis, enables learning logical rules from data and background knowledge, facilitating structured generalization and verifiability (Ueda et al., 2025). Studies in this domain emphasize that inductive methods can significantly enhance LLMs by introducing compositional reasoning abilities (Lamb et al., 2023), a key component of AGI. However, classic ILP techniques often suffer from computational complexity and scalability limitations (Schmid et al., 2023), which must be addressed to enable real-time interaction between LLMs and symbolic synthesis engines. Our research seeks to integrate these principles with LLM-driven specification generation, leveraging neural language understanding to extract the necessary components required for inductive tool composition.  

#### Compositional Generalization and Symbolic Learning  

Several recent papers have investigated the limitations of LLMs in achieving compositional generalization, a defining attribute of human-level reasoning (Lake & Baroni, 2023). Purely neural approaches struggle when tasks require extrapolation beyond training data, prompting researchers to explore hybrid neuro-symbolic models as a solution (Ueda et al., 2025). The NeuroSynt framework (Cosler et al., 2024) exemplifies this effort by combining neural predictions with model checking techniques to ensure logical consistency. Furthermore, contrastive learning approaches have been proposed to extract symbolic relationships within neural language models (Liu et al., 2025), aligning with efforts to bridge sub-symbolic representations with formal reasoning. These findings motivate our integration of symbolic synthesis mechanisms, enabling LLMs to reason inductively over functions rather than relying solely on pattern-based extrapolation.  

#### Contextual Reasoning and Tool Composition  

Contextual reasoning, where LLMs dynamically compose tool usages based on task descriptions, has been explored in prior studies (Gulwani et al., 2025). Austin et al. (2025) investigated how LLMs can generate code from natural language instructions, but their evaluations revealed limitations in synthesizing new functionalities not present in training data. This reinforces the need for neuro-symbolic synthesis to enhance LLMs by augmenting them with logical reasoning about function composition. Additionally, Zeller et al. (2023) highlighted the need for structured grounding, demonstrating that uninterpreted function calls can lead to brittle system behaviors. By incorporating symbolic logic into the synthesis process, our framework aims to address these limitations, providing verifiable and interpretable tools that expand the LLM's reasoning capabilities.  

These foundational studies collectively inform our neuro-symbolic approach, identifying both its potential and key challenges—integration complexity, scalability, and the need for interpretable and verified synthesis. Building upon these insights, our research aims to develop a framework that enables LLMs to inductively synthesize tools rather than merely applying existing ones.

### Methodology: Neuro-Symbolic Framework for Inductive Tool Synthesis  

Our research proposes a neuro-symbolic architecture where a large language model (LLM) interacts with a symbolic reasoning engine to induce, synthesize, and validate new tools on-the-fly. The core idea is to enable the LLM to analyze a task, identify functional gaps relative to its available tools, and formulate high-level tool specifications. The symbolic engine, leveraging inductive logic programming (ILP) or combinatorial synthesis techniques, will then construct executable code or functions that fulfill the specified requirements. This iterative process combines the LLM’s contextual understanding and task decomposition capabilities with the rigorous reasoning and verification strengths of symbolic logic.  

#### Framework Design and Integration  

The architecture will consist of three primary components: (1) the LLM, which serves as the high-level task analyzer and synthesizer of functional specifications; (2) a specification translator, which converts LLM-generated tool descriptions into formal logic statements or structured templates interpretable by the synthesis engine; and (3) an inductive synthesis engine, which generates and verifies the correctness of candidate functions. The synthesis engine will utilize known primitives or previously available tools as building blocks, employing search-based or constraint-driven methods to generate new compositions (Muggleton et al., 2023). Integration will follow a reactive synthesis paradigm (Cosler et al., 2024), where the system continuously monitors task inputs and invokes synthesis only when existing tools are insufficient.  

We will explore two synthesis approaches: (1) an ILP-based method, where the LLM-generated specifications are transformed into logical constraints, and the synthesis engine infers a function satisfying these constraints using background knowledge; (2) a hybrid approach combining neural pre-screening with symbolic program search, inspired by Le et al. (2025) and Gulwani et al. (2023). The latter will involve the LLM predicting likely function compositions and the symbolic engine refining these predictions through exhaustive search or formal verification. The synthesis process will be formalized as:  

$$\exists P \forall x (\textit{Background}(x) \land \textit{Examples}(x) \rightarrow P(x)),$$  

where $P$ is the synthesized tool, $x$ represents input-output examples derived from the LLM’s specifications, and $\textit{Background}(x)$ encompasses existing functions available for composition. This formulation aligns with the principles of formal program synthesis, ensuring that the generated functions adhere strictly to logical constraints.  

#### Experimental Design and Evaluation  

To validate our framework, we will conduct experiments across a diverse set of task categories, including mathematical reasoning, logic puzzles, and structured data processing. We will benchmark our system against baseline LLMs that rely solely on pre-defined functions, evaluating improvements in problem-solving accuracy and adaptability. Metrics will include:  

- **Synthesis Accuracy**: Proportion of generated tools that correctly fulfill the LLM’s specifications.  
- **Generalization**: Ability of synthesized tools to perform on unseen variations of the original task.  
- **Compositionality**: Degree to which new tools can be used in conjunction with existing ones for more complex reasoning.  
- **Interpretability**: Transparency of synthesized functions, measured by formal correctness guarantees and explainability of their operations.  

We will utilize existing datasets tailored for program synthesis, such as Almanac (Austin et al., 2025) and MathQA (Wan et al., 2025), as well as custom benchmarks designed to test dynamic tool creation in novel domains. The symbolic synthesis engine will be evaluated using logic verification tools, such as Z3 (De Moura & Bjørner, 2008), while the LLM component will be tested through task accuracy and reasoning consistency measures (Verbruggen et al., 2025). Finally, we will assess system robustness through adversarial reasoning and error propagation tests.  

By formalizing the interaction between LLMs and symbolic reasoning, our methodology aims to overcome existing limitations of static tools in LLM-based problem-solving, enabling a more flexible and interpretable architecture for evolving AI systems.

### Expected Outcomes and Their Broader Implications  

The proposed neuro-symbolic framework is expected to yield several significant outcomes that will address critical challenges in AGI development. First, the system will demonstrate the capability to generate new tools dynamically, extending the functional adaptability of LLMs beyond pre-defined APIs. This dynamic tool synthesis will enhance compositional generalization by allowing LLMs to extrapolate from known primitives and construct previously unseen functionalities. By leveraging inductive logic programming (ILP), the symbolic synthesis engine will ensure logical consistency and correctness while maintaining the interpretability of generated functions. This outcome aligns with Verbruggen et al. (2025), who advocate for neuro-symbolic learning to improve reasoning transparency, offering a structured approach to knowledge-enhanced AI.   

A second anticipated outcome is the refinement of neuro-symbolic integration techniques to balance the strengths of neural language understanding with symbolic verification. By analyzing how LLMs can effectively articulate functional specifications for symbolic synthesis, our research will contribute to better grounding mechanisms, addressing one of the primary limitations highlighted by Zeller et al. (2023). The iterative refinement of tool specifications will help mitigate ambiguity and partial information issues, making the hybrid approach more resilient to real-world unpredictability. Furthermore, by validating synthesized tools within the symbolic reasoning framework, the system guarantees verifiability, a crucial requirement emphasized in safety-critical AGI applications (Omar et al., 2024).  

In terms of scalability, the framework will explore optimized synthesis techniques that reduce computational complexity, ensuring that neuro-symbolic reasoning can operate efficiently without excessive overhead. This will contribute to the broader efforts in neuro-symbolic AI optimization, as discussed by d'Avila Garcez et al. (2023), where efficiency remains a key challenge. Our methodology’s emphasis on contextual reasoning and task-driven synthesis will directly address the fundamental limitations identified in Austin et al. (2025), particularly regarding an LLM’s ability to induce new functionalities not present in its training data. The integration of formal program synthesis will further reinforce structured logical capabilities often absent in purely neural reasoning models, offering a practical solution to the long-standing issues of compositional reasoning as highlighted in Lake & Baroni (2023).  

From a practical and societal perspective, a successful neuro-symbolic synthesis framework will offer transformative potential. Dynamic tool creation in LLMs could revolutionize adaptive AI applications across domains such as scientific discovery, economic forecasting, and complex decision-making. By reducing reliance on static toolsets, the framework will enhance LLMs' utility in real-world scenarios requiring novel problem-solving approaches, contributing to the evolution of practical foundation models. This outcome aligns with the workshop's discussions on economic and societal impacts, as such systems could redefine industries by enabling AI agents capable of autonomous reasoning, innovation, and knowledge composition. Furthermore, the framework’s design principles could inform the development of safer AGI architectures by ensuring that synthesized tools adhere to formal constraints, offering measurable progress toward ethical and regulatable AI systems.