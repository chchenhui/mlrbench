Title: CrossModMark – Robust Cross-Modal Watermarking for Multi-Modal Generative Models

Motivation:  
As multi-modal foundation models (MFMs) increasingly produce text, images, audio, and video, malicious actors can exploit them to generate misleading or harmful content. Existing watermarking schemes target single modalities and often fail under common transformations (e.g., compression, format conversion). A unified, modality-agnostic watermark is critical for reliable provenance tracking and content verification across diverse outputs.

Main Idea:  
CrossModMark embeds an imperceptible, shared watermark into the joint latent space of MFMs during training. We introduce a lightweight watermark encoder that injects low-magnitude perturbations into multi-modal embeddings and a detector network trained with contrastive objectives to recover the signal regardless of output modality or post-processing. Adversarial training simulates real-world manipulations—cropping, re-encoding, noise—to maximize robustness. We benchmark on leading MFMs (e.g., LLava+Stable Diffusion, Sora) assessing detection accuracy, perceptual quality, and resilience to attacks. Expected outcomes include >95% detection under diverse transformations, <1% utility loss, and easy integration via a plug-in API. CrossModMark enhances trust, curbs misuse of AI-generated media, and provides a standardized tool for regulators and platforms to enforce content authenticity.