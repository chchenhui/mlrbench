**Title:** Diffusion-based Multi-modal Inference for Ambiguous Inverse Problems in Imaging  

**Motivation:** Many real-world inverse problems, such as medical image reconstruction or astronomical imaging, are inherently ambiguous: multiple plausible solutions exist for a single input. Current diffusion-based approaches often produce deterministic outputs or limited diversity, failing to capture the full solution space. Addressing this limitation is critical for applications where exploring diverse hypotheses improves decision-making.  

**Main Idea:** We propose a diffusion framework that explicitly models ambiguity in inverse problems by generating multiple distinct yet plausible outputs. The method combines a conditional diffusion model with a latent space designed to encode uncertainty and diverse modes. During training, the model learns a distribution over solutions by conditioning on both the input data and latent codes that represent variations compatible with the forward model (e.g., noise, missing data). For inference, a hybrid sampling strategy leverages task-specific constraints (e.g., physics-based priors) while varying latent codes to generate diverse outputs. The architecture integrates cross-attention for conditioning and a likelihood-aware loss to penalize implausible solutions.  

**Expected Outcomes & Impact:** This approach will enable efficient sampling of high-quality, diverse solutions for ambiguous tasks, demonstrated on medical CT reconstruction and microscopy deconvolution. It will advance applications requiring uncertainty quantification and exploratory analysis, bridging the gap between generative modeling and scientific inverse problem solving.