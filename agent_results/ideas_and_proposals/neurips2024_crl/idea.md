**Title:** Causal Diffusion Models: Disentangling Latent Causal Factors in Generative AI  

**Motivation:** Generative models like diffusion networks excel at capturing data distributions but often learn spurious correlations due to reliance on non-causal associations. This undermines their trustworthiness in sensitive applications (e.g., healthcare), where controlling outputs via causal factors (e.g., disease features) is critical. Integrating causal representation learning (CRL) with generative frameworks could address this by isolating actionable latent variables tied to causality.  

**Main Idea:** We propose *Causal Diffusion Models (CDMs)*, which embed a causal graph structure into the latent space of diffusion models. During training, CDMs jointly optimize for data reconstruction and causal disentanglement: (1) A causal discovery module infers directional relationships among latent variables via constrained optimization or score-based methods, leveraging interventional data (if available) or domain constraints. (2) The diffusion process incorporates these causal dependencies, aligning each denoising step with the inferred graph. This enables generation guided by causal factors (e.g., "varying disease severity while keeping anatomy fixed"). Outcomes include improved control over outputs, quantifiable via counterfactual editing metrics, and reduced sensitivity to confounding features. CDMs could revolutionize applications like biomedical imaging by enabling interpretable, bias-resistant synthesis and aiding causal hypothesis testing.