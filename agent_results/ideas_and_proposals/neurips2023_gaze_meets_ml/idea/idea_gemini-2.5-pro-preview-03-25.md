**Title:** Gaze-Informed Unsupervised Feature Relevance Discovery

**Motivation:** Identifying relevant features in complex data is crucial but often requires labeled data or relies on statistical assumptions misaligned with human perception. Eye gaze implicitly captures human attention patterns, offering a powerful, yet underexploited, signal for feature importance, especially in unsupervised settings where labels are absent or costly to obtain.

**Main Idea:** We propose an unsupervised method to estimate feature importance directly from eye-gaze data collected during passive observation of data instances (e.g., images, text, visualizations). The core idea is to model the relationship between gaze statistics (fixation duration, density, scanpath patterns) aggregated across multiple observers on specific input regions/features and their intrinsic relevance. We will develop a model (e.g., leveraging contrastive learning or generative models) that learns feature representations sensitive to consistent gaze patterns. Features consistently attracting human attention across diverse observers, irrespective of a specific task label, will be assigned higher importance scores. Expected outcomes include a purely attention-driven, human-centric feature ranking and improved performance in downstream unsupervised or few-shot learning tasks by prioritizing these gaze-informed features.