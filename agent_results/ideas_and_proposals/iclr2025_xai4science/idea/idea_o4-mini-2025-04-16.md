Title: CatalystXplain: Self-Explainable Graph Neural Networks for Catalyst Mechanism Discovery

Motivation:  
Catalyst development in material science is hindered by the black-box nature of deep models, forcing chemists to rely on trial-and-error and expert intuition. Embedding explainability directly into predictive models can unveil structure–activity relationships, reduce experimental overhead, and accelerate the discovery of novel catalytic mechanisms.

Main Idea:  
We propose CatalystXplain, a self-explainable Graph Neural Network (GNN) that jointly learns catalytic performance and human-readable substructure-level rules. The architecture comprises:  
1. Node- and edge-wise attention layers that highlight influential atoms and bonds;  
2. A symbolic rule-extraction module that translates high-attention subgraphs into logical “if-then” chemoinformatic rules;  
3. A multi-task decoder that aligns predictive and explanatory objectives, ensuring explanations remain faithful to performance.  
During training, CatalystXplain optimizes a combined loss—prediction error plus explanation consistency—encouraging the model to focus on chemically meaningful motifs. We validate on benchmark catalyst datasets, extract substructure rules for high-activity predictions, and experimentally test the top candidates. Expected outcomes include improved predictive accuracy, transparent mechanistic insights, and a toolkit for chemists to propose and verify new catalytic cycles.