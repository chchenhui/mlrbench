Title: Bayesian Meta-Scaling for Compute-Constrained Hyperparameter and Architecture Selection

Motivation:  
As model sizes and training budgets grow, exhaustively tuning hyperparameters (e.g., width, depth, batch size, learning rate) and architectures under fixed compute budgets becomes prohibitively expensive. A principled approach to extrapolate optimal configurations from small‐scale experiments to large models would save time, money, and energy.

Main Idea:  
We propose a Bayesian hierarchical framework that learns scaling laws across model size and hyperparameters from multi-fidelity pilot runs. Step 1: Collect performance data on small and medium models by varying width, depth, batch, and learning rate. Step 2: Fit a Bayesian nonparametric model (e.g., Gaussian process with scaling kernels) to jointly infer exponents and interactions governing loss vs. compute. Step 3: Given a target compute budget, solve a constrained Bayesian optimization problem to select the configuration that maximizes expected performance under the posterior. We incorporate multi‐armed bandit allocation for efficient data acquisition and uncertainty‐aware extrapolation to large models. Expected outcomes include a lightweight tool that predicts compute-optimal settings, reducing large‐scale tuning costs, accelerating LLM deployment, and lowering energy consumption.