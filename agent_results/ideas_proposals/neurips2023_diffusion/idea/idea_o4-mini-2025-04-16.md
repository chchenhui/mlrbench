Title: MetaDiff – Meta-Learned Adaptive Solvers for Accelerated Diffusion Sampling

Motivation:  
Diffusion models deliver state-of-the-art generation quality but require hundreds of iterative denoising steps, making real-time and resource-constrained applications impractical. Fixed‐step solvers fail to allocate computation dynamically to critical phases of the diffusion trajectory, leading to suboptimal speed/quality trade-offs. Meta‐learning an adaptive solver can dramatically reduce sampling cost without degrading fidelity.

Main Idea:  
We introduce MetaDiff, a lightweight controller network that, at each diffusion timestep, takes as input the current noisy sample, score estimate, and time coordinate, and outputs an adaptive step size and noise adjustment for the next integration. During training, MetaDiff and the base diffusion model are optimized jointly under a composite loss that balances sample quality (e.g., FID or likelihood) against total step count. By learning to skip redundant steps in low-variance regimes and refine high-complexity regions, MetaDiff achieves 5–10× fewer function evaluations on high-resolution image and audio benchmarks with negligible perceptual loss. This method generalizes across modalities and paves the way for real-time, energy-efficient diffusion-based generative systems.