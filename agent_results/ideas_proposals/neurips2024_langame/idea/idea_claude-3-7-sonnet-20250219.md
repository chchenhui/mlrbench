# Interactive Language Games for LLM Planning Enhancement

## Motivation
Large Language Models (LLMs) currently exhibit limited planning capabilities, a critical constraint for advanced reasoning and problem-solving. This limitation stems partly from their static training paradigms that lack interactive dynamics. While humans develop planning skills through social language games and iterative feedback, LLMs are trained primarily on static text corpora with supervised and preference losses. This research addresses the planning deficit in LLMs by exploring how multi-agent interactions and language games can foster dynamic planning abilities.

## Main Idea
We propose developing a multi-agent reinforcement learning framework where LLMs engage in structured language games specifically designed to enhance planning capabilities. These games involve sequential decision-making tasks where agents must communicate intentions, negotiate strategies, and coordinate actions to achieve common goals. The framework includes: (1) A suite of planning-focused language games with increasing complexity (from linear planning to hierarchical planning); (2) A self-play mechanism where agents provide feedback to each other and adapt strategies; (3) A reward system that incentivizes successful planning and execution rather than just language fluency. The expected outcome is LLMs with enhanced abilities to decompose complex tasks, identify dependencies, anticipate consequences, and adapt plans in dynamic environments. This research bridges Deep RL and Language Emergence to develop more capable and reliable AI assistants for complex real-world tasks.