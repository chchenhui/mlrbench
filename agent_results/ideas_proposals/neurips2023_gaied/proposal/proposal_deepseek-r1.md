**Research Proposal: Generative AI as a Socratic Learning Partner for Collaborative Inquiry**  

---

### 1. **Introduction**  

**Background**  
Generative AI, particularly large language models (LLMs) like ChatGPT, has transformative potential in education. While existing AI tutors excel at delivering answers, they often fail to stimulate the metacognitive skills—critical thinking, self-reflection, and collaborative inquiry—that define deep learning. The Socratic method, which emphasizes dialogue-driven exploration over direct instruction, offers a promising framework for addressing this gap. However, simulating authentic Socratic dialogue with AI remains challenging due to the need for nuanced questioning, adaptability to individual learners, and evaluation of pedagogical effectiveness.  

Recent works, such as SocratiQ (Jabbour et al., 2025) and SPL (Zhang et al., 2024), demonstrate progress in leveraging LLMs for Socratic teaching. However, these systems face limitations in personalization, dialogue authenticity, and scalable evaluation. Meanwhile, EducationQ (Shi et al., 2025) highlights the disconnect between model scale and teaching efficacy, underscoring the need for targeted pedagogical enhancements rather than purely scaling model parameters.  

**Research Objectives**  
This project aims to:  
1. Develop an LLM-based Socratic learning partner that prioritizes inquiry over instruction, using advanced prompting and fine-tuning strategies.  
2. Create a robust evaluation framework to measure the system’s ability to foster metacognitive skills, including self-correction and reflective thinking.  
3. Investigate the impact of personalized, dialogue-driven AI interactions on student engagement and learning outcomes compared to conventional AI tutoring.  

**Significance**  
By bridging the gap between generative AI capabilities and pedagogical best practices, this work addresses two critical thrusts of the GAIED workshop:  
- **GAI→ED**: Enhancing educational technology through AI systems that mimic human peer interactions.  
- **ED→GAI**: Advancing technical safeguards (e.g., bias mitigation) and evaluation frameworks to ensure AI aligns with educational goals.  
The proposed system could democratize access to high-quality Socratic dialogue, particularly in settings where peer collaboration is limited, while providing insights into the design of pedagogically effective AI.  

---

### 2. **Methodology**  

**Research Design**  
The project comprises three phases: (1) **data collection and curation**, (2) **model development** (prompt engineering and fine-tuning), and (3) **experimental validation** through user studies.  

**Data Collection**  
- **Source Data**:  
  - **Educational Dialogues**: Curate a dataset of Socratic interactions from existing tutoring transcripts (e.g., MOOC discussions, classroom Q&A logs) and synthetically generate dialogues using GPT-4, validated by educators.  
  - **Student Responses**: Collect anonymized student problem-solving sessions (e.g., math, science) with think-aloud protocols to capture reasoning processes.  
- **Annotation**: Label dialogues for Socratic elements (e.g., probing questions, counterarguments) using a taxonomy derived from educational psychology literature.  

**Model Development**  
- **Base Model**: Use Llama-3 or Mistral-7B as a foundation due to their balance of performance and computational efficiency, as suggested by EducationQ’s findings on model scale.  
- **Prompt Engineering**:  
  - Design system prompts to enforce Socratic behavior, e.g.,  
    ```  
    "Act as a curious peer learner. Ask open-ended questions to help the student clarify their reasoning. Do not provide direct answers."  
    ```  
  - Implement a **question prioritization module** that scores candidate questions based on relevance, openness, and alignment with learning objectives:  
    $$  
    \text{Score}(q) = \alpha \cdot \text{Relevance}(q, c) + \beta \cdot \text{Openness}(q) + \gamma \cdot \text{LearningObjective}(q, t)  
    $$  
    where \( c \) is the dialogue context, \( t \) is the curriculum topic, and \( \alpha, \beta, \gamma \) are tunable weights.  
- **Fine-Tuning**:  
  - Use Low-Rank Adaptation (LoRA) to fine-tune the base model on the curated Socratic dialogues, minimizing the cross-entropy loss:  
    $$  
    \mathcal{L} = -\sum_{i=1}^N \log P(y_i | x_i, \theta)  
    $$  
    where \( (x_i, y_i) \) are input-output pairs of student statements and Socratic responses.  

**Experimental Validation**  
- **Baselines**: Compare against (1) a standard LLM tutor (e.g., ChatGPT with instructional prompts) and (2) a rule-based Socratic system (e.g., SocratiQ).  
- **Metrics**:  
  - **Quantitative**:  
    - *Question Quality*: Ratio of open-ended to closed-ended questions generated by the AI.  
    - *Student Elaboration*: Average response length and coherence score (using BERTScore).  
    - *Self-Correction Rate*: Frequency of students revising initial answers after AI interaction.  
  - **Qualitative**:  
    - Thematic analysis of dialogue transcripts for critical thinking indicators (e.g., hypothesis generation, counterargument acknowledgment).  
    - Post-session surveys measuring perceived engagement and metacognitive growth.  
- **User Study**:  
  - **Participants**: 120 high school/undergraduate students divided into control (standard tutor) and experimental (Socratic AI) groups.  
  - **Tasks**: Solve ill-structured problems (e.g., ethical dilemmas, open-ended math proofs) requiring iterative reasoning.  
  - **Procedure**:  
    1. Pre-test to assess baseline problem-solving skills.  
    2. Three 45-minute sessions with the assigned AI partner.  
    3. Post-test and structured interviews to evaluate learning gains and reflective thinking.  

---

### 3. **Expected Outcomes**  

1. **Technical Contributions**:  
   - A novel LLM fine-tuning framework optimized for Socratic dialogue, integrating prioritization mechanisms for question quality.  
   - Open-source tools for generating and evaluating educational dialogues, fostering community-driven improvements.  

2. **Empirical Insights**:  
   - Quantitative evidence that Socratic AI interactions increase self-correction rates by 20–30% compared to conventional tutors.  
   - Identification of prompt engineering strategies that maximize student elaboration (e.g., iterative scaffolding vs. single-turn questioning).  

3. **Theoretical Impact**:  
   - A validated taxonomy of Socratic dialogue elements that correlate with metacognitive skill development.  
   - Guidelines for balancing pedagogical effectiveness and computational efficiency in educational AI, addressing EducationQ’s critique of model scale.  

**Broader Impact**  
- **Educational Equity**: Enable scalable access to high-quality Socratic mentoring, particularly in under-resourced schools.  
- **AI Safety**: Demonstrate methods to align generative AI with human-centered educational values, mitigating risks like over-reliance on AI solutions.  
- **Community Building**: Foster GAIED’s multilingual community by bridging technical AI research, pedagogical expertise, and classroom deployment challenges.  

---

### 4. **Conclusion**  

This proposal outlines a rigorous approach to developing and evaluating a generative AI system that prioritizes inquiry over instruction. By leveraging advances in prompt engineering, fine-tuning, and educational theory, the project aims to create a tool that not only enhances learning outcomes but also advances our understanding of how AI can complement human pedagogy. The results will provide actionable insights for educators, AI researchers, and policymakers navigating the opportunities and challenges of AI in education.