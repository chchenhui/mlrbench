**Title:** Large Language Model-Guided Prior Elicitation for Bayesian Optimization

**Motivation:** Bayesian Optimization (BO) efficiency heavily relies on the quality of the prior, typically encoded in a Gaussian Process. Specifying informative priors is challenging, especially for non-experts or in high-dimensional spaces, limiting BO's applicability in complex scientific discovery tasks where function evaluations are expensive.

**Main Idea:** We propose using Large Language Models (LLMs) to automatically elicit informative priors for BO. An LLM, prompted with a natural language description of the optimization problem (e.g., target function characteristics, domain constraints from scientific literature), will generate parameters for the prior distribution (e.g., suggesting relevant input dimensions, appropriate kernel types, hyperparameter ranges for the GP surrogate model). This LLM-generated prior can bootstrap the BO process, potentially leading to faster convergence by focusing exploration on more promising areas identified through the LLM's distilled knowledge. We will evaluate this approach on benchmark optimization tasks and real-world problems like hyperparameter tuning or material design, measuring the reduction in required function evaluations compared to standard priors.