Title: Adaptive Dual-Layer Watermarking for Robust Generative AI Outputs

Motivation:  
Current watermarking schemes in generative AI can be stripped or degraded by adversarial attacks, and static keys quickly become vulnerable. A resilient watermark must survive content transformations (paraphrasing, compression) while remaining imperceptible and preserving generation quality.

Main Idea:  
We propose a two-tier watermarking framework combining (1) token-level embedding—a lightweight, imperceptible signature injected during decoding—and (2) latent-space perturbations—a subtle but globally consistent modification applied to hidden activations. During training, a dynamic key-rotation mechanism periodically updates both embedding patterns, and an adversarial “removal game” is played: a differentiable attacker network learns to strip watermarks, while the generator refines its dual-layer signals to resist removal. We will evaluate robustness across text/image transformations, measure fidelity trade-offs, and publish an open benchmark. Expected outcomes include high survival rates (>95%) under paraphrase and compression attacks, minimal perceptual degradation (<1% quality loss), and an extensible protocol for industry deployment. This approach enhances traceability, deters misuse, and sets new standards for watermark security.