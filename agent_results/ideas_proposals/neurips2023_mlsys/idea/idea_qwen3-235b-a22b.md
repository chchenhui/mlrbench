1. **Title**: Hierarchical Reinforcement Learning for Carbon-Aware Job Scheduling in Distributed Datacenters  

2. **Motivation**: Datacenters account for ~2% of global COâ‚‚ emissions, yet most scheduling algorithms prioritize performance over sustainability. Existing approaches often treat energy efficiency and carbon footprint as secondary objectives, leading to fragmented optimizations. With the rise of large-scale AI workloads and LLMs, there is an urgent need for holistic frameworks that balance performance, energy consumption, and real-time carbon intensity variations across geographically distributed datacenters.  

3. **Main Idea**: Propose a hierarchical reinforcement learning (HRL) framework that jointly optimizes job scheduling and resource allocation across distributed datacenters. The high-level policy dynamically allocates workloads to datacenters based on real-time carbon intensity, energy prices, and workload urgency, while low-level policies manage local resource allocation (e.g., GPU/CPU scheduling, cooling systems) using RL agents trained on synthetic and real-world datasets. The framework integrates transfer learning to adapt policies to new datacenters without retraining. To address reproducibility and benchmarking gaps, we will release an open-source simulation environment with diverse workload traces and carbon-emission profiles. Expected outcomes include a 30-40% reduction in carbon footprint compared to heuristic-based systems, while maintaining latency within 10-15% of performance-optimized baselines. This work bridges ML and systems research, enabling scalable, sustainable cloud computing and establishing a foundation for future competitions in carbon-aware scheduling.