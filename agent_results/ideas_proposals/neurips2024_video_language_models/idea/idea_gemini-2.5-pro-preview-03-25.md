**Title:** Spatio-Temporal Graph Neural Networks for High-Resolution Tactile Event Recognition

**Motivation:** High-resolution tactile sensors produce rich spatio-temporal data, but effectively modeling the dynamic interplay between local pressure changes across the sensor array remains challenging. Existing models often struggle to capture both the potentially irregular spatial layout of taxels and the complex temporal dependencies inherent in dynamic touch interactions.

**Main Idea:** We propose utilizing Spatio-Temporal Graph Neural Networks (ST-GNNs) to learn robust representations from high-resolution tactile sensor data streams. Individual taxels will be represented as nodes in a graph, with edges reflecting spatial adjacency. The ST-GNN architecture will explicitly model spatial dependencies using graph convolutions and capture temporal dynamics using recurrent or temporal convolutional layers operating on the evolving graph states. This integrated approach aims to effectively learn features for complex tactile events like slip detection, texture recognition, and contact force profiling. We expect this method to outperform baseline models on benchmark tactile datasets by better leveraging the unique spatio-temporal structure of touch information.