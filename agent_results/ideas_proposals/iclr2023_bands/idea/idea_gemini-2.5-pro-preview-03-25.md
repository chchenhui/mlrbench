**Title:** Universal Backdoor Defense via Latent Activation Trajectory Analysis

**Motivation:** Current backdoor defenses often target specific trigger types (e.g., patches, blends) and struggle against diverse or unseen attacks. A general defense mechanism is crucial for securing models against the evolving landscape of backdoor threats, especially large pre-trained models where retraining is infeasible.

**Main Idea:** We propose that backdoor triggers induce anomalous, low-dimensional trajectories in the model's latent activation space during inference, regardless of the trigger pattern. This research will develop a method to monitor activation sequences across multiple layers. By modeling the distribution of 'normal' activation trajectories using techniques like recurrent autoencoders or temporal convolutional networks trained on presumed-clean or unlabeled data, we can detect inputs whose activation paths deviate significantly. This anomaly score signals a potential backdoor trigger. The expected outcome is an attack-agnostic defense applicable even in black-box scenarios (by analyzing output probabilities over sequential processing) or with limited clean data, offering broader protection than existing methods.