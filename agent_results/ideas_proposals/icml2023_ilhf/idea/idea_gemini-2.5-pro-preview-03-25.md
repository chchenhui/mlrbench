**Title:** Meta-Learning Personalized Interpreters for Ambiguous Implicit Feedback

**Motivation:** Implicit human feedback like gaze or facial expressions offers rich interactive cues, but their meaning is often ambiguous, user-specific, and context-dependent. Systems fail if they cannot quickly learn *how* a specific user expresses intent implicitly in a given situation, especially when signals are initially ambiguous.

**Main Idea:** We propose a meta-learning framework to rapidly personalize an implicit feedback interpretation model. During interaction, the system observes high-dimensional implicit signals (e.g., gaze patterns, facial action units) alongside sparse task feedback or outcomes. A meta-learner trains a base interpreter model across diverse prior user interactions. During live interaction with a new user, this base model facilitates few-shot adaptation, quickly learning to map the current user's ambiguous signals to latent representations of their underlying state (e.g., confusion, satisfaction, preference shift). This adapted interpreter guides the primary learning agent (e.g., RL policy), enabling more responsive and personalized interaction, even when signal meanings start unclear.