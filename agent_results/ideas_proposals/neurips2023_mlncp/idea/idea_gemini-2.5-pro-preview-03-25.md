**Title:** Noise-Aware Bayesian Learning for Analog Hardware Co-Design

**Motivation:** Analog computing promises significant efficiency gains for ML but suffers from inherent noise and device mismatch, hindering reliable model training and inference. This research aims to transform these physical limitations from obstacles into potential features by developing algorithms that explicitly model and leverage hardware uncertainty.

**Main Idea:** We propose a Bayesian learning framework tailored for analog hardware. Instead of standard deterministic weights, models will learn weight distributions, naturally incorporating hardware noise statistics (measured or estimated) into the posterior inference. Training will involve optimizing variational distributions or using stochastic MCMC methods adapted to account for analog compute non-idealities (e.g., limited precision, non-linearities). This approach inherently provides uncertainty quantification, enhancing model robustness. We expect this co-design to yield models that are not only tolerant to analog variability but potentially benefit from stochasticity for regularization, leading to more efficient and reliable ML on emerging analog accelerators.