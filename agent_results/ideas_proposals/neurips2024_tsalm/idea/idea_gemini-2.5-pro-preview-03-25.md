**Title:** Context-Aware Time Series Forecasting via Dynamic Fusion of Numerical Data and Asynchronous Textual Events

**Motivation:** Standard time series models often fail to anticipate sharp changes caused by external real-world events (e.g., policy announcements, market news) because they primarily rely on numerical history. Incorporating asynchronous textual information describing these events can provide crucial context, leading to more accurate and robust forecasts, particularly in volatile domains like finance or energy.

**Main Idea:** We propose a multimodal time series forecasting framework that dynamically integrates numerical time series data with relevant textual event data. A core time series model (e.g., a transformer-based foundation model) processes the numerical sequence. Concurrently, an event detection module identifies potentially impactful text snippets (news, reports) within the forecast horizon or recent past. A large language model (LLM) encodes these texts into contextual embeddings. A gating or attention mechanism, potentially triggered by detected anomalies or high uncertainty in the numerical forecast, determines the relevance of the textual context and adaptively fuses the text embeddings with the numerical representations before generating the final forecast. This approach aims to improve prediction accuracy, especially for event-driven shifts, compared to purely numerical or statically fused multimodal models.