Title: DiffuRNAS – A Multimodal Diffusion Foundation Model for Optimized mRNA Therapeutics

Motivation:  
Designing therapeutic mRNAs demands precise UTR and codon choices to maximize protein expression while minimizing immunogenicity. Current pipelines rely on time-consuming iterative lab testing and heuristic rules, slowing down vaccine and therapeutic development.

Main Idea:  
We propose DiffuRNAS, a score-based diffusion model that learns the joint distribution of mRNA primary sequence, predicted secondary structures, and functional annotations (translation efficiency, innate immune activation). Training leverages large‐scale datasets of UTR–ORF variants with measured expression and immunogenicity. During generation, DiffuRNAS starts from noise and iteratively “denoises” to yield candidate UTR-codon architectures. A transformer backbone captures long‐range dependencies, while reinforcement learning fine-tunes the model using small batches of wet-lab feedback to bias designs toward high‐yield, low-reactivity profiles. Expected outcomes include a validated library of high-performance mRNA constructs and an open-source toolkit that reduces design cycles by >50%, accelerating mRNA vaccine and therapeutic development.