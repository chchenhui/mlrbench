Title: LLM-Driven Continuous Domain Adaptation for Zero-Shot Sim-to-Real Transfer

Motivation:  
Bridging the simulation-to-real gap remains a manual, time-consuming process that limits the rapid deployment of household robots. Automating domain randomization with minimal human intervention can accelerate policy robustness, reduce real-world data needs, and enable zero-shot transfer for diverse, unstructured tasks such as kitchen tidying or object retrieval.

Main Idea:  
We propose a closed-loop framework where a large language model (LLM) generates and refines simulation perturbations in response to policy failures. Starting from a base physics simulator annotated with scene semantics, the LLM produces natural-language instructions to vary lighting, friction coefficients, object sizes, occlusions, and distractors. A policy trained on these samples is evaluated in simulation; failure cases are fed back as prompts (“the gripper slips on ceramic mugs”) to guide the LLM in proposing targeted variations. Over successive iterations, the curriculum of environment configurations grows adaptively, focusing on edge cases most likely in real homes. We benchmark on a kitchen UR5 arm performing drawer opening, dish sorting, and utensil placement, then deploy without real-world fine-tuning. Expected outcomes include >40% drop in real-world failures, 2× faster policy convergence, and a replicable pipeline reducing manual tuning. This approach empowers scalable, data-efficient sim-to-real transfer for general-purpose robots.