```
Title: DP-Active: Privacy-Preserving Active Learning for Robust Image Classification under Data and Compute Constraints  
Motivation: In domains with resource limits (e.g., healthcare) and sensitive data, acquiring large labeled datasets is impractical. Existing active learning (AL) methods neglect privacy risks and robustness to distribution shifts—critical for trustworthy deployment. Balancing data efficiency, privacy, and robustness under computational constraints remains a key challenge.  
Main Idea: We propose DP-Active, an AL framework integrating differential privacy (DP) and robustness optimization to address data scarcity, privacy, and hardware limitations. DP-Active selects unlabeled samples for annotation by jointly modeling (1) privacy-cost estimates to minimize training data leakage and (2) distribution shift robustness gains via uncertainty quantification and worst-case risk measures. The pipeline employs a lightweight CNN architecture with quantized activations (e.g., TensorFlow Lite-compatible models) to satisfy memory and runtime constraints. During training, DP-Active dynamically adjusts its privacy budget allocation across iterations and uses efficient gradient clipping to bound sensitivity. We hypothesize that prioritizing samples with high robustness utility and low privacy risk improves accuracy with fewer labels while maintaining DP guarantees. Experiments on medical imaging datasets (e.g., CheXpert) will compare DP-Active’s trade-off curves against non-private AL and random sampling baselines, measuring accuracy, calibration under distribution shift (e.g., domain transfer), and privacy cost (epsilon). This approach could enable trustworthy, resource-aware deployment in sensitive, low-data regimes.  
```