Title: GraphLang: A Unified Graph-Language Foundation Model

Motivation: Graph-structured data underlies knowledge bases, molecules, social networks and more, yet remains largely inaccessible via natural language interfaces. Bridging language models with graph learning can empower users to query, reason about and modify complex graphs through intuitive text prompts, unlocking graph insights across domains.

Main Idea: We propose GraphLang, a multi-modal Transformer pretrained on paired graph–text corpora drawn from knowledge graphs, molecular datasets and scene graphs. Pretraining tasks include masked node/edge reconstruction, graph-to-text generation and contrastive alignment between subgraph embeddings and corresponding descriptions. We further instruction-tune GraphLang on synthetic “graph reasoning” dialogues, teaching it to extract or update subgraphs from natural language queries. At inference, GraphLang accepts a prompt (“find drug–target interactions related to kinase inhibitors”) and returns relevant subgraphs, textual explanations and candidate modifications. Expected outcomes include zero-shot graph QA, interactive subgraph retrieval and language-driven graph editing. GraphLang will democratize graph data exploration, enabling scientists and practitioners to leverage graph insights without specialized tooling.