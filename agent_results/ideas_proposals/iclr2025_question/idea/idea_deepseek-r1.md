**Title:** Real-Time Uncertainty Quantification in Autoregressive Models via Token-Level Confidence Aggregation  

**Motivation:** As large language models (LLMs) are deployed in high-stakes domains, efficiently estimating their uncertainty without computational overhead is critical. Current methods (e.g., ensembles, Monte Carlo dropout) are infeasible for real-time use due to scalability limitations, hindering trust and safety in dynamic applications like healthcare or legal advice.  

**Main Idea:** Develop a lightweight, token-level uncertainty quantification framework that aggregates the model’s inherent confidence signals during autoregressive generation. The method computes uncertainty by analyzing token probability distributions and hidden state dynamics at each generation step, then applies a learned aggregation function (e.g., attention-based weighting) to produce a real-time uncertainty score. This avoids multiple forward passes, leveraging the model’s existing outputs. The aggregation function is trained via self-supervision, using inconsistencies in the model’s predictions on perturbed inputs as pseudo-labels. Expected outcomes include a scalable UQ tool that operates with minimal latency, validated against benchmarks measuring hallucination rates and human-annotated uncertainty. Impact: Enables safer LLM deployment by providing actionable uncertainty metrics, balancing computational efficiency with reliability.