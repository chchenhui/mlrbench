**Title:** Uncertainty-Aware Federated Active Learning for Robust Medical Imaging Diagnostics  

**Motivation:** Medical imaging models often fail in real-world settings due to unseen data distributions and inadequate uncertainty quantification, risking misdiagnosis. Current methods lack frameworks to efficiently leverage multi-institutional data while prioritizing reliable predictions for uncertain cases.  

**Main Idea:** Propose a federated active learning framework that combines uncertainty quantification with collaborative model training across hospitals. Institutions locally train Bayesian neural networks to estimate per-image uncertainty, then share only uncertainty-weighted gradients (not raw data) to update a global model. High-uncertainty cases from each site trigger targeted annotation requests, optimizing expert labeling effort. This approach ensures privacy-preserving collaboration, reduces annotation costs, and produces models that explicitly flag low-confidence predictions for clinician review. Expected outcomes include improved generalization on heterogeneous datasets and a 20-30% reduction in diagnostic errors through uncertainty-guided human-AI collaboration.