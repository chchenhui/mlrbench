1. **Title**: *Adaptive Stochastic Relaxations for Differentiable Physics Simulators via Learned Discretization Thresholds*  
2. **Motivation**: Physics simulators in robotics, fluid dynamics, and climate modeling often rely on discrete approximations (e.g., grids, particles) that introduce non-differentiable operations (e.g., collision checks, threshold-based fluid interactions). Standard automatic differentiation fails here, impeding gradient-based optimization for inverse problems or control tasks. Existing differentiable simulators apply fixed smoothing parameters, which destabilize gradients in heterogeneous physical systems. A dynamic, learnable approach to relaxations is needed to balance numerical stability and physical accuracy.  
3. **Main Idea**: We propose a framework where stochastic relaxations are automatically adapted during training via a neural network that predicts optimal discretization thresholds. By modeling discretization boundaries (e.g., fluid density thresholds for phase transitions) as differentiable hyperparameters, the network learns task-specific smoothness levels for operators like contact forces or level-set dynamics. For example, in differentiable fluid simulation, the threshold for droplet merging could be relaxed using learned Gaussian distributions, with gradients estimated via reparameterization. This bridges the gap between discrete numerical methods and gradient-based learning, enabling end-to-end training of control policies for hybrid physical systems. Expected outcomes include improved convergence for inverse problems in physics (e.g., optimal control in turbulent flows) and more robust gradient estimates in systems with abrupt state changes. Impact spans robotics, computational physics, and engineered material design.