**Title:** Cross-Modal Causal Discovery for Robust Representation Learning in Multi-Environment Data  

**Motivation:** AI systems often fail under distribution shifts due to reliance on spurious correlations. Multi-modal data (e.g., images paired with text/sensors) provides complementary information, but current methods lack mechanisms to disentangle causal factors across modalities, limiting robustness. This research aims to learn causal representations invariant across environments by modeling cross-modal causal dependencies, enabling better generalization.  

**Main Idea:** Propose a framework that infers latent causal variables *shared* between modalities (e.g., image regions and textual descriptions) by aligning their causal structures across diverse environments. Use contrastive learning with modality-specific encoders to isolate environment-invariant factors, aided by differentiable causal discovery to model interactions. For identifiability, enforce sparsity in learned causal graphs and leverage interventional data (if available) to resolve ambiguities. Benchmarks include medical imaging datasets with paired diagnostic text and controlled multi-environment synthetic data. Expected outcomes: (1) improved out-of-distribution accuracy compared to non-causal multi-modal baselines, (2) interpretable cross-modal causal graphs. Impact: Enables reliable deployment in domains like healthcare, where modalities (e.g., X-rays, clinical notes) must yield stable causal insights across institutions.