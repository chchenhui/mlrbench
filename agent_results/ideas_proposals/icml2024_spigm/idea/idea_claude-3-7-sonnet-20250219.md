# Hierarchical Attention for Structured Time Series Forecasting

## Motivation
Probabilistic forecasting of structured time series is critical in domains like medicine, finance, and climate science, where data exhibits complex temporal dependencies and hierarchical patterns. Current models often struggle with effectively capturing both local patterns within individual time series and global trends across related series. This limitation hampers forecast accuracy and uncertainty quantification in critical applications like patient monitoring or financial risk assessment. Additionally, most approaches fail to incorporate domain knowledge in a principled way, limiting their interpretability and practical utility.

## Main Idea
We propose a hierarchical attention mechanism that learns to dynamically switch between local and global representations in probabilistic time series forecasting. The architecture consists of three key components: (1) a local encoder that captures temporal patterns within individual series, (2) a global encoder that models dependencies across related series, and (3) a structured attention layer that probabilistically weights the importance of local versus global information based on context and uncertainty. The model is trained using variational inference, allowing it to represent predictive uncertainty at each level of the hierarchy. By incorporating structural priors reflecting domain knowledge (e.g., physiological constraints in medical data), the model maintains interpretability while improving accuracy. We plan to evaluate this approach on healthcare monitoring data, demonstrating superior performance in both point forecasts and uncertainty calibration compared to state-of-the-art methods.