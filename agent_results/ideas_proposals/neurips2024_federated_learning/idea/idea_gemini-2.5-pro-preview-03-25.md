**Title:** Federated Meta-Learning for Adaptive Prompt Generation for Foundation Models

**Motivation:** Fine-tuning large Foundation Models (FMs) via prompting is resource-efficient, but collaboratively designing optimal prompts in federated learning (FL) without sharing private data is challenging. Client data heterogeneity can lead to conflicting prompt optimization objectives, making standard aggregation techniques for soft prompts (embeddings) suboptimal and discrete prompt averaging infeasible.

**Main Idea:** We propose a federated meta-learning framework where clients collaboratively train a central *prompt generator* model, guided by performance on local data, instead of directly averaging prompt parameters. Clients receive candidate prompts (or parameters defining prompts) from the generator, evaluate them on their private datasets, and send gradient information or performance scores back to the server. The server aggregates this feedback using a meta-optimization algorithm to update the prompt generator. This approach potentially handles heterogeneity better than direct averaging and enables the generation of prompts optimized for the diverse needs of the federation, improving FL performance for FMs.