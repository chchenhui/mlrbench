2025-05-07 18:52:32,977 - experiment_runner - INFO - ================================================================================
2025-05-07 18:52:32,977 - experiment_runner - INFO - Starting adaptive code assistant experiment
2025-05-07 18:52:32,977 - experiment_runner - INFO - Configuration: Namespace(developers=2, tasks=3, iterations=2, small_models=True)
2025-05-07 18:52:32,977 - experiment_runner - INFO - Results directory: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:52:32,977 - adaptive_code_assistant - INFO - Ensured directory exists: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:52:32,978 - adaptive_code_assistant - INFO - Random seed set to 42
2025-05-07 18:52:32,978 - adaptive_code_assistant.data - INFO - Created developer profile: developer_1
2025-05-07 18:52:32,978 - adaptive_code_assistant.data - INFO - Created developer profile: developer_2
2025-05-07 18:52:32,978 - adaptive_code_assistant - INFO - Ensured directory exists: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:52:32,979 - adaptive_code_assistant - INFO - Data saved to /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results/developer_profiles.json
2025-05-07 18:52:32,979 - adaptive_code_assistant.data - INFO - Generated 2 developer profiles
2025-05-07 18:52:33,232 - adaptive_code_assistant.data - ERROR - Failed to load dataset openai/humaneval: Dataset 'openai/humaneval' doesn't exist on the Hub or cannot be accessed.
2025-05-07 18:52:33,233 - adaptive_code_assistant.data - INFO - Created mini dataset as fallback
2025-05-07 18:52:33,233 - adaptive_code_assistant.simulation - INFO - Initialized experiment with 2 developers and 3 tasks
2025-05-07 18:52:33,233 - adaptive_code_assistant.simulation - INFO - Running simulations for model: static
2025-05-07 18:52:33,233 - adaptive_code_assistant.simulation - INFO - Simulating developer: developer_1
2025-05-07 18:52:33,233 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:38,305 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:52:38,305 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:39,901 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:52:39,901 - adaptive_code_assistant.models - INFO - Initialized fine-tuned LLM code assistant with simulated fine-tuning
2025-05-07 18:52:39,902 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:39,902 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:41,490 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:52:41,491 - adaptive_code_assistant.models - INFO - Initialized rule-based personalization assistant
2025-05-07 18:52:41,491 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:41,491 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:43,052 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:52:43,052 - adaptive_code_assistant.models - INFO - Initialized Online Learning code assistant with learning rate 0.01
2025-05-07 18:52:43,052 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:43,052 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:44,668 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:52:44,668 - adaptive_code_assistant.models - INFO - Initialized MAML code assistant with meta-learning rate 0.01
2025-05-07 18:52:44,668 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:44,668 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:44,668 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:46,533 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:52:46,533 - adaptive_code_assistant.models - INFO - Initialized Online Learning code assistant with learning rate 0.01
2025-05-07 18:52:46,533 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:46,533 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:52:48,414 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:52:48,414 - adaptive_code_assistant.models - INFO - Initialized MAML code assistant with meta-learning rate 0.01
2025-05-07 18:52:48,414 - adaptive_code_assistant.models - INFO - Initialized Hybrid Adaptive code assistant with blend factor 0.5
2025-05-07 18:52:48,414 - adaptive_code_assistant.models - INFO - Created model: static
2025-05-07 18:52:48,438 - adaptive_code_assistant - INFO - Ensured directory exists: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:52:48,439 - adaptive_code_assistant.evaluation - INFO - Initialized code evaluator
2025-05-07 18:52:48,439 - adaptive_code_assistant.simulation - INFO - Initialized coding simulation for developer developer_1 with model gpt2
2025-05-07 18:52:48,439 - adaptive_code_assistant.simulation - INFO - Running task 1/3: mini_task_8
2025-05-07 18:52:48,439 - adaptive_code_assistant.simulation - INFO - Starting task mini_task_8
2025-05-07 18:52:48,439 - adaptive_code_assistant.simulation - INFO - Iteration 1/2
2025-05-07 18:52:48,443 - experiment_runner - ERROR - Error during experiment: The following `model_kwargs` are not used by the model: ['task_type'] (note: typos in the generate arguments will also show up in this list)
Traceback (most recent call last):
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/run_experiment.py", line 137, in main
    experiment_data = experiment_runner.run_experiment()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/utils.py", line 177, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/simulation.py", line 248, in run_experiment
    session_data = simulation.run_task(task, task_type)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/utils.py", line 177, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/simulation.py", line 97, in run_task
    completion = self.code_assistant.complete_code(prompt, task_type=task_type)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/utils.py", line 177, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/models.py", line 140, in complete_code
    outputs = self.model.generate(
              ^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/miniconda3/envs/mlrbench/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/miniconda3/envs/mlrbench/lib/python3.12/site-packages/transformers/generation/utils.py", line 2255, in generate
    self._validate_model_kwargs(model_kwargs.copy())
  File "/home/chenhui/miniconda3/envs/mlrbench/lib/python3.12/site-packages/transformers/generation/utils.py", line 1524, in _validate_model_kwargs
    raise ValueError(
ValueError: The following `model_kwargs` are not used by the model: ['task_type'] (note: typos in the generate arguments will also show up in this list)
2025-05-07 18:53:24,140 - experiment_runner - INFO - ================================================================================
2025-05-07 18:53:24,140 - experiment_runner - INFO - Starting adaptive code assistant experiment
2025-05-07 18:53:24,140 - experiment_runner - INFO - Configuration: Namespace(developers=2, tasks=2, iterations=2, small_models=True)
2025-05-07 18:53:24,140 - experiment_runner - INFO - Results directory: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:53:24,140 - adaptive_code_assistant - INFO - Ensured directory exists: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:53:24,141 - adaptive_code_assistant - INFO - Random seed set to 42
2025-05-07 18:53:24,141 - adaptive_code_assistant.data - INFO - Created developer profile: developer_1
2025-05-07 18:53:24,141 - adaptive_code_assistant.data - INFO - Created developer profile: developer_2
2025-05-07 18:53:24,141 - adaptive_code_assistant - INFO - Ensured directory exists: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:53:24,142 - adaptive_code_assistant - INFO - Data saved to /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results/developer_profiles.json
2025-05-07 18:53:24,142 - adaptive_code_assistant.data - INFO - Generated 2 developer profiles
2025-05-07 18:53:24,409 - adaptive_code_assistant.data - ERROR - Failed to load dataset openai/humaneval: Dataset 'openai/humaneval' doesn't exist on the Hub or cannot be accessed.
2025-05-07 18:53:24,410 - adaptive_code_assistant.data - INFO - Created mini dataset as fallback
2025-05-07 18:53:24,410 - adaptive_code_assistant.simulation - INFO - Initialized experiment with 2 developers and 2 tasks
2025-05-07 18:53:24,410 - adaptive_code_assistant.simulation - INFO - Running simulations for model: static
2025-05-07 18:53:24,410 - adaptive_code_assistant.simulation - INFO - Simulating developer: developer_1
2025-05-07 18:53:24,410 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:29,345 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:53:29,345 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:30,981 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:53:30,982 - adaptive_code_assistant.models - INFO - Initialized fine-tuned LLM code assistant with simulated fine-tuning
2025-05-07 18:53:30,982 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:30,982 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:32,707 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:53:32,707 - adaptive_code_assistant.models - INFO - Initialized rule-based personalization assistant
2025-05-07 18:53:32,707 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:32,707 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:34,307 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:53:34,307 - adaptive_code_assistant.models - INFO - Initialized Online Learning code assistant with learning rate 0.01
2025-05-07 18:53:34,307 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:34,307 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:35,893 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:53:35,894 - adaptive_code_assistant.models - INFO - Initialized MAML code assistant with meta-learning rate 0.01
2025-05-07 18:53:35,894 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:35,894 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:35,894 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:37,486 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:53:37,487 - adaptive_code_assistant.models - INFO - Initialized Online Learning code assistant with learning rate 0.01
2025-05-07 18:53:37,487 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:37,487 - adaptive_code_assistant.models - INFO - Initialized base code assistant model: codellama/CodeLlama-7b-hf
2025-05-07 18:53:39,064 - adaptive_code_assistant.models - INFO - Loaded model and tokenizer: gpt2
2025-05-07 18:53:39,064 - adaptive_code_assistant.models - INFO - Initialized MAML code assistant with meta-learning rate 0.01
2025-05-07 18:53:39,064 - adaptive_code_assistant.models - INFO - Initialized Hybrid Adaptive code assistant with blend factor 0.5
2025-05-07 18:53:39,064 - adaptive_code_assistant.models - INFO - Created model: static
2025-05-07 18:53:39,089 - adaptive_code_assistant - INFO - Ensured directory exists: /home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/results
2025-05-07 18:53:39,090 - adaptive_code_assistant.evaluation - INFO - Initialized code evaluator
2025-05-07 18:53:39,090 - adaptive_code_assistant.simulation - INFO - Initialized coding simulation for developer developer_1 with model gpt2
2025-05-07 18:53:39,090 - adaptive_code_assistant.simulation - INFO - Running task 1/2: mini_task_8
2025-05-07 18:53:39,090 - adaptive_code_assistant.simulation - INFO - Starting task mini_task_8
2025-05-07 18:53:39,090 - adaptive_code_assistant.simulation - INFO - Iteration 1/2
2025-05-07 18:53:41,270 - adaptive_code_assistant - INFO - Function complete_code took 2.18 seconds to run
2025-05-07 18:53:41,309 - adaptive_code_assistant.evaluation - INFO - Code evaluation: Failed
2025-05-07 18:53:41,310 - adaptive_code_assistant - INFO - Function evaluate_functional_correctness took 0.04 seconds to run
2025-05-07 18:53:41,311 - adaptive_code_assistant.evaluation - INFO - Code style evaluation: 0.33
2025-05-07 18:53:41,311 - experiment_runner - ERROR - Error during experiment: CodeAssistantModel.update() got an unexpected keyword argument 'task_type'
Traceback (most recent call last):
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/run_experiment.py", line 137, in main
    experiment_data = experiment_runner.run_experiment()
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/utils.py", line 177, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/simulation.py", line 248, in run_experiment
    session_data = simulation.run_task(task, task_type)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/utils.py", line 177, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/home/chenhui/mlr-bench/claude_exp2/iclr2025_dl4c/claude_code/simulation.py", line 122, in run_task
    self.code_assistant.update(prompt, feedback, task_type=task_type)
TypeError: CodeAssistantModel.update() got an unexpected keyword argument 'task_type'
