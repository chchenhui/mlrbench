# Workshop on Bidirectional Human-AI Alignment

This workshop focuses on bidirectional Human AI alignment, a paradigm shift in how we approach the challenge of human-AI alignment, which emphasizes the dynamic, complex, and evolving alignment process between humans and AI systems. This is grounded on the "bidirectional human-AI alignment" framework (see Definition and ReadingList) derived from a systematic survey of over 400 interdisciplinary alignment papers in Machine Learning (ML), Human Computer Interaction (HCI), Natural Language Processing (NLP), more domains. Particularly, it involves two directions to maximize its benefits for human society.

- Aligning AI with Humans (AI-centered perspective): focuses on integrating human specifications into training, steering, customizing, and monitoring AI systems;
- Aligning Humans with AI (Human-centered perspective): aims to preserve human agency and empower humans to critically evaluate, explain, and collaborate with AI systems.

## Challenges & Goals
The rapid advancements in general-purpose AI has precipitated the urgent need to align these systems with values, ethical principles, and goals that match the context of use, i.e., for individuals using an AI system, and for the holistic society at large. Traditionally, AI alignment has been viewed as a static, one-way process, with a primary focus on shaping AI systems to achieve desired outcomes and prevent negative side effect. However, as AI systems are taking on more complex decision-making roles, this **unidirectional AI alignment is inadequate to capture the dynamic, complicated, and evolving interactions between humans and AI systems**.

The core objectives of this workshop are twofold: (1) broadening the current understanding of AI alignment and inviting more researchers to collectively explore the bidirectional human-AI alignment studies; (2) fostering interdisciplinary collaboration between researchers in multi-disciplinary domains, such as AI, HCI, and social sciences, creating a platform for exchange and innovation.

## Scopes & Topics
This workshop aims to explore the design space of bidirectional human-AI alignment from a comprehensive view, calling for submissions from various disciplines and topics, including but not limited to (see all in Call For Papers):

- Scope: Broader Definitions and clarifications of Current Alignment Research;
- Opinions: Position Papers and Roadmaps for Future Alignment Research;
- Specification: Representation approaches of Human Values, Behavior, Cognition, Societal Norms for AI Alignment;
- Methods: Reinforcement Learning with Human Feedback, Algorithms, Interaction Mechanisms, UX Design for Alignment;
- Evaluation: Benchmarks, Metrics or Human Evaluation for Multi-objective AI Alignment;
- Deployment: Customizable Alignment, Steerability, Interpretability, and Scalable Oversight;
- Societal Impact and Policy: Fostering an Inclusive Human-AI Alignment Ecosystem.