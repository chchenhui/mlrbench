2025-05-07 20:06:08,609 - __main__ - INFO - Starting LLM-TAC experiment at 2025-05-07 20:06:08.609152
2025-05-07 20:06:08,695 - __main__ - INFO - Configuration: model=Llama-3.1-8B, epochs=5, rl_iterations=10
2025-05-07 20:06:08,695 - data_processing - INFO - Processing Coq proof data
2025-05-07 20:06:08,695 - data_processing - INFO - Loading Coq proof data
2025-05-07 20:06:08,695 - data_processing - INFO - Creating synthetic Coq proof data
2025-05-07 20:06:46,311 - __main__ - INFO - Starting LLM-TAC experiment at 2025-05-07 20:06:46.311603
2025-05-07 20:06:46,395 - __main__ - INFO - Configuration: model=Llama-3.1-8B, epochs=5, rl_iterations=10
2025-05-07 20:06:46,395 - data_processing - INFO - Processing Coq proof data
2025-05-07 20:06:46,395 - data_processing - INFO - Loading Coq proof data
2025-05-07 20:06:46,395 - data_processing - INFO - Loading existing synthetic data from data/synthetic_coq_data.json
2025-05-07 20:06:46,402 - data_processing - INFO - Data split: 0 train, 0 val, 2505 test examples
2025-05-07 20:06:46,402 - __main__ - INFO - Processed data: 0 train, 0 val, 2505 test examples
2025-05-07 20:06:46,402 - __main__ - INFO - Initializing models...
2025-05-07 20:06:46,402 - models.contextual_encoding - INFO - Simulating loading of model Llama-3.1-8B for contextual encoding
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Simulating loading of model Llama-3.1-8B for tactic generation
2025-05-07 20:06:46,403 - __main__ - INFO - Starting supervised fine-tuning...
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Starting supervised fine-tuning for 5 epochs
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Epoch 1/5 - Train Loss: 1.1026, Val Loss: 1.3332, Train Acc: 0.5346, Val Acc: 0.5000, Time: 0.00s
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Epoch 2/5 - Train Loss: 0.8615, Val Loss: 0.8297, Train Acc: 0.5900, Val Acc: 0.5262, Time: 0.00s
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Epoch 3/5 - Train Loss: 0.7012, Val Loss: 0.9039, Train Acc: 0.6138, Val Acc: 0.5000, Time: 0.00s
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Epoch 4/5 - Train Loss: 0.5951, Val Loss: 0.6880, Train Acc: 0.7205, Val Acc: 0.6465, Time: 0.00s
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Epoch 5/5 - Train Loss: 0.4760, Val Loss: 0.5862, Train Acc: 0.8000, Val Acc: 0.7491, Time: 0.00s
2025-05-07 20:06:46,403 - models.tactic_generator - INFO - Fine-tuning completed. Final validation accuracy: 0.7491
2025-05-07 20:06:46,403 - visualization - INFO - Plotting training curve to results/training_curve.png
2025-05-07 20:06:46,826 - __main__ - INFO - Starting reinforcement learning...
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO - Starting reinforcement learning for 10 iterations
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO - RL Iteration 1/10
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO - RL Iteration 2/10
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO - RL Iteration 3/10
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO - RL Iteration 4/10
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO - RL Iteration 5/10
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO - RL Iteration 6/10
2025-05-07 20:06:46,826 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO - RL Iteration 7/10
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO - RL Iteration 8/10
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO - RL Iteration 9/10
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO - RL Iteration 10/10
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO -   Time: 0.00s, Tactic Accuracy: 0.0000, Proof Completion: 0.0000, Reduction: 0.00%, Avg Reward: 0.0000
2025-05-07 20:06:46,827 - models.reinforcement_learner - INFO - Reinforcement learning completed. Final tactic accuracy: 0.0000
2025-05-07 20:06:46,827 - visualization - INFO - Plotting RL progression to results/rl_progression.png
2025-05-07 20:06:47,170 - __main__ - INFO - Evaluating LLM-TAC on test set...
2025-05-07 20:06:47,170 - evaluation - INFO - Evaluating model TacticGenerator on 2505 examples
2025-05-07 20:06:47,174 - evaluation - INFO - Evaluation results for TacticGenerator:
2025-05-07 20:06:47,174 - evaluation - INFO -   Tactic Accuracy: 0.00
2025-05-07 20:06:47,174 - evaluation - INFO -   Proof Completion Rate: 1.00
2025-05-07 20:06:47,174 - evaluation - INFO -   Reduction in Manual Writing: 0.08%
2025-05-07 20:06:47,174 - evaluation - INFO -   Proof Completion Time: 0.00 seconds
2025-05-07 20:06:47,174 - __main__ - INFO - Evaluating baseline models...
2025-05-07 20:06:47,174 - models.baselines - INFO - Simulating loading of model Llama-3.1-8B for NaiveLLM baseline
2025-05-07 20:06:47,174 - evaluation - INFO - Evaluating model NaiveLLM on 2505 examples
2025-05-07 20:06:47,175 - evaluation - INFO - Evaluation results for NaiveLLM:
2025-05-07 20:06:47,176 - evaluation - INFO -   Tactic Accuracy: 0.00
2025-05-07 20:06:47,176 - evaluation - INFO -   Proof Completion Rate: 1.00
2025-05-07 20:06:47,176 - evaluation - INFO -   Reduction in Manual Writing: 0.12%
2025-05-07 20:06:47,176 - evaluation - INFO -   Proof Completion Time: 0.00 seconds
2025-05-07 20:06:47,176 - models.baselines - INFO - Simulating loading of model Llama-3.1-8B for ICLModel baseline
2025-05-07 20:06:47,176 - evaluation - INFO - Evaluating model ICLModel on 2505 examples
2025-05-07 20:06:47,177 - evaluation - INFO - Evaluation results for ICLModel:
2025-05-07 20:06:47,177 - evaluation - INFO -   Tactic Accuracy: 0.00
2025-05-07 20:06:47,177 - evaluation - INFO -   Proof Completion Rate: 1.00
2025-05-07 20:06:47,177 - evaluation - INFO -   Reduction in Manual Writing: 0.12%
2025-05-07 20:06:47,177 - evaluation - INFO -   Proof Completion Time: 0.00 seconds
2025-05-07 20:06:47,177 - evaluation - INFO - Evaluating model TraditionalTactics on 2505 examples
2025-05-07 20:06:47,183 - evaluation - INFO - Evaluation results for TraditionalTactics:
2025-05-07 20:06:47,183 - evaluation - INFO -   Tactic Accuracy: 0.07
2025-05-07 20:06:47,183 - evaluation - INFO -   Proof Completion Rate: 0.00
2025-05-07 20:06:47,183 - evaluation - INFO -   Reduction in Manual Writing: 0.08%
2025-05-07 20:06:47,183 - evaluation - INFO -   Proof Completion Time: 0.00 seconds
2025-05-07 20:06:47,183 - __main__ - INFO - Running ablation studies...
2025-05-07 20:06:47,183 - models.tactic_generator - INFO - Simulating loading of model Llama-3.1-8B for tactic generation
2025-05-07 20:06:47,183 - models.tactic_generator - INFO - Simulating loading pretrained weights from 
2025-05-07 20:06:47,183 - evaluation - INFO - Evaluating model TacticGenerator on 2505 examples
2025-05-07 20:06:47,186 - evaluation - INFO - Evaluation results for TacticGenerator:
2025-05-07 20:06:47,187 - evaluation - INFO -   Tactic Accuracy: 0.00
2025-05-07 20:06:47,187 - evaluation - INFO -   Proof Completion Rate: 1.00
2025-05-07 20:06:47,187 - evaluation - INFO -   Reduction in Manual Writing: 0.08%
2025-05-07 20:06:47,187 - evaluation - INFO -   Proof Completion Time: 0.00 seconds
2025-05-07 20:06:47,187 - models.contextual_encoding - INFO - Simulating loading of model Llama-3.1-8B for contextual encoding
2025-05-07 20:06:47,187 - evaluation - INFO - Evaluating model TacticGenerator on 2505 examples
2025-05-07 20:06:47,189 - evaluation - INFO - Evaluation results for TacticGenerator:
2025-05-07 20:06:47,189 - evaluation - INFO -   Tactic Accuracy: 0.00
2025-05-07 20:06:47,189 - evaluation - INFO -   Proof Completion Rate: 1.00
2025-05-07 20:06:47,189 - evaluation - INFO -   Reduction in Manual Writing: 0.08%
2025-05-07 20:06:47,189 - evaluation - INFO -   Proof Completion Time: 0.00 seconds
2025-05-07 20:06:47,190 - visualization - INFO - Plotting metrics comparison to results/metrics_comparison.png
2025-05-07 20:06:47,669 - visualization - INFO - Plotting completion time comparison to results/metrics_comparison_time.png
2025-05-07 20:06:48,020 - visualization - INFO - Plotting per-domain performance to results/domain_performance.png
2025-05-07 20:06:48,467 - __main__ - INFO - Experiment completed at 2025-05-07 20:06:48.467591
2025-05-07 20:06:48,467 - __main__ - INFO - Results saved to results
2025-05-07 20:06:48,467 - __main__ - INFO - Generating results.md file
2025-05-07 20:06:48,467 - __main__ - INFO - results.md file generated successfully
