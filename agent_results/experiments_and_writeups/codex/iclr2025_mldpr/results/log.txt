2025-07-29 23:56:09,574 INFO: Starting experiments...
2025-07-29 23:56:09,664 INFO: Using device: cuda
2025-07-29 23:56:09,664 INFO: Running seed 0
2025-07-29 23:56:11,180 INFO: Epoch 1/20: train_loss=5.5695, val_loss=2.8718, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,185 INFO: Epoch 2/20: train_loss=2.8974, val_loss=0.6327, val_acc=0.7018, val_f1=0.6852
2025-07-29 23:56:11,189 INFO: Epoch 3/20: train_loss=0.6518, val_loss=0.2962, val_acc=0.8509, val_f1=0.8931
2025-07-29 23:56:11,194 INFO: Epoch 4/20: train_loss=0.5184, val_loss=1.3917, val_acc=0.7456, val_f1=0.8304
2025-07-29 23:56:11,198 INFO: Epoch 5/20: train_loss=1.5106, val_loss=1.8832, val_acc=0.7018, val_f1=0.8068
2025-07-29 23:56:11,202 INFO: Epoch 6/20: train_loss=1.9514, val_loss=1.5429, val_acc=0.7281, val_f1=0.8208
2025-07-29 23:56:11,206 INFO: Epoch 7/20: train_loss=1.6543, val_loss=0.8501, val_acc=0.7895, val_f1=0.8554
2025-07-29 23:56:11,210 INFO: Epoch 8/20: train_loss=1.0569, val_loss=0.2936, val_acc=0.8596, val_f1=0.8987
2025-07-29 23:56:11,214 INFO: Epoch 9/20: train_loss=0.5350, val_loss=0.1433, val_acc=0.9561, val_f1=0.9645
2025-07-29 23:56:11,219 INFO: Epoch 10/20: train_loss=0.2873, val_loss=0.3682, val_acc=0.8772, val_f1=0.8906
2025-07-29 23:56:11,223 INFO: Epoch 11/20: train_loss=0.4043, val_loss=0.7233, val_acc=0.6842, val_f1=0.6604
2025-07-29 23:56:11,227 INFO: Epoch 12/20: train_loss=0.7350, val_loss=0.9286, val_acc=0.6228, val_f1=0.5657
2025-07-29 23:56:11,231 INFO: Epoch 13/20: train_loss=0.9389, val_loss=0.8790, val_acc=0.6316, val_f1=0.5800
2025-07-29 23:56:11,235 INFO: Epoch 14/20: train_loss=0.8895, val_loss=0.6398, val_acc=0.7105, val_f1=0.6972
2025-07-29 23:56:11,239 INFO: Epoch 15/20: train_loss=0.6542, val_loss=0.3607, val_acc=0.8772, val_f1=0.8906
2025-07-29 23:56:11,244 INFO: Epoch 16/20: train_loss=0.3985, val_loss=0.1787, val_acc=0.9561, val_f1=0.9640
2025-07-29 23:56:11,248 INFO: Epoch 17/20: train_loss=0.2816, val_loss=0.1336, val_acc=0.9649, val_f1=0.9718
2025-07-29 23:56:11,252 INFO: Epoch 18/20: train_loss=0.3206, val_loss=0.1939, val_acc=0.9211, val_f1=0.9396
2025-07-29 23:56:11,256 INFO: Epoch 19/20: train_loss=0.4318, val_loss=0.2763, val_acc=0.8596, val_f1=0.8987
2025-07-29 23:56:11,260 INFO: Epoch 20/20: train_loss=0.5324, val_loss=0.3113, val_acc=0.8596, val_f1=0.8987
2025-07-29 23:56:11,263 INFO: Seed 0 logreg val -> acc: 0.9649, f1: 0.9710, comp: 0.9680
2025-07-29 23:56:11,269 INFO: Seed 0 rf val -> acc: 0.9649, f1: 0.9714, comp: 0.9682
2025-07-29 23:56:11,272 INFO: Seed 0 mlp val -> acc: 0.8596, f1: 0.8987, comp: 0.8792
2025-07-29 23:56:11,281 INFO: Running seed 1
2025-07-29 23:56:11,589 INFO: Epoch 1/20: train_loss=8.5470, val_loss=6.7351, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,594 INFO: Epoch 2/20: train_loss=6.9138, val_loss=5.1757, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,598 INFO: Epoch 3/20: train_loss=5.3083, val_loss=3.6449, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,602 INFO: Epoch 4/20: train_loss=3.7311, val_loss=2.1657, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,606 INFO: Epoch 5/20: train_loss=2.2118, val_loss=1.2203, val_acc=0.2193, val_f1=0.0000
2025-07-29 23:56:11,610 INFO: Epoch 6/20: train_loss=1.2179, val_loss=1.9459, val_acc=0.5702, val_f1=0.7263
2025-07-29 23:56:11,614 INFO: Epoch 7/20: train_loss=1.8929, val_loss=2.5799, val_acc=0.6228, val_f1=0.7676
2025-07-29 23:56:11,618 INFO: Epoch 8/20: train_loss=2.5137, val_loss=2.6923, val_acc=0.6228, val_f1=0.7676
2025-07-29 23:56:11,623 INFO: Epoch 9/20: train_loss=2.6158, val_loss=2.4033, val_acc=0.6228, val_f1=0.7676
2025-07-29 23:56:11,627 INFO: Epoch 10/20: train_loss=2.3242, val_loss=1.8691, val_acc=0.6140, val_f1=0.7609
2025-07-29 23:56:11,631 INFO: Epoch 11/20: train_loss=1.7893, val_loss=1.2797, val_acc=0.2982, val_f1=0.4595
2025-07-29 23:56:11,635 INFO: Epoch 12/20: train_loss=1.2135, val_loss=1.0029, val_acc=0.2982, val_f1=0.0000
2025-07-29 23:56:11,639 INFO: Epoch 13/20: train_loss=0.9900, val_loss=1.2412, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,644 INFO: Epoch 14/20: train_loss=1.2660, val_loss=1.4786, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,648 INFO: Epoch 15/20: train_loss=1.5147, val_loss=1.5514, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,652 INFO: Epoch 16/20: train_loss=1.5911, val_loss=1.4662, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,656 INFO: Epoch 17/20: train_loss=1.5040, val_loss=1.2578, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,660 INFO: Epoch 18/20: train_loss=1.2890, val_loss=0.9850, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,664 INFO: Epoch 19/20: train_loss=1.0065, val_loss=0.7705, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:11,668 INFO: Epoch 20/20: train_loss=0.7769, val_loss=0.7916, val_acc=0.4825, val_f1=0.6194
2025-07-29 23:56:11,671 INFO: Seed 1 logreg val -> acc: 0.9649, f1: 0.9726, comp: 0.9688
2025-07-29 23:56:11,677 INFO: Seed 1 rf val -> acc: 0.9649, f1: 0.9718, comp: 0.9684
2025-07-29 23:56:11,680 INFO: Seed 1 mlp val -> acc: 0.4825, f1: 0.6194, comp: 0.5509
2025-07-29 23:56:11,684 INFO: Running seed 2
2025-07-29 23:56:11,992 INFO: Epoch 1/20: train_loss=1.0257, val_loss=0.2557, val_acc=0.9035, val_f1=0.9281
2025-07-29 23:56:11,996 INFO: Epoch 2/20: train_loss=0.2516, val_loss=0.7065, val_acc=0.7544, val_f1=0.8353
2025-07-29 23:56:12,000 INFO: Epoch 3/20: train_loss=0.6682, val_loss=0.5951, val_acc=0.7895, val_f1=0.8554
2025-07-29 23:56:12,005 INFO: Epoch 4/20: train_loss=0.5569, val_loss=0.3116, val_acc=0.8860, val_f1=0.9161
2025-07-29 23:56:12,009 INFO: Epoch 5/20: train_loss=0.2863, val_loss=0.2319, val_acc=0.9035, val_f1=0.9252
2025-07-29 23:56:12,013 INFO: Epoch 6/20: train_loss=0.2453, val_loss=0.3173, val_acc=0.8860, val_f1=0.9008
2025-07-29 23:56:12,018 INFO: Epoch 7/20: train_loss=0.3811, val_loss=0.3617, val_acc=0.8509, val_f1=0.8661
2025-07-29 23:56:12,022 INFO: Epoch 8/20: train_loss=0.4412, val_loss=0.2970, val_acc=0.9123, val_f1=0.9254
2025-07-29 23:56:12,026 INFO: Epoch 9/20: train_loss=0.3565, val_loss=0.2261, val_acc=0.9035, val_f1=0.9252
2025-07-29 23:56:12,030 INFO: Epoch 10/20: train_loss=0.2455, val_loss=0.2356, val_acc=0.9035, val_f1=0.9281
2025-07-29 23:56:12,035 INFO: Epoch 11/20: train_loss=0.2177, val_loss=0.3050, val_acc=0.8860, val_f1=0.9161
2025-07-29 23:56:12,039 INFO: Epoch 12/20: train_loss=0.2713, val_loss=0.3570, val_acc=0.8772, val_f1=0.9103
2025-07-29 23:56:12,043 INFO: Epoch 13/20: train_loss=0.3194, val_loss=0.3421, val_acc=0.8772, val_f1=0.9103
2025-07-29 23:56:12,047 INFO: Epoch 14/20: train_loss=0.3030, val_loss=0.2810, val_acc=0.8947, val_f1=0.9221
2025-07-29 23:56:12,051 INFO: Epoch 15/20: train_loss=0.2445, val_loss=0.2246, val_acc=0.9123, val_f1=0.9342
2025-07-29 23:56:12,055 INFO: Epoch 16/20: train_loss=0.2048, val_loss=0.2082, val_acc=0.9123, val_f1=0.9324
2025-07-29 23:56:12,060 INFO: Epoch 17/20: train_loss=0.2154, val_loss=0.2232, val_acc=0.9123, val_f1=0.9306
2025-07-29 23:56:12,064 INFO: Epoch 18/20: train_loss=0.2526, val_loss=0.2289, val_acc=0.9123, val_f1=0.9286
2025-07-29 23:56:12,068 INFO: Epoch 19/20: train_loss=0.2639, val_loss=0.2146, val_acc=0.9123, val_f1=0.9315
2025-07-29 23:56:12,072 INFO: Epoch 20/20: train_loss=0.2377, val_loss=0.2053, val_acc=0.9123, val_f1=0.9324
2025-07-29 23:56:12,074 INFO: Seed 2 logreg val -> acc: 0.9561, f1: 0.9655, comp: 0.9608
2025-07-29 23:56:12,081 INFO: Seed 2 rf val -> acc: 0.9737, f1: 0.9787, comp: 0.9762
2025-07-29 23:56:12,083 INFO: Seed 2 mlp val -> acc: 0.9123, f1: 0.9324, comp: 0.9224
2025-07-29 23:56:12,098 INFO: Saved results to /home/chenhui/mlr-bench/codex_experiments/iclr2025_mldpr/codex/results
2025-07-29 23:56:12,605 INFO: Epoch 1/20: train_loss=5.5695, val_loss=2.8718, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:12,609 INFO: Epoch 2/20: train_loss=2.8974, val_loss=0.6327, val_acc=0.7018, val_f1=0.6852
2025-07-29 23:56:12,613 INFO: Epoch 3/20: train_loss=0.6518, val_loss=0.2962, val_acc=0.8509, val_f1=0.8931
2025-07-29 23:56:12,617 INFO: Epoch 4/20: train_loss=0.5184, val_loss=1.3917, val_acc=0.7456, val_f1=0.8304
2025-07-29 23:56:12,621 INFO: Epoch 5/20: train_loss=1.5106, val_loss=1.8832, val_acc=0.7018, val_f1=0.8068
2025-07-29 23:56:12,625 INFO: Epoch 6/20: train_loss=1.9514, val_loss=1.5429, val_acc=0.7281, val_f1=0.8208
2025-07-29 23:56:12,630 INFO: Epoch 7/20: train_loss=1.6543, val_loss=0.8501, val_acc=0.7895, val_f1=0.8554
2025-07-29 23:56:12,634 INFO: Epoch 8/20: train_loss=1.0569, val_loss=0.2936, val_acc=0.8596, val_f1=0.8987
2025-07-29 23:56:12,638 INFO: Epoch 9/20: train_loss=0.5350, val_loss=0.1433, val_acc=0.9561, val_f1=0.9645
2025-07-29 23:56:12,642 INFO: Epoch 10/20: train_loss=0.2873, val_loss=0.3682, val_acc=0.8772, val_f1=0.8906
2025-07-29 23:56:12,646 INFO: Epoch 11/20: train_loss=0.4043, val_loss=0.7233, val_acc=0.6842, val_f1=0.6604
2025-07-29 23:56:12,650 INFO: Epoch 12/20: train_loss=0.7350, val_loss=0.9286, val_acc=0.6228, val_f1=0.5657
2025-07-29 23:56:12,654 INFO: Epoch 13/20: train_loss=0.9389, val_loss=0.8790, val_acc=0.6316, val_f1=0.5800
2025-07-29 23:56:12,659 INFO: Epoch 14/20: train_loss=0.8895, val_loss=0.6398, val_acc=0.7105, val_f1=0.6972
2025-07-29 23:56:12,663 INFO: Epoch 15/20: train_loss=0.6542, val_loss=0.3607, val_acc=0.8772, val_f1=0.8906
2025-07-29 23:56:12,667 INFO: Epoch 16/20: train_loss=0.3985, val_loss=0.1787, val_acc=0.9561, val_f1=0.9640
2025-07-29 23:56:12,671 INFO: Epoch 17/20: train_loss=0.2816, val_loss=0.1336, val_acc=0.9649, val_f1=0.9718
2025-07-29 23:56:12,675 INFO: Epoch 18/20: train_loss=0.3206, val_loss=0.1939, val_acc=0.9211, val_f1=0.9396
2025-07-29 23:56:12,679 INFO: Epoch 19/20: train_loss=0.4318, val_loss=0.2763, val_acc=0.8596, val_f1=0.8987
2025-07-29 23:56:12,683 INFO: Epoch 20/20: train_loss=0.5324, val_loss=0.3113, val_acc=0.8596, val_f1=0.8987
2025-07-29 23:56:12,999 INFO: Epoch 1/20: train_loss=8.5470, val_loss=6.7351, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,003 INFO: Epoch 2/20: train_loss=6.9138, val_loss=5.1757, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,007 INFO: Epoch 3/20: train_loss=5.3083, val_loss=3.6449, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,011 INFO: Epoch 4/20: train_loss=3.7311, val_loss=2.1657, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,015 INFO: Epoch 5/20: train_loss=2.2118, val_loss=1.2203, val_acc=0.2193, val_f1=0.0000
2025-07-29 23:56:13,019 INFO: Epoch 6/20: train_loss=1.2179, val_loss=1.9459, val_acc=0.5702, val_f1=0.7263
2025-07-29 23:56:13,024 INFO: Epoch 7/20: train_loss=1.8929, val_loss=2.5799, val_acc=0.6228, val_f1=0.7676
2025-07-29 23:56:13,028 INFO: Epoch 8/20: train_loss=2.5137, val_loss=2.6923, val_acc=0.6228, val_f1=0.7676
2025-07-29 23:56:13,032 INFO: Epoch 9/20: train_loss=2.6158, val_loss=2.4033, val_acc=0.6228, val_f1=0.7676
2025-07-29 23:56:13,036 INFO: Epoch 10/20: train_loss=2.3242, val_loss=1.8691, val_acc=0.6140, val_f1=0.7609
2025-07-29 23:56:13,040 INFO: Epoch 11/20: train_loss=1.7893, val_loss=1.2797, val_acc=0.2982, val_f1=0.4595
2025-07-29 23:56:13,044 INFO: Epoch 12/20: train_loss=1.2135, val_loss=1.0029, val_acc=0.2982, val_f1=0.0000
2025-07-29 23:56:13,048 INFO: Epoch 13/20: train_loss=0.9900, val_loss=1.2412, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,052 INFO: Epoch 14/20: train_loss=1.2660, val_loss=1.4786, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,057 INFO: Epoch 15/20: train_loss=1.5147, val_loss=1.5514, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,061 INFO: Epoch 16/20: train_loss=1.5911, val_loss=1.4662, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,065 INFO: Epoch 17/20: train_loss=1.5040, val_loss=1.2578, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,069 INFO: Epoch 18/20: train_loss=1.2890, val_loss=0.9850, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,073 INFO: Epoch 19/20: train_loss=1.0065, val_loss=0.7705, val_acc=0.3772, val_f1=0.0000
2025-07-29 23:56:13,077 INFO: Epoch 20/20: train_loss=0.7769, val_loss=0.7916, val_acc=0.4825, val_f1=0.6194
2025-07-29 23:56:13,395 INFO: Epoch 1/20: train_loss=1.0257, val_loss=0.2557, val_acc=0.9035, val_f1=0.9281
2025-07-29 23:56:13,400 INFO: Epoch 2/20: train_loss=0.2516, val_loss=0.7065, val_acc=0.7544, val_f1=0.8353
2025-07-29 23:56:13,404 INFO: Epoch 3/20: train_loss=0.6682, val_loss=0.5951, val_acc=0.7895, val_f1=0.8554
2025-07-29 23:56:13,408 INFO: Epoch 4/20: train_loss=0.5569, val_loss=0.3116, val_acc=0.8860, val_f1=0.9161
2025-07-29 23:56:13,412 INFO: Epoch 5/20: train_loss=0.2863, val_loss=0.2319, val_acc=0.9035, val_f1=0.9252
2025-07-29 23:56:13,416 INFO: Epoch 6/20: train_loss=0.2453, val_loss=0.3173, val_acc=0.8860, val_f1=0.9008
2025-07-29 23:56:13,420 INFO: Epoch 7/20: train_loss=0.3811, val_loss=0.3617, val_acc=0.8509, val_f1=0.8661
2025-07-29 23:56:13,424 INFO: Epoch 8/20: train_loss=0.4412, val_loss=0.2970, val_acc=0.9123, val_f1=0.9254
2025-07-29 23:56:13,428 INFO: Epoch 9/20: train_loss=0.3565, val_loss=0.2261, val_acc=0.9035, val_f1=0.9252
2025-07-29 23:56:13,433 INFO: Epoch 10/20: train_loss=0.2455, val_loss=0.2356, val_acc=0.9035, val_f1=0.9281
2025-07-29 23:56:13,437 INFO: Epoch 11/20: train_loss=0.2177, val_loss=0.3050, val_acc=0.8860, val_f1=0.9161
2025-07-29 23:56:13,441 INFO: Epoch 12/20: train_loss=0.2713, val_loss=0.3570, val_acc=0.8772, val_f1=0.9103
2025-07-29 23:56:13,445 INFO: Epoch 13/20: train_loss=0.3194, val_loss=0.3421, val_acc=0.8772, val_f1=0.9103
2025-07-29 23:56:13,449 INFO: Epoch 14/20: train_loss=0.3030, val_loss=0.2810, val_acc=0.8947, val_f1=0.9221
2025-07-29 23:56:13,453 INFO: Epoch 15/20: train_loss=0.2445, val_loss=0.2246, val_acc=0.9123, val_f1=0.9342
2025-07-29 23:56:13,457 INFO: Epoch 16/20: train_loss=0.2048, val_loss=0.2082, val_acc=0.9123, val_f1=0.9324
2025-07-29 23:56:13,461 INFO: Epoch 17/20: train_loss=0.2154, val_loss=0.2232, val_acc=0.9123, val_f1=0.9306
2025-07-29 23:56:13,465 INFO: Epoch 18/20: train_loss=0.2526, val_loss=0.2289, val_acc=0.9123, val_f1=0.9286
2025-07-29 23:56:13,470 INFO: Epoch 19/20: train_loss=0.2639, val_loss=0.2146, val_acc=0.9123, val_f1=0.9315
2025-07-29 23:56:13,474 INFO: Epoch 20/20: train_loss=0.2377, val_loss=0.2053, val_acc=0.9123, val_f1=0.9324
2025-07-29 23:56:13,618 INFO: Plots saved.
2025-07-29 23:56:13,618 INFO: Experiment completed.
